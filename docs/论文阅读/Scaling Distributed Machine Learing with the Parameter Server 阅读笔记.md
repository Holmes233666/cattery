# Scaling Distributed Machine Learing with the Parameter Server 阅读笔记

OSDI会议：操作系统设计和实现，SOSP两个会议是系统领域的两大会议

相似方向：高性能计算、编译器等

使用参数服务器扩展机器学习

## 摘要

概述：

针对分布式机器学习问题提出了一个参数服务器架构。

数据-工作 分布在工作节点上，服务器结点维护全局的共享参数——表示为稠密或者系数的向量或者矩阵的形式。

该架构管理结点之间的异步通信，支持灵活一致性模型，有弹性的伸缩性，持续容错

实验：

验证可扩展性，在PB级的数据的基础上展示了实验结果，涉及的问题范围包括稀疏逻辑回归到LDA和分布式算法。

## Introduction

<u>问题+重要性：</u>

解决大规模机器学习问题的先决条件——分布式优化和预演

单台机器无法完成，实现一个有效的分布式算法也并不容易

密集的计算工作量和大量的数据通信都要求对系统进行精心的设计，即一个精心的设计要包含这两个方面的考量——

- 密集的工作量
- 数据通信量

<u>细致分析：</u>

$10^{9}$到$10^{12}$参数，所有工作节点间共享这些模型

三大痛点

- 巨大的网络通信量

- 机器学习的问题是顺序求解的，需要在结点之间进行大量的数据同步

- 容灾具有重要性

  为什么要容灾？

  ![image-20220808210454976](https://cdn.jsdelivr.net/gh/Holmes233666/blogImage@main/img/image-20220808210454976.png)

工业界容灾非常重要。

### 1.1 Contribution

第一代 jeff dean  ->  第二代  ->  提出第三代开源实现

好处：

- 共享模块抽象，实现任务比较简单
- 同时能够处理各种算法：Logsitic 回归，LDA

机器学习在工业界，真实抽象：

- 有效通信：压缩，降低通信量

- 灵活一致性模型：每一个计算节点数据的一致性

  强一致性：适合机器学习  vs 弱一致性：适合系统

  做一个权衡

- 弹性的可扩展性：新的结点可以加进来，不会导致任务停止；

  对于非常强一致性的问题，很重要

- 容灾：要花多少时间去恢复——1s恢复，继续执行；使用vector colock

- 易用性：全局的parameter表示为向量和矩阵（当时python的numpy还没有那么流行，主要机器学习还是使用C++来开发）

- 新颖度：找到了合适的系统技术，适配到机器学习算法中。系统+AI很好的融合，具体的说放弃了一些一致性的要求，同时修改机器学习的算法，使其能够接受丢失的一致性

### 1.2 Engineering Challenges

工程上的挑战：需要不断读写全局参数

参数服务器：提供了一个有效的机制去聚合和同步模型的参数，计算结点会读取数据进行计算

别人的抽象：datastore提供的key value的抽象是不够的，key一般对应下标，开销大

我们：很多学习模型把参数表示成数学对象，比如矩阵、向量，某个时间点时这个矩阵，向量的一部分会发生改变。工作节点发送向量的一个段segment，或者是整个矩阵的一整行。去批量的发送和更新，而不是逐个更新

容灾技术：数据结点-实时复制，计算结点-替换/增加结点都是可以做到的

### 1.3 相关的工作

引用13使用的parameter sever，使这个名字出名。

自己的模型称为第三代：尝试做一个更通用

## Machine Learning

算法1：

梯度下降的算法  ------   如何转换为  ------->   分布式的算法

抽象：
$$
\begin{cases}任务调度器：for循环，迭代时间\\计算节点Worker：本质是一个进程，可以在一台机器上出现（抽象的概念）\begin{cases}找到那一块的结点\\读到后权重拿下来\\迭代T，拿到T时刻的w，计算梯度，总梯度push回去\end{cases}\\服务结点Server：另外的进程\begin{cases}梯度汇总，得到总梯度\\\end{cases}\end{cases}
$$
![image-20220808220744697](https://cdn.jsdelivr.net/gh/Holmes233666/blogImage@main/img/image-20220808220744697.png)

## Achetecture

