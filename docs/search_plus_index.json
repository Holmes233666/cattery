{"./":{"url":"./","title":"简介","keywords":"","body":"Summary 软工大三下笔记 算法分析与设计笔记 CH1：Introduction CH2：算法入门 CH2：算法入门_review CH3：Growth of Functions CH3：Growth of Functions_review CH4：Recurrences CH6：HeapSort CH7：QuickSort CH8：Sorting in linear time CH9：Medians and Order Statistics CH10：Divide and Conquer：More Algorithms CH15：Dynamic_Programming CH16：Greedy_Algorithms CH24：Shorest_Path CH25：Back-Tracking 软件体系结构 CH1：Introduction CH2：Achitecture_Style CH3：UML CH4：理解质量属性 CH5：ATMA 软件过程与项目管理 PART1-判断题错误总结 PART2-选择题答案整理 PART3-填空题 PART4-简答题 保研笔记 保研算法练习AcWing训练 基础算法.md 计算机通信与网络保研复习 补充：上下层协议 数据链路层 网络层 传输层 应用层 论文阅读 ParameterServer阅读笔记-2014-OSDI-李沐 PATHWAYS阅读笔记-2022-MLSys-JeffDean-Sanjay Alpa阅读笔记-2022-OSDI-郑怜悯 FasterMoE阅读笔记-2022-PPoPP-何家傲 SEUSS阅读笔记-2020-EuroSys-JamesCadden 离散数学 集合论基础 命题逻辑 命题逻辑的推理理论 谓词逻辑 二元关系 特殊关系 函数 图论基础 操作系统复习 引论 进程与线程 经验贴-面试 保研英语面试常见问题总结 英文个人陈述 预推免各院校经验贴总结 var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"算法/about.html":{"url":"算法/about.html","title":"算法分析与设计","keywords":"","body":"var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"算法/CH1：Introduction.html":{"url":"算法/CH1：Introduction.html","title":"CH1：Introduction","keywords":"","body":"CH1：Introduction 1.1 Factors of Programming programming language IDE software achitecture 架构： 架构的类型： \\begin{cases}C2\\ Style：conponent\\ \\& \\ connector\\\\Pipe-Fliter\\ Style:输入\\rightarrow 输出\\\\Repositories\\ Style：以某一数据源为中心的操作\\end{cases} 成熟的模式：逐步产生商业架构 Java EE CORBA .NET（与javaEE类似） 1.2 More Important 1.2.1 Transaction finish or null 1.2.2 Security 1.3 DS and Algorithm 1.3.1 Algorithm Concept：A well-Defined computational procedure that takes some value, or set of values, as input and proceduces some value, or set of values, as output. Broadly：a step-step procedure for solving a problem or accomplishing some end especially by a computer. issues： correctness efficiency(amount of work done and space used) storage(simplicity, clarity) optimality 1.3.2 Promblem that can be solved by algorithm 基因工程 网络 电子商务 生产 一个经典的问题：you are given n integers(there may be negative ones but not all) a1, a2, ..., an, determine i and j which maximize the sum from $a_i$ to $a_j$. Case：6 integers：(-2, 11, -4, 13, -5, -2) Ans：i = 2, j = 4, max sum is 20 1.3.3 Importance of algorithms 问题：给1000,000个整数排序 数据量 主频 算法时间复杂度 计算时间 1000000 1GHz $2n^2$ $2\\times 10^5\\ seconds$ 1000000 100MHz $50nlgn$ $105\\ seconds$ 加之主频的提升不大，算法更为重要 1.3.4 About course Design and Analysis 怎么找算法？ 评价算法，定量 var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"算法/CH2：算法入门.html":{"url":"算法/CH2：算法入门.html","title":"CH2：算法入门","keywords":"","body":"CH2：算法入门 The problem of sorting input：sequence of n natural numbers output：permutation such that $a_1'\\leq a_2'\\leq ....\\leq a_n'$ 2.1 Insert Sort 算法： for(i = 2; i = 1 and A[j] > key){ A[j+1] = A[j]; // 后移 j--; } A[j+1] = key; } 2.2 Kinds of Analysis worstest - case（usually）：最坏情况优先考虑 Average - case（sometimes） Best - case（bogus） 2.2.1 循环不变式 loop-invariants Proving correctness Using Loop-invariants【外层为循环】 需要证明的三个性质： 初始化：它在循环的第一轮迭代开始时，应该是正确的 保持：如果在某一次的迭代开始前是正确的，那么在下一次迭代开始前，他也应该保持正确 终止：不变式给了一个有用的性质，表明算法是正确的 2.2.2 运行时间 （1）Running Time 运行时间的取决因素： 输入序列：已经排列好的序列【数据特征】 数据规模：更短的序列更容易排好 通常，我们考虑运行时间的上界，因为这是一个保证 （2）Machine-independent time 插入排序的最差时间取决于计算机的速度： 相对速度（on the same machine）——关注算法 绝对速度（on different machine） 通常我们忽视机器相关时间的限制，关注“the growth of T(n) as n → ∞” 称为渐近分析“Asympotic Analysis” （3）$\\theta-$notation 关心增长率，低阶和常数丢弃 Drop low-order terms; ignore leading constants Example：$3n^3+90n^2-5n+6046 = \\theta(n^3)$ 当n变得足够大时，一个$\\theta(n^2)$的算法总会打败一个$\\theta(n^3)$的算法 2.2.3 Insertion Sort Analysis Worest case：Input reverse sorted【逆序的序列】 T(n) = \\sum\\limits_{j = 2,...,n}\\theta(j) = \\theta(n^2) Average case：All permutations equally likely T(n) = \\sum\\limits_{j = 2,...,n}\\theta(j/2)=\\theta(n^2) 2.3 Analysis Algorithm Analysis An Algorithm： 算法分析指的是对一个算法所需的资源进行分析，预测算法所需的资源，包括内存、通信带宽或计算机硬件等。 但是通常我们更想测量计算时间。 2.3.1 RAM RAM：单处理机，随机存储模型 random-access-machine（RAM） Model with no concurrent operations 不考虑并发 executed as an atom operation 不考虑中断，原子操作 每条指令需要固定时间 内存容量足够大 在RAM模型下，对基础的操作进行计数即可 count fundamental operation。 2.3.2 Analysis of Insert Operation 插入排序的时间计算如下： T(n) = c_1n+c_2(n-1) + c_4(n-1)+c_5\\sum\\limits_{j=2}^nt_j+c_6\\sum\\limits_{j=2}^n(t_j-1) + c_7\\sum\\limits_{j=2}^n(t_j-1)+c_8(n-1)\\\\ best case：数组是有序的 **$t_j = 1$，检查一次，不需要后移** T(n) = c_1n+c_2(n-1) + c_4(n-1)+c_5(n-1)+c_8(n-1)\\\\=(c_1+c_2+c_4+c_5+c_8)n-(c_2+c_4+c_5+c_8) 运行时间是n的线性函数 worest case：数组是倒序的 **$t_j = j$，检查一次，不需要后移** T(n) = c_1n+c_2(n-1)+c_4(n-1)+c_5(n(n+1)/2-1)+c_6(n(n-1)/2)+c_7(n(n-1)/2)+c_8(n-1)\\\\=(c_5/2+c_6/2+c_7/2)n^2+(c_1+c_2+c_4+c_5/2-c_6/2-c_7/2+c_8)n-(c_2+c_4+c_5+c_8) 运行时间是n的二次函数。 note： 对于某些算法来说，最坏情况经常发生 平均情况有时候和一般情况一样糟糕 2.3.3 Order of Growth 我们只考虑运行时间的增长顺序: 我们可以忽略低阶项，因为对于非常大的n，它们相对不重要。 我们也可以忽略前项的常系数，因为对于非常大的n，它们对计算效率的增长速度并不重要。 我们刚刚说过，最好的情况是n的线性而最坏/平均的情况是n的二次型。 2.4 Designing Algorithm 2.4.1 Divide and Conquer To solve P： Divide P into smaller problems P_1, P_2, ... , P_k Conquer by solving the (smaller) subproblems recursively Combine the solutions to P_1,P_2,...,P_k into the solution for P （1）Merge Sort Using Divide and Conquer, we can obtain a merge sort algorithm Divide：divide n elements into two subsequences of n/2 elements each Conquer：Solve the two subsequences recursively Combine：Merge the two sorted subsequences to produce the sorted answer Merge-Sort(A，p，r) INPUT: a sequence of n numbers stored in array A OUTPUT: an ordered sequence of n numbers MergeSort(A,p,r) if p Actions of Merge Sort： 2.4.2 Analysis divide and conquer Algorithm $T(n)$ running time on a problem of size n 【n ：问题规模】 假设把原问题分成a个子问题，每个子问题是原问题规模的$1/b$ 对于MergeSort来说，a = 2，每个问题的规模是原问题的1/b $D(n)$ 分解的开销 $C(n)$ 合并的开销 子问题 --合并-->原问题 MergeSort Recurrence Equation T(n) = \\begin{cases}\\Theta(1)\\quad if\\ n≤c\\\\ aT(n/b)+D(n) + C(n)\\quad otherwise\\end{cases} 对于MergeSort来说，递归式如下： T(n) = \\begin{cases}\\Theta(1)\\quad if\\ n≤c\\\\ 2T(n/2)+\\Theta(n)\\quad otherwise\\end{cases} Claim： T(n) = nlog_2^n 所有情况下均为nlog_2^n 最好 最坏 平均 $log_2^n+1$是针对结点的，若是针对边则是$log_2^n$。每层的和是一定的，都是cn 所以总的花费时间为： \\sum_{i=1}^{log_2^n} cn = cn·log_2^n Proof by Telescoping T(n) = 2T(n/2)+n = 2(2T(n/4) + n/2)+n = 4T(n/4)+2n\\\\ =......=nT(n/n)+log_2^n n=nT(1)+nlog_2^n var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"算法/CH2：算法入门_review.html":{"url":"算法/CH2：算法入门_review.html","title":"CH2：算法入门_review","keywords":"","body":"CH2 算法入门 MindMap 排序问题： 输入：序列$$ 输出：非降序排列：$$，满足$a_1'\\leq a_2'\\leq...\\leq a_n'$ 2.1 Insert Sort 程序： void insertSort(vector& vec) { for (int i = 2; i 0 && vec[j] > key) { vec[j+1] = vec[j]; // 后移操作 j--; } vec[j+1] = key; } } 注意后移操作：A[j+1] = A[j] 若位置0处数字为负无穷，那么while循环中将不用写条件j>0。 2.2 Analysis of algorithms 2.2.1 运行时间 Running Time： 数据的初始特征 数据规模 we seek upper bounds on the running time Kinds of Analysis： Worst - case（usually 最坏情况最优先考虑） Average - case（sometimes） Best - case（bogus） 2.2.2 loop-invariant Proving correctness using loop-invariant：最外层必须是循环，证明某一性质每一次循环都不变 需要证明的三个性质 初始化：他在循环的第一轮迭代开始前，应该是正确的 保持：如果在某一次的迭代开始前是正确的，那么在下一次的迭代开始前他也应该保持正确 终止：循环结束时，不变式给了一个有用的性质，表明算法是正确的 使用循环不变式证明插入排序 证明：在每次迭代开始前子数组A[1...j-1]中元素为原数组中的A[1...j-1]，但是是有序的 初始化 j = 2 保持：A[j - 1], A[j - 2],… are moved one at a time till the proper position for A[j] is found. 结束：当j=n+1时，整个序列有序 2.2.3 机器独立时间 machine independent time relative time：在相同的机器上——关注算法 absolute time：在不同的机器上 忽略机器相关的约束，直接考虑 $n\\rightarrow \\infty$时的$T(n)$ —— 渐近分析 Asymptotic Analysis 2.2.4 $\\Theta-Notation$ （1）定义 $\\Theta$表示法的定义： 数学定义：$\\Theta(g(n)) = {存在正整数c_1和c_2，并且n_0>0，满足当所有的n\\geq n_0时，0\\leq c_1g(n)\\leq f(n)\\leq c_2g(n)}$ 工程上：关心增长率，低阶和常数项丢弃 Example：$3n^3 + 9n^2-5n+8344 = \\Theta(n^3)$ （2）Asyptotic Performance 当n变得足够大的时候，一个$\\Theta(n^2)$的算法一定比一个$\\theta(n^3)$的算法要好 2.2.5 Insertion sort analysis 最差情况：输入是逆序的——每个数都要前移 T(n) = \\sum_{j=2..n}\\Theta(j)=\\Theta(n^2) 平均情况： T(n) = \\sum_{j=2..n}\\Theta(j/2)=\\Theta(n^2) 2.3 算法分析的入门 2.3.1 算法分析的概念 算法分析指的是对一个算法所需的资源进行分析，内存，通信带宽或者计算机硬件是主要关心的，但通常希望测量计算时间。 在我们分析算法之前，我们必须有一个将要使用的实现技术的模型，包括该技术的资源及其成本的模型 算法实现的技术模型：单处理器，随机存储模型[RAM] 2.3.2 Random Access Model 不考虑并发 不考虑中断，原子操作 假设每条指令花费常数时间 内存足够大 …… 在RAM模型下，需要考虑的是基本操作的次数 counting fundamental operations 2.3.3 Analysis of insert operation $cost$：每次基本操作花费的代价 $t_j$：假设第$j$次迭代需要检查$while$循环条件的次数为$t_j$ T(n) = c_1n+c_2(n-1) + c_4(n-1) +c_5\\sum_{j=2}^n t_j+c_6\\sum_{j=2}^n (t_j-1)+c_7\\sum_{j=2}^n (t_j-1)+c_8(n-1) best-case：数组是有序的，$t_j=1$检查一次while，不需要后移 T(n) = c_1n+c_2(n-1) + c_4(n-1) +c_5(n-1)+c_8(n-1) = (c_1+c_2+c_4+c_5+c_8)n -(c_2+c_4+c_5+c_8) 即，最好情况下插入排序开销为线性开销。 worest-case：数组是逆序的，那么$t_j = j$（$i=0$也会检查） \\begin{aligned} T(n)=& c_{1} n+c_{2}(n-1)+c_{4}(n-1)+c_{5}(n(n+1) / 2-1)+c_{6}(n(n-1) / 2) \\\\ & c_{7}(n(n-1) / 2)+c_{8}(n-1) \\\\ =&\\left(c_{5} / 2+c_{6} / 2+c_{7} / 2\\right) n^{2} \\\\ &+\\left(c_{1}+c_{2}+c_{4}+c_{5} / 2-c_{6} / 2-c_{7} / 2+c_{8}\\right) n-\\left(c_{2}+c_{4}+c_{5}+c_{8}\\right) \\end{aligned} 运行时间是平方级开销。 在一些算法中，最坏情况经常发生，比如查询数据库 有时候平均情况和最差情况一样糟糕 Order of Growth 忽略低阶项 忽略常数项 2.4 Designing Algorithms Insert Sort：增量法 2.4.1 Divide-and-Conquer To solve P: Divide P into smaller problems P1 , P2 , …, Pk . Conquer by solving the (smaller) subproblems recursively. Combine the solutions to P1 , P2 , …, Pk into the solution for P. note：解决问题前想一想：该问题难以解决是否是因为规模太大了，若是规模足够小，那么是不是可以解决 2.4.2 Merge Sort 使用分治策略，我们首先分析归并排序。 Divide：把n个元素分成两个子序列，每个子序列有$n/2$个元素 Conquer：递归求解两个子问题 Solve the two subsequences recursively Combine：合并两个子序列，得到有序的结果 （1）Merge-Sort函数 假设我们有一个Merge(A,p,q,r)函数，他把两个有序的数组A[p……q]和A[q+1……r]合并 Merge-Sort 输入：需要排序的n个数序列A 输出：有序序列 #include #include #include using namespace std; void Merge_Sort(vector& vec, int start, int end); // 分治算法主体 void Merge(vector& A, int start, int mid, int end); // 合并的过程，重点在合并 void printVec(vector& vec); int main() { vector nums = {8,5,9,10,3,6,2,7}; Merge_Sort(nums, 0, nums.size()-1); printVec(nums); return 0; } void Merge_Sort(vector& vec, int start, int end) { if (start & A, int start, int mid, int end) { int n1 = mid - start + 1; // 数组1个数 int n2 = end - (mid + 1) + 1; // 数组2元素个数 vector vec1(n1+1), vec2(n2+1); // 临时数组初始化 // 数组末尾设为无穷大简化了扫尾工作 vec1[n1] = 99999; vec2[n2] = 99999; // 数组赋值 for (int i = start; i & vec) { for (int i = 0; i 注意分治时采取自上而下的递归处理时，每个分支执行的顺序，如下： 2.4.3 Analysis divide-and-conquer Algorithm （1）符号定义 $T(n)$：$\\text{running time on a problem of size n}$， 问题的运行时间，n为问题规模 $D(n)$：分解的时间开销 $C(n)$：合并的开销 $子问题\\rightarrow 原问题$ 统一模式： T(n)=\\begin{cases}\\Theta(1)&& if\\ n\\leq c\\\\ D(n) + aT(n/b) + C(n)&& otherwise\\end{cases} 当问题规模足够小时，不需要分治。 否则递归求解 （2）MergeSort Analysis T(n)=\\begin{cases}\\Theta(1)&& if\\ n\\leq c\\\\ 2T(n/2) + C(n)=2T(n/2) + \\Theta(n)&& otherwise\\end{cases} 在归并排序中，分解时分解为2个子问题，每个问题的规模是原来的$n/2$。 Claim：$T(n) = nlog2^n$，所有情况下均为$nlgn$【平均、最好、最坏】 证明： 递归到何时终止？$n/x == 1$时终止，次数：除法$log_2^n$，树高$log_2^n+1$ T(n) = cn·lg^n + c'n 代入法证明 Proof by Telescoping T(n) =2T(n/2) + n\\\\ =2(2T(n/4)+n/2) +n=4T(n/4)+2n\\\\ =4(2T(n/8) + n/4) + 2n = 8T(n/8) + 3n\\\\ =……\\\\=nT(n/2^k) + kn\\\\=……\\\\ =nT(n/2^{lgn}) + nlgn 数学归纳法证明 T(n) = nlgn var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"算法/CH3：Growth_of_Functions.html":{"url":"算法/CH3：Growth_of_Functions.html","title":"CH3：Growth of Functions","keywords":"","body":"CH3：Growth of Functions Topics： Growth of Functions O/\\Theta/\\Omega notations Asymptotic Growth： We want to express rate of growth of standard functions: the leading term with respect to n 【第一项】 ignoring constants in front of it 【忽略常数项】 3.1 Asymptotic Notation 3.1.1 O-notation O(g(n)) = {f(n) ：There exist positive constants c and n_0 such that 0≤f(n) ≤cg(n) for all $n≥n_0$} O(.) 用来渐近表示计算时间的上届 —— 【最坏情况】 O(.) is used to bound worest-case running time 将f(n)用简洁的O(.)来表示 任何一个二次多项式都是$O(n^2)$ Note： When we say \"the running time is O(n)\"：the worest case running time is O(n) We often write f(n) = O(g(n)), instead of f(n) ∈ O(g(n)) Use O(n) in equations：2n^2+3n+1 = 2n^2+O(n) 3.1.2 $\\Omega-notation$ \\Omega(g(n)) = \\{\\text{There exist positive constants c and n0 such that 0=n0}\\} 【大于g（n）的整数倍】 \\Omega-notation用于给出函数的下界 任何一个二次多项式都是\\Omega(n^2)的。 3.1.3 \\Theta-notation \\Theta(g(n)) = \\{\\text{There exist positive constants c and n0 such that } 0\\leq c_1g(n)\\leq f(n)\\leq c_2g(n)\\ \\text{for all n>=n0}\\} \\Theta(g(n))提供了函数的一个tight bound 紧致界 $f(n) = \\Theta(g(n))$当且仅当f(n) = O(g(n))并且f(n) =\\Omega(g(n)) 只要最高次项，那就是$\\Theta(.)$ Note： We often think of f(n) = O(g(n)) as corresponding to f(n)≤ g(n) f(n) = \\Theta(g(n)) corresponds to f(n) = g(n) f(n) = \\Omega(g(n)) corresponds to f(n) ≥ g(n) Example： 4n^3 + 3n^2 + 2n + 1 = 4n^3 + 3n^2 + Θ(n)= 4n^3 + Θ(n^2) = Θ(n^3) var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"算法/CH3：Growth_of_Functions_review.html":{"url":"算法/CH3：Growth_of_Functions_review.html","title":"CH3：Growth of Functions_review","keywords":"","body":"CH3：Growth of Functions MindMap Asymptotic Growth 分析算法时我们对算法输入规模为n时的最坏情况下运行时间函数感兴趣 不考虑常数项 不考虑低阶项 3.1 Asymptotic Notation 3.1.1 O-Notation （1）定义 O(g(n)) = \\{f(n):\\text{There exists positive c and }n_0\\text{ such that } 0\\leq f(n)\\leq cg(n)\\text{ for all }n\\geq n_0\\} 正整数c 正整数n0 g(n)是最高次项 exists：存在即可 **$O(g(n))$是一个满足上述条件的运行时间函数的集合** $O(.)$：用于渐进上界函数 $\\text{is used to asymptotic upper bound a function}$ $O(.)$：用来表示最坏情况的运行时间$\\text{is used to bound worst-case running time}$ （2）Example （3）使用情况 当我们说道“运行时间是O(n)”时，我们指的是最坏情况下的运行时间是O(n) 通常写为：$f(n) = O(g(n))$，而不是$f(n)\\in O(g(n))$——虽然是个集合 我们也在等式中使用$O(n)$，例子： 2n^2+3n +1 = 2n^2 +O(n) $O(1)$表示常数时间 3.1.2 $\\Omega-Notation$ （1）定义 \\Omega(g(n)) = \\{f(n):\\text{There exists positive c and }n_0\\text{ such that } 0\\leq cg(n)\\leq f(n) \\text{ for all }n\\geq n_0\\} 我们使用$\\Omega(.)$来表示运行时间的下界 （2）Example when we say “the running time is $Ω(n^2 )$” we mean that the best-case running time is $Ω(n^2)$ ——the worst case might be worse. 3.1.3 $\\Theta-Notation$ （1）定义 \\Theta(g(n)) = \\{f(n):\\text{There exists positive }c_1，c_2\\text{ and }n_0\\text{ such that } 0\\leq c_1g(n)\\leq f(n)\\leq c_2g(n) \\text{ for all }n\\geq n_0\\} 我们使用$\\Theta-Notation$来表示紧致界 充要条件：$f(n) = Θ(g(n))\\ if\\ and\\ only\\ if\\ f(n) =O(g(n))\\ \\ and\\ \\ f(n) = Ω(g(n))$ （2）Example 3.1.4 总结 （1）表示法 （2）在等式中的使用 使用$O、\\Theta、\\Omega$在函数中替换低阶项简化函数表达 var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"算法/CH4：Recurrences.html":{"url":"算法/CH4：Recurrences.html","title":"CH4：Recurrences","keywords":"","body":"CH4：Recurrences MindMap Review： MergeSort 分析MergeSort的时间复杂度 递归树 Picture of Recursion Tree 迭代法 Telescoping 数学归纳法 Mathematical Induction 渐近分析 $O-Notation$ $\\Omega-Notation$ $\\Theta-Notation$ 算法包含对自身的调用时，其运行时间可以用递归式表示： $MergeSort：T(n) = aT(n/b) +D(n) +C(n) = 2T(n/2) + O(n)$ 3种求解递归函数的方法： 代换法-------------Substitution 递归树法----------Recursion Tree 主方法-------------Master Method 4.1 Substitution Method 代换法 （1）步骤 步骤： 猜测一个解的形式 Guess the form of solution 使用数学归纳法证明 Verify by induction 求解常数项 Solve for constants （2）例子 Example1：$T(n) = 4T(n/2) + 100n$ 猜测：$O(n^3)$（如果要证明$\\Theta$的话，那么要分别证明O和$\\Omega$） 归纳基础：$T(1) = \\Theta(1)$ 归纳假设：$T(k) \\leq ck^3 $在$k 使用数学归纳法证明：$T(n) \\leq cn^3$ 证明： \\begin{aligned} \\mathrm{T}(\\mathrm{n}) &=4 \\mathrm{~T}(\\mathrm{n} / 2)+100 n \\\\ & \\leq 4 \\mathrm{c}(\\mathrm{n} / 2)^{3}+100 n \\\\ &=(\\mathrm{c} / 2) n^{3}+100 n \\\\ &=\\mathrm{cn}^{3}-\\left((\\mathrm{c} / 2) n^{3}-100 n\\right)\\\\ &\\leq\\mathrm{cn}^{3} \\end{aligned} 最后确定c和n的值即可： Example2：$T(n) = 2T(\\lfloor n/2\\rfloor) + n$ 要严格遵守证明的结果的模式，下面的证明是错误的： Example3：尝试变量替换 考虑：$T(n) = 2T(\\sqrt{n}) + lgn$ Rename：$m = lgn\\Rightarrow T(2^m) = 2T(2^{\\frac{m}{2}})+m$ 令$S(m) = T(2^m)$，则有：$S(m) = 2S(m/2) + m$ 设当$m_0\\leq m$时有：$S(m_0)\\leq cm_0lgm_0$ S(m) = 2S(m/2) + m\\\\ \\leq 2c(m/2)lg(m/2) + m\\\\ =cmlg(m/2)+m\\\\=cmlgm-cm + m\\\\ =cmlgm-(c-1)m\\\\=O(mlgm) 转换回来 $T(2^m) = S(m) = O(mlgm)$ $T(m) = O(lgmlgm)$ $T(n) = O(lgnlglgn)$ （3）猜测方法 使用代换法的一个重要技巧是要猜测 猜测的方式： 递归树的方法帮助猜测 与先前见过的相似 先整较松的上届然后缩小区间 降低上届，提高下界，缩小不确定区间 4.2 Recursion-tree Method 递归树是一个好的猜测的直接方法 递归树方法可能不可靠，就像任何使用省略号的方法一样 4.2.1 例子说明 $T(n) = 3T(n/4) + \\Theta(n^2)$ （1）递归树猜测上界 最后一层叶子数：$3^{log_4^n} = n^{log_4^3}$ 每层开销：$((\\frac{3}{16})^icn^2)$ 总开销：$cn^2 + (\\frac{3}{16})cn^2+(\\frac{3}{16})^2cn^2+......+(\\frac{3}{16})^{log_4^n-1}cn^2 + O(n^{log_4^3})=\\frac{1\\times (1-(\\frac{3}{16})^{log_4^n+1})}{1-\\frac{3}{16}}+O(n^{log_4^3})$ 使用等比数列的上界作为上限： cn^2\\sum_{i=0}^{log_4^n-1}(\\frac{3}{16})^i = \\frac{cn^2}{1-\\frac{3}{16}}=\\frac{13}{16}cn^2 所以： T(n) =cn^2 + (\\frac{3}{16})cn^2+(\\frac{3}{16})^2cn^2+......+(\\frac{3}{16})^{log_4^n-1}cn^2 + O(n^{log_4^3})=\\frac{1\\times (1-(\\frac{3}{16})^{log_4^n+1})}{1-\\frac{3}{16}}+O(n^{log_4^3})\\\\ \\leq \\frac{13}{16}cn^2 +O(n^{log_4^3}) = O(n^2) （2）迭代法证明 递归基础：$T(1) = O(1)$ 归纳假设：$T(k) \\leq ck^2，当k 证明：$T(n) \\leq cn^2$ T(n) = 3T(n/4) + d(n^2)\\\\ \\leq 3c(n/4)^2 + d(n^2)\\\\ =\\frac{3}{16}cn^2 + d(n^2)\\\\ \\leq cn^2 当$d\\geq \\frac{16}{13}c$时成立。 4.3 Master Method “cook book” Method for solving recurrences of the form: T(n) = aT(n/b) + f(n)\\\\ 其中a \\geq 1 , b >1 叶子的个数：$a^h = a^{log_b^n} = n^{log_b^a}$ 比较树根$f(n)$和$n^{log_b^a}$ 三种情况： 由根到叶子\\begin{cases}减少\\\\不变\\\\增大\\end{cases} 4.3.1 Compare f(n) with $n^{log_b^a}$ （1）$f(n) = O(n^{log_{b}^{a}-\\epsilon})$ 叶子开销严格大于树根 $f(n)$多项式增长慢于$n^{log_b^a}(by\\ an\\ n^{\\epsilon}\\ factor)$ $Solution:T(n) = \\Theta(n^{log_b^a})$ 注意是$\\Theta$ （2）$f(n) = O(n^{log_{b}^{a}}(lgn)^k)$ 树根开销为叶子开销的$lgn$的$k$次方倍 其中$k\\geq 0$，整数 $Solution:T(n) = \\Theta(n^{log_b^a}lgn^{k+1})$最终结果多乘以一个树高的k次方 （3）$f(n) = O(n^{log_{b}^{a}+\\epsilon})$ 叶子开销小于树根开销 需要额外满足$af(n/b)\\leq cf(n)$ $T(n)=\\Theta(f(n))$树根量级 4.3.2 Conclusion （1）方法总结 树根和叶子比较，同时要注意什么时候写$O$，什么时候写$\\Omega$，什么时候 例题： Example1 T(n) = 9T(n/3) + n $f(n) = n = O(n^{log_b^{a}-\\epsilon})= n^{2-\\epsilon}$，其中$\\epsilon = 1$ 所以$T(n) = \\Theta(n^2)$ Example2 T(n) = T(2n/3) + 1 $f(n) = 1 = \\Theta(n^{log_{\\frac{3}{2}}^1}lg^kn)$，其中$k=1$ 所以$T(n) = \\Theta(lgn)$ Example3 T(n) = 3T(n/4) +nlgn $f(n) = nlgn = \\Omega(n^{log_4^3}+\\epsilon)$，其中$\\epsilon ≈ 0.2$ 且$af(n/b) = 3f(n/4) = 3\\frac{n}{4}lg{\\frac{n}{4}}=\\frac{3n}{4}(lgn-2)\\leq cnlgn$ 当$c = \\frac{3}{4}, n\\geq 1$时成立。 var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"算法/CH6：HeapSort.html":{"url":"算法/CH6：HeapSort.html","title":"CH6：HeapSort","keywords":"","body":"CH6：HeapSort MindMap Topics： Heaps HeapSort Priority queue Recap and Overview 强调稳定性时多关注的是多关键字排序。 插入排序 时间复杂度是$O(n^2)$，原地排序 归并排序 时间复杂度是$O(nlgn)$，需要辅助存储空间 堆排序 时间复杂度是$\\Theta(nlgn)$，原地排序 快排 平均情况的时间复杂度是$O(nlgn)$，原地排序 线性时间的排序 6.1 Heap 6.1.1 堆存储和堆数据结构 （1）堆内存的使用 堆的使用： 内存的分类 \\begin{cases}栈内存：局部变量，方法和函数\\\\ 堆内存：malloc\\ new\\\\ 静态方法区：全局变量\\end{cases} （2）堆数据结构的使用 堆数据结构： 元素按照下标索引——堆数据结构的实现是一个一维数组 每个元素支持：PARENT，LEFT和RIGHT操作 父子关系的映射逻辑为： 若数组下标从1开始，那么父子映射关系函数为： $PARENT(i) = \\lfloor i/2 \\rfloor$ $LEFT(i) = 2i$ $RIGHT(i) = 2i+1$ 若数组下标从0开始，那么父子映射关系函数为： $PARENT(i) = \\lceil i/2 \\rceil -1$ $LEFT(i) = 2i+1$ $RIGHT(i) = 2i+2$ int getParent(int child) { return ceil(child / 2.0) - 1; } int getLeft(int parent) { return parent * 2 + 1; } int getRight(int parent) { return parent * 2 + 2; } 堆中父子的大小关系 \\begin{cases}大顶堆：A[PARENT(i)]\\geq A[i]\\\\ 小顶堆：A[PARENT(i)]\\leq A[i]\\end{cases} 堆中的第一个元素是$A[0]$或者$A[1]$，对应两种不同的情况 结点的高度是从该结点到叶子结点的最长路径。 堆的高度是树根的高度。 叶子结点的高度为0，树根的高度为树的高度。 有n个结点的树的高度为$\\lfloor lgn\\rfloor$ （3）时间复杂度概述 MAX-HEAPIFY：保证堆是一个大顶堆，时间复杂度是$O(lgn)$ Build-Max-Heap：建堆，时间复杂度是$O(n)$ 堆排序：堆排序时，我们首先要建成一个大顶堆，然后反复执行，取下结点后调用MAX-HEAPIFY的过程，时间复杂度是$O(nlgn)$ 6.1.2 堆的建立 建堆两种方式：递归建堆和非递归建堆 （1）递归建堆 递归建堆三个步骤：分、治、合并 分：分解成子树 治：递归处理左子树和右子树 合并：MaxHeapify void buildMaxHeap(int parent, vector& vec) { if (parent （2）非递归建堆 非递归建堆过程采用循环的建堆方式，从最后一个非叶子结点开始，逐步建堆 最后一个非叶子结点的下标：$\\lfloor vec.size()/2\\rfloor$ void buildMaxHeap_iteration(vector& vec) { int last_non_leaf = vec.size() / 2; for (int i = last_non_leaf; i >= 0; i--) { maxHeapify(vec, i); } } （3）合并过程：MAXHEAPIFY MaxHeapify()时间复杂度为$O(h)$，其中$h$是树的高度，$h = \\lfloor lgn \\rfloor $ 递归写法 写成递归处理的形式如下： void maxHeapify(vector& vec, int parent) { int largest = parent; int left = getLeft(parent); int right = getRight(parent); // 找到父子之间最大值的位置 if (left vec[largest]) { // 注意短路判决 largest = left; } if (right vec[largest]) { // 注意短路判决 largest = right; } // 更换位置 if (largest != parent) { int temp = vec[largest]; vec[largest] = vec[parent]; vec[parent] = temp; // 接着maxheapify处理子树 maxHeapify(vec, largest); } } 循环写法 上述的写法是在结束的时候调用递归处理，这种写法很容易改成循环的形式。如下： void maxHeapify(vector& vec, int parent) { int largest = parent; bool ifChange = true; while(ifChange) { int left = getLeft(parent); int right = getRight(parent); // 找到父子之间最大值的位置 if (left vec[largest]) { // 注意短路判决 largest = left; } if (right vec[largest]) { // 注意短路判决 largest = right; } // 更换位置 if (largest != parent) { // 需要交换 int temp = vec[largest]; vec[largest] = vec[parent]; vec[parent] = temp; ifChange = true; }else{ ifChange = false; } } } （4）运行时间分析 若采取直接的方式分析运行时间，那么时间将会是： T(n) = O(n/2)\\times O(lgn) = O(nlgn) **key observation：** T(n) = 2T(n/2) + O(lgn) $f(n) = lgn = O(n^{log_2^2-\\epsilon})=O(n^{1-\\epsilon})$ 所以堆排序的时间复杂度为$\\Theta(n)$ 6.1.3 堆排序 堆排序策略：每次取出堆顶的元素，使用堆中最后一个元素与堆顶元素交换，然后调用MaxHeapify void HeapSort(vector& vec) { int size = vec.size(); // 从0开始的 for (int i = size - 1; i >= 1; i--) { // 从最后一个结点开始 int temp = vec[i]; vec[i] = vec[0]; vec[0] = temp; size = size - 1; maxHeapify(vec, 0, size); } } 时间复杂度：$O(nlgn)$ 原地排序 inplace 不稳定排序 6.2 PriorityQueue 6.2.1 应用 最大值优先队列的应用： 在共享计算机上调度工作 实现优先队列 最小值优先队列应用： 迪杰特斯拉算法 Prim 最小生成树算法 哈夫曼编码 6.2.2 优先队列 操作： 插入一个元素Insert(S, x) 获得最大值MAXIMUM(S) 取出最大值EXTRACT-MAX(S) INCREASE-KEYS(S, x, k) 将位置x的元素正大为key （1）获得最大元素 MAXMUM(A) return A[0]; （2）去除最大元素 先检查溢出 最后一个元素与第一个元素交换 maxHeapify调整 int PriorityQueue::extract_max() { if (vec.size() （3）增大元素 首先判断是否是增大 一直和父亲换，直到父亲的值更大 void PriorityQueue::increase_key(int index, int key) { if (key 0 && vec[parent(index)] （4）插入元素 堆大小加一 将末尾元素设置为无穷小 调用增大元素的函数进行处理 void PriorityQueue::insert(int key) { // 放到最后 vec.push_back(key); // 向上比较调整 increase_key(vec.size()-1, key); } var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"算法/CH7：QuickSort.html":{"url":"算法/CH7：QuickSort.html","title":"CH7：QuickSort","keywords":"","body":"CH7：QuickSort 7.1 Description of QuickSort 7.1.1 Randomized algorithm 随机的应用： QuickSort rand()：产生0~1之间随机数 为什么使用随机？——没有更好的解决方法 7.1.2 快排的概述 分治的结果：分解时做得少，那么合并时就要做的多。反之，分解时做得多，那么合并时做得少。 Divide：利用pivot将数组分为两半，一半比pivot大，一半比pivot小 Conquer：递归求解子数组 Combine：Trival 7.1.2.1 Divide and Conquer （1）QuickSort 主算法：quickSort(A, p, r) 主要做分治，分解问题时做较多的石墙：每次确定pivot的位置 pivot位置确定后，分别递归求解左边和右边的数组 算法为原地排序，不需要合并 void quickSort(vector& vec, int start, int end) { if (start （2）Partition 注意i的初始化 注意各个区间的表示含义： 程序如下： int partition(vector& vec, int start, int end) { // pivot的选择 int pivot = vec[end]; // 选择最后一个元素充当pivot int i = start - 1; for (int j = start; j 有多少个比pivot小的，那么就加几次1 7.1.2.2 快排的分析 假设每个元素是不一样的，现实中，如果有重复的元素，那么有更好的算法存在。 （1）快排的最坏情况 我们假设$T(n)$是最坏情况下的运行时间，那么： 最坏情况发生在pivot是最大或者最小的元素时，此时，问题分解成两个问题，其中一个问题的规模为0，另一个问题的规模为n-1。 一次只会减少规模1. T(n) = T(n-1) + T(0) +\\Theta(n) 递归树如下： （2）快排的最好情况 快排的最好情况发生在每次选取的pivot为中位数时， T(n) = 2T(n/2) +\\Theta(n) 此时，递归树如下： 时间复杂度与归并相同。 （3）1:9情况 假设pivot每次把数组分为1:9的两个数组，那么递归式如下： T(n) = T(9n/10)+T(n/10) +\\Theta(n) 此时的递归树如下： 每次都除以$9/10$，那么树高为$log_{\\frac{10}{9}}^{n}$ 总代价小于$cnlog_{\\frac{10}{9}}^{n}$，所以时间复杂度$T(n) = O(nlgn)$ （4）引入随机的快排 随机选择一个元素作为Pivot。 // 引入随机 int RandomizedPartition(vector& vec, int start, int end) { int p = rand() % (end - start + 1) + start; // 随机选择一个作为pivot int temp = vec[p]; vec[p] = vec[end]; vec[end] = temp; return partition(vec, start, end); } 每次都选到最大或者最小的数的概率为： $\\frac{2}{100}\\times\\frac{2}{99}.......\\times \\frac{2}{2}$ excepted time 为$O(nlgn)$ var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"算法/CH8：Sorting_in_linear_time.html":{"url":"算法/CH8：Sorting_in_linear_time.html","title":"CH8：Sorting in linear time","keywords":"","body":"CH8：Sorting in linear time Comparision Sort 比较排序：在排序的最终结果中，各元素的次序依赖于他们之间的比较。 任何的比较排序最好的最坏情况下经过$\\Omega(nlgn)$次比较，归并，堆排都是最优的。 8.1 排序算法的下界 $Sort$ 判定树：Decision Tree 内部节点：$i：j$标识，满足$1\\leq i,j\\leq n$ 叶子结点为一个排序序列：$$ 算法的执行对应一条从根节点到叶子结点的路径，每个内部节点标识一次比较$a_i\\leq a_j$。 树包含所有可能出现的结果。 上树表示的是直接插入排序的结果。 从根节点到达任意一个可达叶子结点直接的最简单路径的长度：最坏情况下的比较次数。 所有情况：叶子数量为$n$的全排列，即$n!$ h\\geq lg(n!) \\geq lg(n/e)^n\\\\ =nlgn-nlge=\\Omega(nlgn) 归并排序和堆排序是渐进分析框架下的最优比较排序算法。 不可能比$\\Omega(nlgn)$更好 ------------------------------------------>不靠比大小排序，数据具有特殊性 8.2 Counting Sort 计数排序 8.1.1 算法思路 输入：小范围内整数，重复值较多。数据范围为$[1……n]$ 输出：另一个顺序数组$[1...n]$已排序 辅助数组：C[1...k] 算法思想： For x in A, if there are 17 elements less than x in A, then x belongs in output position 18. How if several elements in A have the same value? – Put the 1st in position 18, 2nd in position 19,3rd in position 20,… How if there are 17 elements not greater than x in A? – Put the last one in position 17, the penultimate one in position 16,… 利用数据特殊性，使用k个计数器。 vector countingSort(vector& vec, int k) { // 计数器初始化为全0 vector C(k+1, 0); // 初始化计数器 vector result = vec; // 初始化结果数组 // 统计等于该数的数据数量 for (int i = 1; i = 1; i--) { // 从原数组的最后一个开始向前扫描：保证稳定排序 result[C[vec[i]]] = vec[i]; // 三重嵌套，注意 C[vec[i]]--; // 使用一次减一回 } return result; } 8.1.2 算法分析 （1）时间复杂度分析 该算法如果输入的数据是小范围的，k不超过n，那么时间复杂度为$\\Theta(n)$，最坏情况下也是$\\Theta(n)$ （2）偏移考虑 数组范围： 如果范围是$0……k$，那么计数器C[0]也使用即可 如果范围是$[2……k]$，那么计数器$C[1]$不用 如果范围是$[5000……5100]$，那么计数器所有的$C[vec[i]-偏移量]$ // 给定某个范围，比如5000~5015 void counting_sort2(vector& vec, vector& result, int start, int k) { vector counter(k - start + 1, 0); // 初始化为待排序数组的范围个0：0~k个0 for (int i = 0; i =0; i--) { result[counter[vec[i] - start]-1] = vec[i]; counter[vec[i] - start]--; } print(counter); } （3）扫描顺序 最后一步填入结果数组时，从原数组的最后向前扫描，保证稳定性。 8.3 Radix Sort 基数排序 8.3.1 算法思路 Digit by Digit Sort：按位排序 基数排序：使用辅助数组的稳定排序，首先对最低有效位进行排序 对每一位进行排序时使用的都是稳定排序，最后结果稳定。 RADIX-SORT(A, d) for (int i = 1; i 若位数不固定：采用最大的位数。 counting sort 合适。 8.2.2 时间复杂度分析 时间复杂度为$\\Theta(dO(n))$，其中$d$是一个常数，时间复杂度为$\\Theta(n)$ 8.4 BucketSort 8.4.1 算法思路 数据特殊性表现在：数据均匀分布。每个区间的数出现的概率相等。 （1）步骤 为每一个值分配一个桶 将$A[i]$插入到桶$B[\\lfloor nA[i]\\rfloor]$中，桶范围为$0~n-1$ 映射关系保证，桶n-k内的数一定比桶n-k-r内的数大 对于每一个桶，内部使用直接插入排序 满足均匀分布，数字较少，插入排序可以认为为常数时间 将各个桶合并 常数时间 （2）算法实现 实际实现时桶的数据结构需要考虑用链表数组来实现。首先给出伪代码： #include #include #include #include using namespace std; class LinkNode{ public: double val; LinkNode *next; LinkNode() : val(0), next(nullptr) {}; LinkNode(double x): val(x), next(nullptr) {} LinkNode(int x, LinkNode *next) : val(x), next(next) {} }; void printVec(vector& vec) { for(int i = 0; i& vec, int a, int b, int n) { // 产生a到b之间均匀分布的n个随机数 srand((unsigned int)time(NULL)); for(int i = 0; i & vec, vector& res, int start, int end) { vector linklist_vec; int n = vec.size(); // 处理链表数组的头结点，头结点不放置数据 for(int i = 0; i next != nullptr and head->next->valnext; } // 找到要插入的位置 LinkNode* next_Pointer = head->next; head->next =new LinkNode(vec[i]); head->next->next = next_Pointer; } // 将非空桶中的数据取出，得到最终的顺序 // 扫描并连接链表 for(int i = 0; i next != nullptr) { head = head->next; res.push_back(head->val); } } } int main() { vector vec; int start = 2, end = 5, n = 30; // 准备随机数 random_generation(vec, start, end, n); // 桶排序 vector res; bucket_sort(vec, res, start, end); printVec(res); } 8.4.2 算法分析 算法的时间复杂度为$O(n)$，插入的时间和内部排序的时间都视作常数。 若区间不在0~1之间，那么要进行修改： [0~2]：$B[\\lfloor nA[i]/2\\rfloor]$ [a, b]：B[\\lfloor n(A[i]-a)/(b-a)\\rfloor] 想一下怎么把这个数变到0~1就行了。 8.5 总结 var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"算法/CH9：Medians_and_Order_Statistics.html":{"url":"算法/CH9：Medians_and_Order_Statistics.html","title":"CH9：Medians and Order Statistics","keywords":"","body":"CH9：Medians and Order Statistics MindMap 9.1 Order Statistics 9.1.1 背景介绍 OrderStatistics 排位统计：集合中第i小的元素 中位数：快排中找中位数，代价大 寻找集合中第i小的元素： 最大：i = n 最小：i = 1 中位数 我们可以多快解决这个问题？ 最大或者最小：O(n) 排序：O(nlgn) 下面尝试用O(n)解决 9.1.2 Randomized algorithm for finding the i th element 随机算法 （1）算法思路 算法思路： 利用带有随机的partition算法确定pivot的位置，按照pivot位置和要找的元素的排名对对应的部分进行递归 终止条件：区间长度为1或者是pivot位置就是rank位置 递归找左还是右不要搞错 算法实现： int randomizedSelect(vector& vec, int start, int end, int rank) { if (start == end) return vec[start]; int pivot_index = randomizedPartition(vec, start, end); int pivot_rank = pivot_index - start + 1; if (pivot_rank == rank) { return vec[pivot_index]; } if (rank （2）算法分析 最坏情况下时间复杂度：$T(n) = T(n-1) +\\Theta(n) = \\Theta(n^2)$ 与快排区别，快排是两个子问题。 9.1.3 对于快排的优化 对于快排的时间复杂度，若找中值是线性开销，那么： T(n) = 2T(n/2) + O(n) + O(n) =\\Theta(nlgn) 若找中值是最坏情况： T(n) = 2T(n/2) + O(n) +O(n^2) 线性的找中值： 每5个一组，快速通过直接插入排序找到中值，每组中值的中值作为pivot。 T(n) = T(n/5) + \\Theta(n) + T(7n/10) = \\Theta(n) var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"算法/CH10：Divide_and_Conquer：More_Algorithms.html":{"url":"算法/CH10：Divide_and_Conquer：More_Algorithms.html","title":"CH10：Divide and Conquer：More Algorithms","keywords":"","body":"CH10：Divide and Conquer：More Algorithms 10.1 Square matrix multiplication 矩阵相乘 10.1.1 分治算法 $A = (a{ij})，B = (b{ij})$，都是n×n的矩阵 定义： $C = A\\times B, c{ij} = \\sum{k=1}^{n}a{i,k}b{k,j}$ 矩阵相乘的算法： 分治：partition 矩阵相乘符合标量乘法 矩阵乘法的分治：Square-Matrix-Multiply-Recursive(A,B) T(n) = 8T(n/2) + (\\frac{n}{2})^2\\\\ f(n) = \\Theta(n^2)\\\\ n^{log_2^8} = n^3\\\\ T(n) = O(n^3) 10.1.2 Strassen’s method 10.2 The Maximum - subarray problem 10.2.1 问题背景 要求最低点买入？最高点卖出？ 建模为最和子数组和问题： 10.2.2 暴力解法 暴力解法：穷举所有的子数组——穷举所有的下标可能情况，找出最大值的子数组. 暴力解法程序如下： // 暴力穷举子数组 int maxSum_brute(vector& vec) { int maxSum = -1; int besti = -1, bestj = -1; for (int i = 0; i maxSum) { maxSum = tempSum; besti = i; bestj = j; } } } return maxSum; } 时间复杂度是$O(n^2)$ 10.2.3 分治法 分治法需要额外考虑一个cross的情况：最优解可能是在两个子数组的中间得到。 \\begin{cases}二分\\\\n推n-1\\end{cases} Divide：把数组分成两个数组 Conquer：递归求解子问题，并额外求解跨越中间的情况 Combine：三挑一，找到最大和子数组 算法实现如下： // 分治法，含有cross int getMidMax(vector& vec, int start, int end, int mid) { int maxsum = vec[mid]; int maxNum = vec[mid]; for (int i = mid - 1; i >= start; i--) { maxsum += vec[i]; if (maxsum > maxNum) { maxNum = maxsum; } } maxsum = maxNum; for (int i = mid + 1; i maxNum) { maxNum = maxsum; } } return maxNum; } int maxSum(vector& vec, int start, int end) { if (start == end) return vec[start]; // 分 int mid = (start + end) / 2; // 治 int maxSumLeft = maxSum(vec, start, mid); int maxSumRight = maxSum(vec, mid + 1, end); int maxSumCross = getMidMax(vec, start, end, mid); // 合并 int maxNum = max(maxSumLeft, maxSumRight); maxNum = max(maxNum, maxSumCross); return maxNum; } 时间复杂度：$nlgn$ $T(n) = 2T(n/2) + \\Theta(n)$ $f(n) = n^{log_2^2} = n = \\Theta(nlg^0k)$ var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"算法/CH15：Dynamic_Programming.html":{"url":"算法/CH15：Dynamic_Programming.html","title":"CH15：Dynamic_Programming","keywords":"","body":"CH15：Dynamic Programming MindMap： 动态规划：分治应用在优化问题上 15.1 Optimization Problems 15.1.1 动态规划与DC 动态规划是一种算法设计策略，类似分治。 动态规划是自下而上的计算，而不是自上而下的计算。 bottom up rather than top down 15.1.2 动态规划求解问题的步骤 动态规划的方法有4个步骤： 刻画问题的最优解的结构，如何利用子问题求解父问题【最优子结构找出来】 问题的最优解一定使用子问题的最优解 递归定义最优解的值 区分最优解和最优解的值，动态规划求解问题时通常计算的是最优解的值，而不是最优解 递推式代表的是最优解的值，表示的是怎么用子问题的最优解 按照从下至上的模式求解 递归+备忘录 // 自下而上，计算次序需注意 重构最优解 最优解的值知道了，还需要计算最优解 怎么挑？过程需要保存。 15.2 装配线问题 Assembly Line Scheduling 15.2.1 背景 工厂中有两条平行的装配线，每条线n个站：$S{i,1},S{i,2},...,S_{i,n}$，$i=1,2$ 每个站$S{1,i}$和$S{2,j}$做的事情相同，但可能有不同的装配时间：$a_{i,j}$ 此外若是从装配线$i$到装配线$j$，需要花费传送时间：$t_{i,j}$ 流水线可以混用，切换流水线需要代价 开始时有准备时间$e_i$和最后的离开时间$x_i$ 如何选择调度，才能获得时间上最短的最优解？ 15.2.2 算法分析 （1）分析 对于当前站$S_{1,j}$，选择只有两种： if $j = 1$，那么只有一种 如果$j \\geq 2$，那么： 直接从$S_{1,j-1}$站到达 由$S{2,j-1}$站传递到$S{1,j-1}$ 依赖于最优子结构Optimal substructure：一个问题的最优解一定包含子问题的最优解 （2）递推式 分两个线路写递推式： 站点1： f_{1,j} = \\begin{cases}a_{1,1} + e_1&& if \\ j=1\\\\ min(f_{1,j-1}+a_{1,j}, f_{2,j-1}+t_{2,j-1}+a_{1,j})&& if \\ j\\geq2\\end{cases} 站点2： f_{2,j} = \\begin{cases}a_{2,1} + e_2&& if \\ j=1\\\\ min(f_{2,j-1}+a_{2,j}, f_{1,j-1}+t_{1,j-1}+a_{2,j})&& if \\ j\\geq2\\end{cases} Total Time： $min{f_1[n]+x_1, f_2[n]+x2}$ 15.2.3 算法实现 （1）直接实现 直接按照上述思路，实现程序如下： int fun1(int j) { if (j == 1) { return t1[0] + a1[1]; } return min(fun2(j-1) + t2[j-1] + a1[j], fun1[j-1] + a1[j]); } int fun2(int j) { if (j == 1) { return t2[0] + a2[1]; } return min(fun1(j-1) + t1[j-1] + a2[j], fun2[j-1] + a2[j]); } int main() { int time = min(fun1(n) + t1[j], f2(n) + t2[j]); return 0; } 算法时间复杂度为$T(n) = 2T(n-1) + O(1)$ 含有大量的重复计算的过程，时间复杂度为$O(2^n)$，可以使用备忘录的思路。 （2）自下而上 从1~n计算，非递归 j 1 2 3 4 5 6 f1[j] 9 18 20 24 32 35 f2[j] 12 16 22 25 30 37 $f^* = min(35+3, 37+2)$ 算法实现： 使用数组$L$记录本次选择。 打印站点的选择情况： 栈打印 递归打印 15.3 Matrix Chain Product 15.3.1 问题背景 n个矩阵，每个矩阵维度可能不同，保证能够连乘，求解链乘的最小代价。 代价的定义：使用标量乘法的次数表示代价scalar multiplications $A_1:p\\times q\\quad A_2:q\\times r$ 那么$A_1\\times A_2$的代价为：$p\\times q\\times r$ 非方阵，乘法的计算顺序导致最后的计算量不同。 Order1 15.3.2 求解 15.3.2.1 暴力解法 穷举加括号的方式，多少种加括号方式？ 15.3.2.2 分治 （1）刻画最优解结构 考虑常见的两种分治方法： 二分： 不一定分成中间两半：最优解不一定用到子问题的最优解 n推n-1： 99个知道---->100个：不一定用第99个的最优解 上述两种情况：二分和n推n-1提供的都是子问题的一种可能，需要列举所有的子问题，划分很重要，所有的划分都要列举。 需要列举所有的可能的子问题：n-1个子问题，原问题的最优解一定用的是n-1个子问题中的一个。 子问题如何求解：递归求解。 （2）递归定义最优解的值 最优解：怎么加括号 最优解的值：最小的计算量 首先描述该问题需要左括号位置和右括号位置两个维度，所以该递归式的公共样式必然是一个二维表达式，不妨用𝑚[𝑖,𝑗]表示： 其中𝑖是右括号的位置 𝑗是左括号的位置 𝑚[𝑖,𝑗]为规模为𝑖 ∼ 𝑗的矩阵链乘问题的最小代价值 其次，结合上图的加括号的方式，规模为𝑛时是从𝑛 − 1个子问题中挑选。我们可以推得，对于任意一个规模为𝑖 ∼ 𝑗的问题，其子问题的个数为𝑗 − 𝑖个。 对应的子问题可以描述为𝑖 ∼ 𝑘个矩阵作为子问题计算，𝑘 + 1 ∼ 𝑗个矩阵作为另一个子问题计算，𝑘的取值范围应该满足𝑖 ≤ 𝑘 最后，需要注意父问题的代价不仅仅是两个子问题的最小代价相加，还包括两个子问 题合并的代价，以代价数组的形式描述合并的代价即为：𝑃[𝑖 − 1]𝑃[𝑘]𝑃[𝑗] 递归式： m[i,j] = \\min_{i\\leq k （3）自下而上计算 ①递归算法 终止条件： i==j：开销为0 因为重复计算存在，所以，需要打备忘录 备忘录结果如下： // 递归写法的初始化备忘录 void init_memo(vector>& res, vector& p) { for(int i = 0; i & cost, int start, int end, vector>& choose, vector>& res) { if (res[start][end] != 999999) return res[start][end]; for (int k = start; k new_cost) { res[start][end] = new_cost; choose[start][end] = k; } } return res[start][end]; } ② 自下而上 注意规模： 初始化，矩阵规模为1时，计算量为0；规模为其他时，初始将计算量置为无穷 起始矩阵确定，规模确定，那么末尾矩阵确定 在起始和末尾之间遍历k，选择最小的 程序实现： // 自下而上的求解 int matrix_chain_product_down_top(vector& p, int start, int end, vector>& choose, vector>& res) { for (int l = 2; l = cost) { res[i][j] = cost; choose[i][j] = k; } } } } return res[start][end]; } 时间复杂度是$O(n^3)$ Example： （4）重构最优解 p[i,j] = \"(\" p[i, s[i,j]] p[s[i,j]+1, j] \")\" // 打印加括号的方法 void printBracket(vector> s, int i, int j) { if(i == j){ cout 15.3 动态规划原理 最优子结构 optimal substructure 满足：可用DC---->DP Q： 是否一定用子问题的最优解？怎么用？ 维数 最优解的值：几挑一 15.3.1 Optimal substructure 不一定能应用在所有问题上，有些问题只能穷举：TSP 不满足最优子结构的例子：最长/短简单路径Longest simple path 简单路径：不能绕环 15.4 Longest Common Subsequence 子序列：不一定连续，但是顺序一定 15.4.1 算法分析 暴力求解：首先找到较短串的所有子序列$O(2^m)$，然后在在较长串中比较$O(n)$，总时间复杂度为$O(n2^m)$ 分治： 串变短方式： 二分 n推n-1 串末尾比较 \\begin{cases}末尾相同：最优解一定会用该字母，最终解为子问题最优解 + 1\\\\ 末尾不同：不可能两个字母都用，只有一个可用，挑一个最优的\\end{cases} 递归式： c[i,j] = \\begin{cases}c[i-1,j-1]+1&& x[i]==y[j]\\\\ max(c[i-1,j],c[i,j-1])&& x[i]\\neq y[j]\\end{cases} 边界条件： $j==0或i==0$，某一串为空，那么最长公共子序列长度为0 15.4.2 算法实现 （1）直接实现 时间复杂度较高，重复子问题 // 递归-无备忘录 int LCS_recursive(string& x, string& y, int i, int j) { if (j == -1 || i == -1) { return 0; } if (x[i] == y[j]) return LCS_recursive(x, y, i-1, j-1) + 1; return max(LCS_recursive(x, y, i-1, j), LCS_recursive(x, y, i, j-1)); } （2）递归+备忘录 /** 递归写法，带备忘录 **/ int recursive_LCS_Memoization(string& x, string& y, int i, int j, vector>& res, vector>& s) { if(res[i+1][j+1] != -999999) { // 自己不为空，那么直接返回即可。 return res[i+1][j+1]; } if(x[i] == y[j]) { int num = recursive_LCS_Memoization(x, y, i - 1, j - 1, res, s); res[i+1][j+1] = num + 1; }else{ int num1 = recursive_LCS_Memoization(x, y, i-1, j, res, s); int num2 = recursive_LCS_Memoization(x, y, i, j-1, res, s); res[i+1][j+1] = max(num1, num2); } return res[i+1][j+1]; } /* 备忘录的初始化 */ void init_memoization(vector>& res, string& x, string& y) { // 第0行和第0列初始化为0 for(int i = 0; i （3）自下而上 /** 递归写法，带备忘录 **/ int recursive_LCS_Memoization(string& x, string& y, int i, int j, vector>& res, vector>& s) { if(res[i+1][j+1] != -999999) { // 自己不为空，那么直接返回即可。 return res[i+1][j+1]; } if(x[i] == y[j]) { int num = recursive_LCS_Memoization(x, y, i - 1, j - 1, res, s); res[i+1][j+1] = num + 1; }else{ int num1 = recursive_LCS_Memoization(x, y, i-1, j, res, s); int num2 = recursive_LCS_Memoization(x, y, i, j-1, res, s); res[i+1][j+1] = max(num1, num2); } return res[i+1][j+1]; } /* 备忘录的初始化 */ void init_memoization(vector>& res, string& x, string& y) { // 第0行和第0列初始化为0 for(int i = 0; i void printLongest(vector>& s, string& x, string& y, int i, int j) { if (i == -1 or j == -1) return; string last = s[i][j]; if(last == \"↖\") { printLongest(s, x, y, i-1, j-1); cout 15.5 最大子数组和 漏掉不能递归，是不愿看到的。 改变建模方式：以$a_k$结尾的最大和子数组 $b[j] = max(b[j-1]+a[j], a[j])$ 子问题是不是正数？正数就加 var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"算法/CH16：Greedy_Algorithms.html":{"url":"算法/CH16：Greedy_Algorithms.html","title":"CH16：Greedy_Algorithms","keywords":"","body":"CH16：Greedy Algorithms MindMap： DC---优化--->DP----->Greedy DP：有时overkill Greedy：认准一种 16.1 Activity-Selection Problem 活动集合：$A = {a_1,a_2,...,a_n}$ 不同的活动持续时间不同，开始时间和结束时间：$(s_i,f_i)\\qquad 1\\leq i\\leq n$ 目标：最大不冲突活动集合 \"non-overlapping\" activities Selection \\begin{cases}按结束时间排序√\\\\按开始时间排序？\\end{cases} 16.1.1 例子分析 若穷举：$2^n$种选择 16.1.1.1 分治 （1）二分 $a1,a_2,……,a_k$|$a{k+1},……,a_n$ ​ 3 4 ​ 3+4 ？ 不一定，可能冲突 从合并的角度看，两个子问题不相互独立，可能冲突，无法合并。 （2）n推n-1 与二分问题相同，也可能冲突 （3）cross 需要子问题提供所有的最优解，次优解……规模失控 （4）建模子问题：活动集 s_{ij} = \\{a_k\\in S: f_i\\leq s_k 活动i结束后开始，活动j开始前结束的活动集合。 将活动作为隔离： 使用一个集合$s{0,n+1}$，其中$s_0$的结束时间为0时刻，$s{n+1}$的开始时间为无穷 最终的答案是$S_{0,n+1}$ 使用某一个活动作为隔离， 中间的终止条件：$s_{i,j}$为空，如：a_i的结束比a_j的开始要晚 $A{i,j} = A{i,k}\\cup {ak}\\cup A{k,j}$ 那么，问题的最优解的值可以递归定义为： c[i,j]=\\begin{cases}0&&if\\ S_{i,j}=\\empty\\\\ \\max\\limits_{i 16.1.1.2 Greedy （1）k的挑选 是否真的要挑所有的k？ 冲突的活动不需要作为k进行挑选 问题特殊性：知道k=?时最优？ 最优解中一定包含结束最早的。——不用穷举所有的k，直接找结束时间最早的。 （2）求解实现 递归实现 没有要和j比的，aj的开始时间是无穷大，肯定满足。 迭代实现 按照结束时间排序，进行扫描即可。 时间复杂度为$O(n)$ void iterate_AS(vector acts, vector& res) { sort(acts.begin(), acts.end(), Activity::cmp); res.push_back(acts[0]); int last_act = 0; for (int i = 1; i = acts[last_act].end) { res.push_back(acts[i]); last_act = i; } } } 16.1.2 贪心策略分析 贪心策略何时满足： Greedy Choice property 一个问题的全局最优解能够通过该局部最优解得到 Optimal subtructure 一个问题一定使用子问题的最优解 16.2 Knapsack Problem \\begin{cases}0-1背包：要么拿，要么不拿，穷举2^n种可能性\\\\ 分数背包：拿多少，穷举可能性为无穷大\\end{cases} 最优子结构的判定：是否一定使用子问题的最优解？ 子问题：是否剩下的容量一定用其最大价值？是 ——满足最优子结构，推给子问题。 16.2.1 Fractional Knapsack 无法推给子问题。 最优解一定装满性价比最高的。 16.2.2 0-1 Knapsack Problem （1）分治思路分析 寻找规模压缩的方法 规模\\begin{cases}背包的容量\\\\物品的数量\\end{cases}\\qquad 任何一个减少都是规模压缩 思路： ① 二分容量和物品：经常不对，子问题的情况太多 ② n推n-1 那么推给子问题有两种情况： \\begin{cases}容量全给子问题\\\\容量自己留一部分，剩余部分给子问题\\end{cases} 子问题递归求解 最优解的值：能得到的最大价值： $c[i,j]：前i个物品，背包容量为j$： c[i,j] = max(c[i-1, j], c[i-1,j-w[i]] + v[i]) 对物品的顺序无要求，实际逻辑就是要列举每个物品装入或者不装入 实际上递归比两个for要快，：只会调部分，不是所有的子问题都要计算。 初始的条件：背包容量为空和可选物品为空时，代价均为0 // 0-1背包，递归求解前item_num个物品在背包容量为capacity时的最大价值 // 使用备忘录 double knapstack_dp(vector& items, int item_num, int capacity, vector>& result, vector& choose) { // 查看备忘录 if(result[item_num][capacity] != -99999) { return result[item_num][capacity]; } // 当前物品的重量已经超过背包容量，直接返回给子问题 if(items[item_num-1].weight > capacity) { result[item_num][capacity] = knapstack_dp(items, item_num-1, capacity, result, choose); // 打备忘录 choose[item_num - 1] = false; return knapstack_dp(items, item_num-1, capacity, result, choose); // 返回 } // 否则两个子问题中挑出更优的 double with_now = knapstack_dp(items, item_num - 1, capacity - items[item_num-1].weight, result, choose) + items[item_num-1].value; // 装入当前的物品 double without_now = knapstack_dp(items, item_num - 1, capacity, result, choose); // 不装当前的物品 // 二挑一 if(with_now >= without_now) { result[item_num][capacity] = with_now; choose[item_num - 1] = true; }else{ result[item_num][capacity] = without_now; choose[item_num - 1] = false; } return result[item_num][capacity]; } // 初始化备忘录 void init_memoization(vector>& result, int item_num, int capacity) { for (int i = 0; i & items, int capacity, vector>& result, vector& choose) { init_memoization(result, items.size(), capacity); // 初始化表格 for (int i = 1; i = items[i-1].weight && result[i-1][j - items[i-1].weight] + items[i-1].value > result[i-1][j]) { choose[i-1] = true; result[i][j] = result[i-1][j - items[i-1].weight] + items[i-1].value; }else{ choose[i-1] = false; result[i][j] = result[i-1][j]; } } } return result[items.size()][capacity]; } 16.3 Huffman codes 16.3.1 应用背景 定长编码和变长编码效率不同： 16.3.2 Prefix-free Code 无前缀码，解码结果是唯一的。 哈夫曼编码的求解过程： var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"算法/CH24：Shorest_Path.html":{"url":"算法/CH24：Shorest_Path.html","title":"CH24：Shorest_Path","keywords":"","body":"CH24：Shorest Path MindMap： 24.1 定义 最短路径问题： 最优解：最短路径，怎么走 最优解的值：最短路径的长度 最短路径的权重定义为： 最短路径的权重定义为：\\begin{cases}min(\\{w(p)：\\text{if there is a path p from u to v}\\} \\\\ \\infty\\quad otherwise\\end{cases} 一般使用有向图，无向图视作双向。 最短路径一定满足最优子结构（不可用simple约束） 三角不等式： \\sigma (u,v)\\leq \\sigma(u,x)+\\sigma(x,v) 如果图中包含负权环，那么最短路径可能不存在。 24.2 Single-Source shortest path 单源：源点的位置固定，source固定 每对$\\sigma(u,v)$：每一对结点之间 24.2.1 算法分析 满足最优子结构：一定使用子问题的最优解 二分 k是中间的一个结点，找u->k + k->v，穷举所有的k，挑一个最小的 无法计算：可能存在子问题互相包含。 n推n-1 一样的问题。 计算次序的确定是最短路径的关键。 计算次序是否存在? \\begin{cases}无顺序：人为的增加一个顺序\\\\ 有顺序：尝试，分别做子问题的尝试\\end{cases} 24.2.2 dijkstra算法 （1）思路分析 顺序是否真的不存在？考虑下面的图： 特点：无负权，可能存在计算次序 无负权值的图有特点：越往后走路径只能越长，所以对于从A到其余的点，C离A更近，只可能C是别的问题的子问题，不可能别的问题是C的子问题。于是： 尝试让C当别的问题的子问题 尝试让E当别的问题的子问题 尝试让B充当别的问题的子问题 …… 与前面的DP逻辑的不同： DP：父问题找子问题 现在：子问题找父问题 即dijkstra算法 （2）程序实现 （3）时间复杂度分析 最坏的情况下，每条边都会用来做松弛，时间复杂度为： T(n) = \\Theta(VT_{EXTRACT\\_MIN} +ET_{DECREASE\\_KEY}) Q $T_{EXTRACT_MIN}$ $T_{DECREASE_KEY}$ Total array O(V) O(1) O(v2) Binary Heap O(lgV) O(lgV) O(ElgV) Fibonacci Heap O(lgV) O(1) O(E+VlgV) 24.2.3 其他边权的情况 24.2.3.1 无权图 使用广度优先搜索，堆数据结构换为队列即可。 时间复杂度$Time=O(V+E)$ 24.2.4 Bellman-Ford 如果真的含有负权值边，那么之前的计算次序将不可用，使用Bellman-Ford 其思想在于：若子问题嵌套，那么多使用几次。只要有一条边就拿来尝试更新，但不是只使用一次。 本质：穷举所有的前驱 循环次数：|V|-1 程序实现： 算法实现时，可以为遍历边的次序进行规定。按照次序利用每条边尝试进行松弛。 /*** Bellman-Ford算法 ***/ void Graph::bellman_ford(char s) { int source = s - 'A'; // 源点的下标 vector distance(vexnum, 999999); // 距离数组的初始化 distance[source] = 0; vector pre(vexnum, '@'); int iternum = vexnum - 1; for (int i = 0; i distance[j] + arcList[j][k].weight) { distance[target] = distance[j] + arcList[j][k].weight; pre[target] = j + 'A'; } } } } // 再松弛一次，若有负环则报错 for (int i = 0; i distance[i] + arcList[i][j].weight) { cout 思考，为什么进行n-1轮即可。 一个无负环的图，最短路径的边的最多条数为n-1条，否则会出现环。 不绕环的最短路径，边数最多是n-1 24.3 All-pairs shorest path 所有结点对之间的最短路径： 无负权：跑n遍dijkstra $O(V^2lgV + EVlgV)$ 含负权：跑n遍Bellman-Ford 24.3.1 用边数做约束的DP （1）算法思想 Dynamic Programming 规模变小：边数变少 限制边的数量——n推n-1 定义： d_{ij}^m:从i→j最多过m条边的最短路径 那么有： d_{ij}^0 =\\begin{cases}0&& if \\ i=j\\\\ \\infty&& if\\ i\\neq j\\end{cases} 松弛为： 求 k ---> v的最短路径，过100条边的最短路径，求99条，穷举k d_{ij}^{(m)}=\\min_{k}\\{d_{i,k}^{(m-1)} + a_{k,j}\\} 最终刻画问题为最多过x条边的最短路径。 自上而下：推到m=0时就有答案了。 自下而上：从m=0开始推，m从小到大计算 d_{ij}^0：i到j最多0条边\\rightarrow d_{ij}^1：i到j最多1条边\\rightarrow……d_{ij}^{n-1}：i到j最多n-1条边 无负环，最短路径最多n-1条边。 假设使用迭代的方式： for m = 1~n-1 // 每个m计算一个二维数组 for i = 1~n for j = 1~n for k = 1~n // 所有前驱 需要使用三维数组，逻辑上是一个二维数组 实际的操作没有标m： 计算的过程可能被加速： 无负环： \\sigma(i,j) = d_{ij}^{(n-1)} = d_{ij}^{(n)}=d_{ij}^{(n+1)}…… 故m在工程中可以省略。 负环如何检测？ 再计算一轮未必能检测出来 解决：i=j的场景，检查对角线是否有负值，并将m算到n 将该算法应用到单源点，即为Bellman-Ford算法。 （2）改进：Matrix multiplication 每次使用上一次计算的结果和邻接矩阵计算一个新的矩阵。上述思想的伪代码表示如下： for m = 1 ~ n-1 for i = 1 ~ n for j = 1 ~ n for k = 1 ~ n if d_ij^m >= d_ik^m + a_{k,j} d_ij^m = d_ik^m + a_{k,j} 需要穷举所有的k，所以使用的是结果矩阵的第i行去加上邻接矩阵的第j列。——类似于矩阵相乘的逻辑 C_{ij} = \\min\\{a_{ik}+b_{kj}\\} 24.3.2 用顶点数做约束的DP：Folyed Warshell （1）算法思路 定义： c_{ij}^k表示从i到j最多经过前面k个顶点的最短路径 尝试n推n-1： 过前n个结点 尝试 推给过前n-1个结点，类比0-1背包，那么只有两种情况： c_{ij}^{(k)}\\begin{cases}过第k个顶点：c_{ik}^{(k-1) }+ c_{kj}^{(k-1)}\\\\ 不过第k个顶点：c_{ij}^{(k-1)}\\end{cases} 过0个结点时，$a_{ij}$的权值就是答案 c_{ij}^{(k)} = \\min_k\\{c_{ij}^{(k-1)}, c_{ik}^{(k-1)}+c_{kj}^{(k-1)}\\} 最终过不过第k个结点，比较进行确定。 伪代码： for k = 1 ~ n for i = 1 ~ n for j = 1 ~ n do if cij > cik + ckj // Relaxation then cij = cik + ckj 只用一个数组，和上述的用边约束相同，可能会加速计算，但结果不会出错。 Example： 一个结点都不过：原距离矩阵 过第1个结点 过第2个结点 过第3个结点 （2）负环检测 24.4 Johnson 算法 要是是正权值，那么可以使用dijkstra算法，如何重赋权？ 考虑下面的图，若顶点权值如下，使用$w(u,v)+h(u)-h(v)$得到一个新的权值，为正值： 运行一遍dijkstra，得到的最短路径值做reweighting 选择谁当source 数学性质上任何点都可以成立，但是要用于修改原来的权值 source到每个点的距离不能是无穷大 实际工程上，使用一个不存在的源点source，到任何点的距离为0 使用哪个算法？ Bellman-Ford 算法步骤： Bellman-Ford增加点的情况下跑最短路径值，作为顶点值 重赋权 跑dijkstra var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"算法/CH25：Back-Tracking.html":{"url":"算法/CH25：Back-Tracking.html","title":"CH25：Back-Tracking","keywords":"","body":"CH25：Back-Tracking MindMap： 15.1 Back-Tracking Paradigm 使用场景：无法使用最优子结构 问题特征： 算法使用策略 可以用来解优化问题也可以用来求解可行解 回溯\\begin{cases}寻找可行解\\\\ 寻找最优解\\end{cases} 将问题建模为n元组：$(x_1,x_2,...,x_n)$ 约束条件： \\begin{cases}显式约束：explict变量取值范围\\\\ 隐式约束：inplicit分量与分量之间的关系\\end{cases} 15.2 N-Queens 特征：寻找可行解 15.2.1 问题分析 若采用分治策略： 无法合并，子问题之间并不是相互独立的 n推n-1，仍无法解决子问题不相互独立的问题 求解？ ——暴力穷举【搜索是一种类似于穷举的方式】 每个棋盘8×8个位置不用都尝试，n×n棋盘一定每一行放一个，每一列放一个。 做法： 给行编号，第$i$个棋子放在第$i$行 给列编号，每个棋子做列的选择 候选解即一个8元组：$(x_1,x_2,...,x_8)$，$x_i$是棋子的列号 15.2.2 问题求解 （1）约束条件 显式约束：每个棋子的列号在1~8之间，即$x_i\\in{1,2,3,4,5,6,7,8},1\\leq i\\leq 8$ 隐式约束：棋子不能同行，同列，同斜线，即 x_i\\neq x_j且|x_i-x_j|\\neq |i-j| （2）求解空间树 所有的候选的解：从根到叶子的所有路径 每一个节点：问题解决的目前状态 节点的分类： Alive-Node：孩子节点还未生成完的结点——可能不止一个活结点 E-Node：孩子结点正在生成——只有一个E-结点 Dead-Node：孩子结点已经挑选完，或者人为去除 （3）搜索的DFS和分支限界 DFS 问题的深度优先搜索的过程： DFS：只有当深搜无法向下继续时，才会切换E-节点 分支限界 BFS是分支限界的一种，但分支限界不都是BFS 使用限界函数bound function去认为的标记活结点为死结点，是回溯和暴力搜索的区别。 15.2.3 回溯的一般写法 （1）一般写法 （2）N皇后问题求解 主程序 限界函数 15.3 0-1背包问题 背包类比皇后，背包问题中使用的限界函数为分数背包的思想。 // 回溯法求解背包问题-[迭代] vector knapsack_dfs(int capacity, vector& items, vector& res) { sort(items.begin()+1, items.end(), Item::cmp); int k = 1; int item_num = items.size() - 1; // 去除两个额外的位置 double max_v_w = items[1].v_w; res[0] = 0; // 初始化为0 res[item_num + 1] = 0; vector bestChoice = res; // 初始化什么物品都不装, 下标第一个位置放此时的物品总价值 while (k > 0) { // 回退到第0个物品，不存在第0个物品，终止 res[k] += 1; // 值递增 while (res[k] bestChoice[items.size()]) { bestChoice = res; // 重置最好的值。 } }else{ // 可以继续尝试 k++; res[k] = -1; } } else { // 该结点没有再被尝试的可能，回退 k--; // 做下一步的选择 } } return bestChoice; } 15.4 General Method 15.4.1 Branch & Bound Paradigm （1）D-Search 广搜使用队列 D-Search使用栈 （2）皇后问题使用分支限界 在展开时使用限界函数： 使用队列作为数据结构 分支限界需要把树保留下来。否则变量之间的关系会丢失 （3）分支限界的可优化性 分支限界与回溯的比较 若只找一个解，那么活结点的选择上，无论是回溯还是分支限界，选择活结点的方式过于死板 栈或者是队列都无助于找到answer 使用别的方式：活结点评价函数 利用评价函数选择更好的活结点，结点的代价：cost 以X为树根的树中需要生成多少个结点才能找到answer X离他最近的answer需要切换几次 此时活结点表应该使用堆，这种解法有些事后诸葛亮 （4）LC-Search 对代价进行估计：LC-Search 考虑因素：\\begin{cases}估计代价\\\\根到该结点的深度\\end{cases} g(x)：估计从结点到一个解的代价——引导我们做深度优先搜索 一般孩子结点代价 h(x)：该结点到根的深度 15.5 15-Puzzle 问题空间：16!种可能性 15.5.1 使用DFS或BFS （1）DFS （2）BFS 15迷问题使用回溯是不合适的 15.5.2 LCS 代价定为：有几块没摆好 但要加修正：深度+“估计代价” 未用先验知识： LC-Search的核心：设计c(x) var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"软件体系结构/about.html":{"url":"软件体系结构/about.html","title":"软件体系结构","keywords":"","body":"var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"软件体系结构/CH1：Introduction.html":{"url":"软件体系结构/CH1：Introduction.html","title":"CH1：Introduction","keywords":"","body":"CH1：Introduction Only one Point：软件体系结构的定义 不存在统一的定义 各个流派对软件体系结构的定义 重点关注： Garlan and Shaw对软件体系结构的定义 超越算法和数据结构的计算； 设计和确定系统的总体结构是一个新的课题。 结构问题包括组织和全局控制结构、通信协议、同步和数据访问、将功能分配给设计元素、物理分布 设计元素的构成 扩展和性能，设计方案的选择 概括为 体系结构 = 组件 + 连接件 + 约束 组件：一组代码，也可以是独立的程序 连接件：组件之间的相互关系，过程调用、管道和消息 约束：组件连接时的条件 var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"软件体系结构/CH2：Achitecture_Style.html":{"url":"软件体系结构/CH2：Achitecture_Style.html","title":"CH2：Achitecture_Style","keywords":"","body":"CH2：Achitecture Style MindMap： 2.1 架构风格的定义 不存在统一的定义： 架构风格 Achitecture Style = 一组组件类型 component type / 连接件类型 connector type（交互机制） 组件的拓扑分布 一组对拓扑和行为的约束 一些对风格的代价和益处的非正式描述 如何描述的？重点要看 分类法： 纯粹的体系结构在现实中很难遇到，实际上的系统通常： 经常偏离学术定义 典型的，融合很多的体系风格的特色 作为一个架构师，必须理解“纯”的风格，理解优点和缺点，理解背离这种风格会带来什么结果 没有完备的列表 风格彼此是重叠的 一个系统通常表现出来多种风格 2.2 Data Flow 2.2.1 数据流风格概述 （1）风格 数据流系统： 数据控制计算 the availability of data controls the computation 系统结构由数据在处理之间的有序移动决定 the structure of the design is dominated by orderly motion of data from process to process 数据流系统的结构是显而易见的 纯数据流系统中，处理之间除了数据交换，没有其他的别的交互，变化的是： 如何施加控制——数据的控制方式 pull 拉 消费者角度 push 推 从数据源角度 并行的程度 一条数据流，多条数据流 topology 顺序，循环 （2）Component & Connector & System Component 组件接口是输入端口和输出端口 Interfaces are input ports and output ports Connector：Data Stream 通常是异步的，有缓冲。同步的容易阻塞 System 任意拓扑结构，函数式编程 （3）数据流和控制流 控制流 主要问题是控制点control怎么在程序或者系统之间移动 数据可能跟着控制走，但是并不起到推动系统运转的作用 关注的核心是计算顺序 eg：冯诺依曼结构 数据流 主要问题是数据怎么在运算单元之间流动 数据到了，计算单元便工作 我们关心数据是否可用，转换，延迟 2.2.2 Three Examples of Data Flow 2.2.2.1 Batch Sequential 批处理 （1）图 每一个处理步骤是一个独立的程序，每一步在上一步结束后才能开始，数据必须是完整的，以整体的方式传送。 （2）应用 典型应用： 编译器 case工具 2.2.2.2 Pipe-and-Filter 管道过滤器 （1）图 （2）管道与过滤器 fliter 功能：将数据流作为输入，经过处理后输出 进行流到流的转换： \\begin{cases}丰富数据\\\\精炼数据\\\\转换数据\\end{cases} 数据不再是自包含的 fliter是无状态的计算。没有上下文，状态保存等。 pipe 将数据流从一个过滤器传递到另一个过滤器 数据传送引起动作 （3）优点 隐蔽性，高内聚，低耦合 可支持并发，多个过滤器并发执行 系统容易维护和扩展 （4）缺点 不适合交互性很强的应用——计算过程事先确定 数据传输没有通用标准，每个过滤器需要额外解析和合成数据 （5）数据流与管道过滤器的区别 2.2.2.3 Proccess Control 控制 开环控制 Open loop Control 闭环控制Close Loop Process Control 闭环控制有两种形式：反馈控制和前馈控制 当软件系统的运行受到外部干扰时，需要为软件体系结构考虑一种过程控制范例 2.2.3 选择数据流方式的方针 任务由数据主导 事先知道数据的流向 数据流动带来性能损坏 2.3 Call/Return 2.3.1 风格类型 经典的例子： 主程序和子程序 main program and subroutines 经典编程范式：函数分解 面向对象的抽象数据类型 信息的隐藏 层次化结构 每一层只和他的近邻通信 其他 客户机-服务器 2.3.2 历史过程 主程序（子程序）\\rightarrow 函数模块\\rightarrow ADT\\rightarrow Object\\rightarrow OO架构\\rightarrow Component 2.3.3 Call/Return的具体风格类型 2.3.3.1 Main Program and Subroutine （1）示意图 Problem：适用于通过过程定义层次结构适当定义计算的应用程序 Context：命名空间局部性 Solution： 系统模型：调用和定义层次结构，子系统通常模块化定义 组件：过程和显式可见数据 所有数据对外完全可见 连接器：过程调用和显式数据共享 控制结构：单线程 （2）Pipe Versus Procedures 2.3.3.2 Data Abstaction or Object-Oriented 系统模型：局部化状态保持 组件：对象 连接件：过程调用 控制结构：去中心化，通常是单线程 （1）模块分解 隐藏细节： 数据+策略 隐藏可能改变的细节，接口中公开不太可能改变的假设 （2）封装和信息隐藏 对象有状态和操作，但是也有完整性。 对象被外界知道的是他的接口 对象从模板产生 （3）示意图 对象架构的元素： \\begin{cases}封装：限制信息的访问\\\\交互：过程调用或其他协议\\\\多态：运行时选择具体的操作\\\\继承：对共享的功能保持一致的接口\\\\复用和维护：封装和聚合提高生产力\\end{cases} （4）优缺点 管理大量的对象 对象的海洋需要额外结构容纳 管理很多交互 单一的接口能力有限且笨拙（友元） 分散的行为责任 系统的功能难以理解 捕获关联的设计 类和类型通常是不够的，设计模式是发展 2.3.3.3 Layered system （1）OSI模型的例子 （2）概述 适用问题 包含可以按层次结构安排的不同服务类别 系统模型 不透明的层次结构 构件 各层次内部的构件，过程的集合 连接件 取决于组件的结构;在受限的可见性下，过程调用通常也可能是客户机/服务器 限制 控制结构 单线程 （3）层次风格的特点 每一层为上一层提供服务，使用下一层的服务，只能见到与自己相邻的层 大问题逐渐分解成为若干个渐进的小问题，逐步解决，隐藏了很多复杂度 修改一层，最多影响两层，而通常影响上层，接口稳固，则对谁都不影响 上层必须知道下层的身份，不能调整层次之间的顺序 层层相调，影响性能 2.3.3.4 Client/Server 分类： \\begin{cases}两层CS结构\\\\三层CS结构\\\\BS结构\\end{cases} （1）两层CS 客户机应用程序、数据库服务器、网络 特点：瘦服务器，胖客户机 缺点： 客户端对硬件软件配置要求高，客户机臃肿 升级维护较为困难 数据不安全，客户端可以直接访问服务器数据 信息内容和形式单一 客户端程序编写困难 （2）三层CS 客户机、数据库服务器、应用服务器、网络 特点：瘦客户机 应用功能划分：功能层、表示层、数据层 （3）BS架构 三层CS的特例 客户端使用http浏览器即可，使用http协议，省去了很多麻烦 只能拉，不能推 客户端之间的通信只能通过服务器进行中转 对客户机和其他网络资源的利用受限 客户端资源浪费，服务器压力较大 BS的速度相对于CS慢 2.4 Data Center / Data Sharing 2.4.1 Shared Information System 以数据为中心的体系结构风格概述 2.4.1.1 组件和风格特征 这种风格描述了很多系统，共同特点是共享数据 收集、操作、保存大量的数据 定义：以数据为中心的风格架构涉及到一种共享数据源方法来传递信息。 example： 剪切板 注册表 数据库 优点 系统耦合程度低 方便添加/删除/生产/消费/操纵数据 单个生产者的错误无影响 问题 同步问题——数据发生改变时，控制反转，数据仓库压力大 配置和管理 ACID特性 2.4.1.2 应用场合 早期的数据共享出现在批处理系统 迫切需要数据时即时存取 如今： 应用在各个场景，比如web就是一个巨大的分布式数据库 GitHub 2.4.2 Repository Architecture 2.4.2.1 概述 仓库是共享和维护信息中心的场所 组件： 中心数据结构，表示当前的数据状态 一组对中心数据结构进行操作的独立组件 连接件： 计算单元与中心数据结构之间通过之间数据访问或者过程调用的交互 控制结构： 典型应用场合： 数据库 如，编译器的符号表： 2.4.3 BlackBorad Repository 2.4.3.1 概述 问题： 问题特征： 多种方法可以解决问题，找不到确定的解决思路 求解的每个步骤都有可能产生多个可能的解，寻求最佳或者可接受的解。 需要多个领域的专门知识协作解决 eg： 自然语言处理 语音处理 模式识别 图像处理 如何求解此类问题？——黑板体系结构 一个大问题被分解成若干的子问题 每个子问题的解决需要不同的问题表达方式和求解模型，分别设计求解程序 2.4.3.2 黑板模型 知识元：问题分解成几个部分，每个部分独立计算——知识元对黑板进行修改，逐步找到问题的解 黑板数据结构：全局数据库包含解域的全部状态 控制：完全由黑板的状态驱动，黑板的状态的改变决定使用的特定知识 让知识元响应偶然事件 （1）知识源 目标： 提供解决问题的知识，分别存放且相互独立 动作： 只修改黑板，知识源之间的通讯交互只通过黑板进行 负责： 知道什么时候能发挥作用：“条件-动作”形式 （2）中心数据结构 目标： 保存知识源所需要的数据，保存来自解空间的数据 组织： 解决问题中的状态数据，以层次的形式组织起来 各个知识源只通过黑板进行交互 （3）控制 Control 时刻监控黑板的状态，对黑板上的当前信息进行判断和评价 满足知识源执行条件时，知识源被控制器触发，并进行计算，结果写在黑板上 这种更新又导致其他的知识源参与计算，直到找到问题的解为止 目标： 让知识源响应偶然事件，了解各个知识源的能力，决策解决问题的步骤 2.4.3.3 应用 信号处理、模式处理、模式识别 人工智能 2.5 Virtual Machine Interpreters：模拟不是硬件固有的功能 Rule-Based System：解释器的特例 2.5.1 Interpreter （1）应用问题 应用问题：应用的最佳的执行环境或者语言不能够得到直接的支持。 引入中间层\\begin{cases}应用不能直接支持\\\\环境不适合\\\\跨平台\\end{cases} 无法直接使用最合适的语言或者机器来执行解决方案 核心问题是定义解决方案的符号的应用程序，如脚本 有时以链的形式使用，在一系列阶段的过程中从需要的语言/机器翻译 上下文： 桥接需要的机器和语言与执行环境已经支持的机器（虚拟的）和语言 Solution： 系统模型：一个虚拟机 组件：一个状态机和三个存储 \\begin{cases}状态机：执行的引擎\\\\ 三个存储：\\begin{cases}执行引擎的当前状态\\\\被解释的程序\\\\被解释的程序目前所处的状态\\end{cases}\\end{cases} 连接件：数据访问和过程调用 控制结构：通过引擎状态转移，输入确定选择翻译什么 （2）优缺点 优点 功能性 functionality ：可以模拟非本机功能 测试性 testing ：可以模拟灾难模式（安全攸关的应用） 灵活性 flexibility ：非常通用的工具 缺点 效率：比硬件慢，慢两个数量级；比编译器慢 测试：需要测试额外的中间层 （3）解释器的应用 解释型语言 VB, JS, HTML, Java字节码 通信协议 用户输入 2.5.2 规则系统 （1）问题 根据当前的状态，基于事实，判断我需要的输出 知识库：要被执行的代码 规则引擎：翻译引擎 规则/数据选择：解释器的状态 工作存储：当前代码的状态 （2）理解 对于一个架构，可以从不同的架构去理解 eg：hearsay 2.6 Independent Component 2.6.1 进程间通信 2.6.1.1 背景概述 分布式环境，出现多进程多线程，节点之间相互独立。 已经广泛应用的： 操作系统 分布式应用 2.6.1.2 进程间通信 （1）应用问题 包含一系列不同的，在很大程度上独立的计算的应用程序，这些计算的执行应该独立进行。 计算涉及数据的协调或者对离散的时间点的控制。因此，系统的正确性需要注意消息的路由和同步。 eg：网络游戏的例子 （2）背景 通信策略的选择通常由可用操作系统提供的通信支持决定。 （3）解决方案solution 系统模型：独立交流的进程 组件：向明确接收方发送和接收消息的进程 连接件：离散的消息==（没有共享数据 important）== 控制结构：每个线程都有自己的线程控制 （4）重要变化 确保消息一定收到。 （5）设计需要考虑的问题 图的拓扑结构、失败模型、性能 2.7 事件系统 2.7.1 隐式调用和显式调用 显式调用：明确知道消息的接收者 隐式调用：中间层调用 2.7.1.1 隐式调用 implicit invocation （1）问题 适用于： 松耦合的组件集合应用程序，每个组件执行某些操作，并可能在流程中启用其他操作，通常是响应式系统。 对于必须动态进行，可重新配置的应用程序，该模式是有用的。 上下文： 需要事件处理程序，接收对事件的兴趣，并且在事件引发时通知组件。注册行为 （2）特点 构件不直接调用一个过程，而是触发广播或者多个事件 不能假定构件的处理顺序，甚至不知道哪些构件会被调用 各构件之间彼此无连接关系，相互独立存在 （3）解决方案 solution 系统模型：独立交互式进程 组件：在不知道接收方的情况下发送接收消息的进程 连接件：自动调用已对事件感兴趣的进程 控制：分散，单个组件不知道消息的接收方 （4）应用 Debugger-编辑器和变量监视器登记Debugger断点事件 在编程环境中集成各种工具 数据库管理系统中确保数据的一致性 用户管理界面系统中管理数据 var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"软件体系结构/CH3：UML.html":{"url":"软件体系结构/CH3：UML.html","title":"CH3：UML","keywords":"","body":"CH3：软件体系结构建模和文档化 1.UML 1.1 Use Case 用例图：理解系统功能需求的宝贵工具 用于显示若干的角色与系统提供用例之间的关系，用例是系统的功能 是系统的外部视图，没有与系统内部的类的交互 1.2 Class Diagram 类图：表示类class和类class之间的联系，对系统静态结构的描述 1.3 Object Diagram 对象图：是系统在某一个时间点的对象的快照，表示的是实例instance而不是类，所以也叫Instance diagram 对象图展示对象之间的连接关系，显示连接在一起的对象的示例 1.4 Package Diagram 包图表示的是更高层次的单元： 使用包图可以将相关元素纳入一个系统 1.5 Sequence Diagram 多个对象之间随着时间推移的交互关系 序列图便于展示对象之间的协作。 如果想要看一个use case中的多个对象的行为，那么使用序列图 如果想看一个对象在多个use case中的行为，那么使用状态图 如果想看多个对象在多个线程中的行为，那么使用活动图。 1.6 Communication Diagram ==协作图（通信图）==：描述对象之间的动态协作 协作图（通信图）是一种交互图，强调的是发送和接收消息的对象之间的组织结构。一 个协作图显示了一系列的对象及对象之间的联系以及对象间发送和接收的消息。 强调时间：序列图 强调上下级关系：协作图 交互图\\begin{cases}协作图、通信图：强调上下级关系\\\\序列图：强调时间推移\\end{cases} 1.7 State Diagram 描述类的对象所有可能的状态以及事件发生时的状态的转移条件。通常状态图是对类图的补充。 1.8 Activity Diagram 满足用例要求所要进行的活动以及活动间的约束关系 重点：支持并行行为parallel 1.9 Component Diagram 组件图：描述代码构件的物理结构和各个构件之间的依赖关系 1.10 Deployment Diagram 软硬件的物理结构，硬件节点，软件视图。 1.11 Composite Structures 复合结构：分层地将类分解为内部结构 1.12 Interaction Diagram 交互概述图：活动图和序列图的结合 1.13 Timing Diagram 时序图：交互图的另一种形式，一般针对一个或者多个对象描述。 2. “4+1”视图 逻辑视图：支持行为要求。关键抽象，对象或者对象类 类图 对象图 状态图 协作图 过程视图：解决并发和分发 活动图 开发视图：组织软件 包图 组件图 物理视图：其他元素映射到处理和通信结点 部署图 用例视图（场景）：其他视图映射到重点的用例，帮助用户理解系统功能 var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"软件体系结构/CH4：理解质量属性.html":{"url":"软件体系结构/CH4：理解质量属性.html","title":"CH4：理解质量属性","keywords":"","body":"CH4：理解质量属性 1.质量属性场景的概念 质量属性场景： 源 刺激物 制品 环境 响应 响应衡量 2.六大质量属性 2.1 可用性 Availability 故障，相关后果 定义：在需要是可用的概率，停机不算 α的定义 \\alpha = \\frac{平均无故障时间}{平均无故障时间 + 故障修复时间} failure的特性：可感知的，未达到声称级别的功能即为错误。 可用性的质量属性场景： 源：系统内部或者外部故障迹象 刺激物：系统崩溃，系统错误，给出结果不准时，错误结果 制品：系统处理器，通信信道，存储，进程 环境：正常、亚健康 响应：记录错误日志，传回；通知管理员或者其他系统；关闭系统 响应测量：平均无故障时间，修复时间，故障时间百分比，可用时间百分比 2.2 可修改性 Modifiablity 关注：改什么，谁改，什么时候改，改的代价 质量属性场景 源：谁去修改（开发者，系统管理员，用户） 刺激物：要进行的具体修改 制品：要修改哪一部分的内容：修改系统的功能 or UI 或者其他部分 环境：在什么时间进行修改，设计or开发or运行时间 响应：操作员怎么理解修改，部署，运行 度量：改的时间和成本 2.3 性能 Performance 主要是系统响应事件的花费时间，事件数量，到来形式 质量属性场景 源：可能来自系统外部（可能多个）也可能来自系统内部 刺激物：事件的到达，到达的形式（周期性，随机，偶发） 制品：系统提供的服务 环境：系统处于不同的环境——正常，紧急，超载 响应：==系统必须处理到来的事件，可能导致系统的环境的变化== 响应度量： 处理事件花费的时间 单位时间内处理事件的数量 出错的错误率，丢失率 2.4 安全性 保证正常用户，阻挡非法攻击 安全性的不同类型 不可抵赖性 机密性 完整性 保证性 审计 ==可用性== 质量属性场景 源：攻击可能由人或者其他系统发起；可能先前被识别，或者当前未知。 刺激物 ==对系统的攻击（或者试图破坏系统安全保护）==，常见的形式： 数据 超过权限的服务 影响可用性 制品：系统所提供的服务或系统中的数据 环境：系统可能处于不同的情况下——联网/未联网，在线/下线，在防火墙外/在防火墙内 响应： 合法用户正常使用，拒绝非法用户的使用 对攻击有威慑 度量 发起攻击的难度 从攻击中恢复的难度 2.5 可测试性 软件测试为了发现bug 测试的重要性 测试的质量属性场景 源：测试可能由不同的角色发起（开发者、单元测试人员、集成测试人员、系统管理员、用户……） 刺激物：里程碑 制品：程序，设计，系统 环境：设计阶段、开发阶段、编译时，部署阶段、正常运行时 响应 理想的响应是可以进行测试，并且可以==观察到==测试结果 当测试结果无法被观察到时，测试难度很大 响应的衡量标准 白盒测试的覆盖率 未来继续发现Bug的概率 ==最长测试链的长度== 2.6 易用性 用户希望完成任务有多容易 质量属性场景 源：终端用户 刺激物： 终端用户希望学会使用，提高效率，减少错误 制品：整个系统 环境：运行时或者部署时 响应： 系统响应用户的需求 响应度量 用户完成任务的时间 用户出错的概率 用户满意程度 用户操作的成功率 3.从架构上设计质量属性的策略 3.1 可用性 \\begin{cases}错误检测\\begin{cases}ping/echo\\\\Heartbeats：被监控组件向监控组件发出周期性信号\\\\异常\\end{cases} \\\\错误恢复\\begin{cases}投票机制\\\\主动冗余\\\\被动冗余\\\\内测\\\\检查点/回滚\\end{cases}\\\\错误避免\\begin{cases}事务\\\\关闭服务\\\\进程监控\\end{cases}\\end{cases} 3.2 可修改性 \\begin{cases}局部化修改\\begin{cases}保持语义的高内聚性\\\\考虑未来可能会发生的改变\\\\模块泛化\\\\选项变少\\\\抽象公共服务\\end{cases}\\\\避免连锁反应\\begin{cases}保持已有的接口\\\\使用中间层\\\\信息隐藏\\end{cases}\\\\延迟绑定时间\\begin{cases}运行时注册\\\\配置文件\\\\多态\\end{cases}\\end{cases} 3.3 性能 \\begin{cases}资源需求\\begin{cases}提升计算能力\\\\减少处理的数据数量\\\\管理事件达到的频率\\\\限制采样率\\end{cases}\\\\资源管理\\begin{cases}长任务设置上限执行时间\\\\限制事务队列的长度\\\\利用并发机制\\end{cases}\\\\资源仲裁：使用调度策略\\begin{cases}FIFO\\\\固定优先级\\\\动态优先级\\end{cases}\\end{cases} 3.4 安全性 \\begin{cases}抵御攻击\\begin{cases}用户认证\\\\用户授权\\\\保证数据的机密性\\\\保证数据的完整性\\\\限制访问：防火墙\\end{cases}\\\\攻击检测：入侵检测系统\\\\攻击恢复\\begin{cases}数据备份\\\\攻击者识别\\end{cases}\\end{cases} 3.5 可测试性 \\begin{cases}管理输入输出\\begin{cases}记录/回放，重演\\\\ 接口和实现分离\\end{cases}\\\\ 内部检测：内部监控器\\begin{cases}IDE断点\\end{cases}\\end{cases} 3.6 易用性 \\begin{cases}运行时策略\\begin{cases}保证用户模型\\\\保证系统模型\\\\保证任务模型\\end{cases}\\\\设计时策略\\begin{cases}UI界面与其他分离：MVC\\end{cases}\\\\具体：\\begin{cases}系统给与用户适当反馈\\\\系统猜测用户要完成的任务\\\\系统支持撤销\\\\系统给用户提供一致性体验\\\\用户接口分离\\end{cases}\\end{cases} var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"软件过程与项目管理/about.html":{"url":"软件过程与项目管理/about.html","title":"软件过程与项目管理","keywords":"","body":"var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"软件过程与项目管理/PART1-判断题错误总结.html":{"url":"软件过程与项目管理/PART1-判断题错误总结.html","title":"PART1-判断题错误总结","keywords":"","body":"PART1-判断题错误总结 4.triple contraints ：【scope】【time】【cost】 记住，填空也要答 7.Project managers work with the project sponsors to define success for particular projects. （T） 8.Individual projects always address strategic goals whereas portfolio management addresses tactical goals. （F） 13.The last phase of the traditional project life cycle is the implementation phase。 （F） 18.The level of activity and length of each process group varies for every project （T） 21.Monitoring and controlling processes overlap all of the other project management process groups. （T） 22.Many project management activities occur as part of the planning process group. （T） 24.The Rational Unified Process (RUP) framework is incompatible with the PMBOK process. (F) 25.The kick-off meeting is always held before the business case and project charter are completed. （F） 26.A milestone list is an output associated with the Project Scope Management knowledge area. (F) 28.The burndown chart is a Scrum created artifact that provides a list of features prioritized by business value. （F） 37.Project scope management includes the processes involved in defining and controlling what is or ​ is not included in a project （T） 40.Project scope statements must include the project boundaries, constraints, and assumptions. （F） 44.The scope baseline includes the approved project scope statement and its associated WBS and WBS dictionary （T） 45.The main purpose of the WBS is to define all of the work required to complete a project. （T） 46.A work package represents one component of the product that the project aims to deliver (F) 47.The tasks in a WBS must be developed as a sequential list of steps (F) A unit of work should appear at only one place in the WBS (T) 51.In project schedule management, the primary output of defining activities is a schedule management plan (F) 55.Network diagrams are the preferred technique for showing activity sequencing (T) 56.Start-to-finish relationships are the most frequently used dependencies between activities. (F) 57.In a critical path analysis, the shortest path is what drives the completion date for the project. (F) 58.A backward pass through the network diagram determines the early start and early finish dates for each activity (F) 59.The technique of fast tracking can result in lengthening the project schedule (T) 60.Critical chain scheduling assumes that resources multitask and maximizes multitasking. (F) 61.Overrun is the additional percentage amount by which estimates exceed actual costs. (F) 63.Contingency reserves are also known as unknown unknown （F） 67.The formulas for variances and indexes start with EV, the earn value （T） 68.Project stakeholder management has only been identified as an entire knowledge area by the Project Management Institute since 2013. (T) 75.Unknown risks can be managed proactively （F） 76.Risk events refer to specific, certain events that may occur to the detriment or enhancement of (F) 78.Top Ten Risk Item Tracking is a quantitative risk analysis tool. (F) ​ var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"软件过程与项目管理/PART2-选择题答案整理.html":{"url":"软件过程与项目管理/PART2-选择题答案整理.html","title":"PART2-选择题答案整理","keywords":"","body":"PART2-选择题答案整理 1.易错题 What important Scrum artifact is used to graphically display progress on each sprint during the monitoring and controlling process? a. WBS b. sprint backlog c. burndown chart d. product backlog Answer C What is developed in the Project Integration Management knowledge area? a. schedule management plan b. project management plan c. WBS d. quality management 初始阶段：计划 Which activity is a part of the Scrum planning process? a. Determining how many sprints will compose each release b. Demonstrating the product during a sprint review meeting c. Completing tasks each day during sprints d. Creating sprint backlog The __ is responsible for maximizing return on investment (ROI) by identifying product features, translating these into a prioritized feature list, deciding which should be at the top of the list for the next Sprint, and continually re-prioritizing and refining the list. A) Scrum Master B) Product Owner C) Manager D) Team ANSWER: B Which information is included in a business case业务用例? ​ a. business need for the project ​ b. relevant government or industry standards ​ c. project objective, high-level requirements, and time and cost goals ​ 项目目标、高层次需求、时间和成本目标 ​ d. policies, procedures, guidelines, and systems that influence a project’s success What is the first step in the planning process? A ​ a. tie the information technology strategic plan to the organization’s overall strategic plan ​ b. perform a business area analysis ​ c. start defining potential IT projects in terms of their scope, benefits, and constraints ​ d. choose which projects to do and assigning resources to work on them ANSWER: a Which process includes defining project scope, benefits, and constraints? A ​ a. project planning b. business area analysis ​ c. resource allocation d. information technology strategy planning ANSWER: a Which process involves working with stakeholders to create the document that formally authorizes a project? ​ a. Developing the project charter[项目章程] ​ b. Developing the preliminary project scope statement ​ c. Developing the project management plan ​ d. Performing integrated change control Which technique is used for making cost and schedule trade-offs to obtain the greatest amount of schedule compression for the least incremental cost? ​ a. dependency b. crashing[崩溃！] ​ c. critical chain scheduling d. feeding buffers What term is used for the amount of time an activity can be delayed from its early start without delaying the planned project finish date【不延迟结束时间】? ​ a. total slack b. free float ​ c. backward pass d. forward pass ANSWER: a What term is used for the amount of time an activity can be delayed without delaying the early start date of any immediately following activities【不延迟开始时间】? ​ a. forward pass b. backward pass ​ c. fast tracking d. free slack ANSWER: d Which method is used for determining the estimated annual costs [年度成本]and benefits[和收益] for a project? ​ a. Critical path analysis b. Cash flow analysis 现金流分析 ​ c. Present value analysis d. Requirements analysis ANSWER: b Scope, time and cost goals in order of importance can be ranked on an expectations managementmatrix_. ​ a. requirements traceability matrix b. expectations management matrix ​ c. responsibility assignment matrix d. probability matrix Which process involves numerically estimating the effects of risks on project objectives? ​ a. performing qualitative risk analysis b. planning risk responses ​ c. identifying risks d. performing quantitative risk analysis 2.全部题目 During which phase must project teams address important considerations for managing information (and often end up updating business processes through improved communications)? 在哪个阶段，项目团队必须处理管理信息的重要考虑事项(并且经常通过改进的通信来更新业务流程)? b. execution An example of push communication is _. c. voice mails An example of pull communication is _. d. blogs Which document addresses where the project stands in terms of meeting scope, time, and cost goals? b. status reports Which process involves numerically estimating the effects of risks on project objectives? 哪个过程涉及到用数字估计风险对项目目标的影响? d. performing quantitative risk analysis _ are predefined actions that the project team will take if an identified risk event occurs. c. Contingency plans[应急计划] Which is a fact-finding technique that can be used for collecting information in face-to-face, phone, e-mail, or instant-messaging discussions? interviewing d. interviewing Which document contains results of various risk management processes; it is often displayed in a table or spreadsheet format? a. risk register The _ lists the relative probability of a risk occurring and the relative impact of the risk occurring. ​ c. probability/impact matrix Which diagramming technique is used to help select the best course of action in situations in which future outcomes are uncertain? a. decision tree Which action involves eliminating【消除】 a specific threat, usually by eliminating its causes【原因】? 哪个行动涉及消除特定的威胁，通常是通过消除其原因? ​ a. risk avoidance _ are unplanned responses to risk events used when project teams do not have contingency plans in place. ​ a. Workarounds In project procurement management, which is an output of the planning process? d. make-or-buy decisions A(n) _ is a document used to solicit proposals from prospective suppliers. _是一份用来向潜在供应商征求建议的文件。 c. RFP A document used to solicit quotes or bids from prospective suppliers is known as a(n) _. 用于从潜在供应商征求报价或投标的文件称为 _。 a. RFQ After planning for procurement management, the next process involves __. d. sending appropriate documentation to potential sellers What process involves determining everyone involved in the project or affected by it, and determining the best ways to manage relationships with them? ​ a. identifying stakeholders The main output of which process is the stakeholder register? b. identifying stakeholders Which is true about identifying stakeholders? a. External project stakeholders include the project’s customers. The project team must take corrective action if stakeholders with _ are categorized as resistant or unaware. b. high interest and high power Scope, time and cost goals in order of importance can be ranked on an ___. b. expectations management matrix A(n) _ is a tool used to document, monitor, and track problems that need resolution. d. issue log Which process involves allocating the overall cost estimate to individual work items to establish a baseline for measuring performance? 哪个过程涉及到将总体成本估计分配到单个工作项，以建立测量性能的基线? a. determining the budget Which process results in a cost baseline as a main output? c. cost budgeting Budget - - Base line for measuring performance or cost base line Which process helps develop an accurate projection of a project’s financial expenses and benefits? ​ c. life cycle costing Which method is used for determining the estimated annual costs [年度成本]and benefits[和收益] for a project? b. Cash flow analysis Which statement is true of contingency reserves? a. They allow for future situations that can be partially planned for. Which is most likely to be a reason for inaccuracies in information technology cost estimates? ​ b. People lack estimating experience. What is another term used for budget? d. planned value Which is true of earned value? ​ c. It is an estimate of the value of the physical work actually completed. During which relationship is the “from” activity unable start until the “to” activity is started? ​ a. start-to-start After working with key stakeholders to define activities and calculate their resources, what is the next process in project schedule management? d. estimate the duration of activities. Which provide a standard format for displaying project schedule information by listing project activities and their corresponding start and finish dates in a calendar format? ​ a. Gantt charts Which technique involves network diagramming[网络图] and is used primarily to predict total project duration? b. critical path analysis The critical path is the _ path through a network diagram, and it represents the _ amount of slack or float. b. longest; shortest What term is used for the amount of time an activity can be delayed without delaying the early start date of any immediately following activities【不延迟开始时间】? d. free slack What term is used for the amount of time an activity can be delayed from its early start without delaying the planned project finish date【不延迟结束时间】? ​ a. total slack Which technique involves doing activities in parallel that one would normally do in sequence? ​ c. Fast tracking Which technique is used for making cost and schedule trade-offs to obtain the greatest amount of schedule compression for the least incremental cost? b. crashing How does critical chain scheduling protect tasks on the critical chain from being delayed? b. feeding buffers Which law states that work expands to fill the time allowed? ​ c. Parkinson’s Law Which is a similarity between scope control and schedule control? ​ c. Both are portions【部分】 of the integrated change control process under project integration management. Which term describes a product produced as part of a project? ​ c. deliverable Which statement best describes scope? d. work involved in creating the products and the processes used to create them Which task is at the lowest level of the WBS? d. work package Which is recommended for the creation of a good WBS? ​ b. A unit of work should appear at only one place in the WBS. Which process involves working with stakeholders to create the document that formally authorizes a project? ​ a. Developing the project charter What is the first step in the planning process? a. tie the information technology strategic plan to the organization’s overall strategic plan Which process includes defining project scope, benefits, and constraints? ​ a. project planning What type of analysis involves calculating the expected net【净赚】 monetary gain or loss from a project by discounting all expected future cash inflows and outflows to the present point in time? b. Net present value In a weighted scoring model, what percent must the sum of the weights of all the criteria total? ​ c. 100 Which information is included in a business case业务用例? ​ c. project objective, high-level requirements, and time and cost goals Which section of the project management plan provides the planned cost of deliverables? b. budget The scrum approach originated with agile software development as practitioners looked for ways to .............. A) improve communication B) increase throughput Although Scrum was intended for management of software development projects, it can be used to run software maintenance teams, or as a general project/program management approach. A) True The main roles in Scrum are: A) ScrumMaster B) Product Owner C) Team Scrum eliminates many of the tasks required of a lead because teams become self-organizing. A) True In scrum the team activity is monitored and coordinated on ......... basis. B) daily Scrum is iterative. The iteration is called _ C) sprint The ................. is responsible for maximizing return on investment (ROI) by identifying product features, translating these into a prioritized feature list, deciding which should be at the top of the list for the next Sprint, and continually re-prioritizing and refining the list. B) Product Owner The team in Scrum is seven plus or minus two people. A) True The ScrumMaster and the Product Owner can be the same individual; B) False The first step in Scrum is for the Product Owner to articulate the product vision. Eventually, this evolves into a refined and prioritized list of features called the .......... C) Product Backlog The team meets daily for ...... minutes, where each member of the team discusses the work they’ve completed since the last meeting 15 12)................. are of scrum principles. A) Time-boxes B) Cross-functional teams C) Open communications within team. D) All of above Users & Stakeholders in scrum are Interested in results but not responsible for deliverables. False The organization recognizes that a new project exists and completes a project charter during which processes for a new project? a. initiating What is developed in the Project Integration Management knowledge area? b. project management plan What is the main purpose of project plans? d. guide project execution Which process includes measuring progress toward project objectives and taking corrective action to match progress with the plan? b. Monitoring and controlling Which is true about the agile method? c. It uses several iterations or deliveries of software instead of waiting until the end of the project to provide a product. Which project would be compatible with the use of the agile approach? d. Projects that have more flexible scheduling Which activity is a part of the Scrum planning process? d. Creating sprint backlog In the Scrum method, during which meeting is the improvement of the product and process discussed? a. sprint retrospective A _ is usually not necessary to the Scrum method, because Scrum implies that team members work as a self-directed group【不需要team charter】. a. team charter【团队宪章】 What important Scrum artifact is used to graphically display progress on each sprint during the monitoring and controlling process? c. burndown chart In what type of organizational structure do project managers have the most authority? b. Project In which product life cycle the scope, schedule, and cost are determined early, and changes to scope are carefully managed? C ​ c. Predictive In which development life cycle do stakeholders define and approve the detailed scope before the start on an iteration? ​ a. Adaptive Which observation is true of the agile approach to software development? ​ a. In the agile method, requirements and solutions evolve through collaboration. Which objective is true of projects? ​ b. They have a unique purpose. The role of a _ is to provide direction and funding for a project. ​ a. project sponsor Which knowledge area involves defining and managing all the work【要做什么提前准备好】 required to complete the project successfully? b. Project scope management Which project management knowledge area ensures that the project will satisfy the stated or implied needs for which it was undertaken? d. Project quality management Project procurement management mainly involves: b. buying goods and services for a project from outside the performing organization. An important tool for project scope management is _. d. a work breakdown structure Fast tracking is an example of a tool used in _ management. ​ a. schedule Which organization provides certification as a Project Management Professional? ​ c. PMI var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"软件过程与项目管理/PART3-填空题.html":{"url":"软件过程与项目管理/PART3-填空题.html","title":"PART3-填空题","keywords":"","body":"PART3-填空题易错整理 Agile software development can be used for software development or in any environment in which the requirements are unknown or change quickly. Agile，没有method Sprint planning is part of the basic Scrum framework___ project management process groups_ progress from initiation activities to planning activities, executing activities, monitoring and controlling activities, and closing activities. The ideal outcome of the monitoring and controlling_ process group is to complete a project successfully by delivering the agreed-upon project scope within time, cost, and quality constraints. A(n) _product owner is the person responsible for the business value of the project and for deciding what work to do and in what order when using a Scrum method. A(n) _scrum master is the person who ensures that the team is productive, facilitates the daily Scrum, enables close cooperation across all roles and functions, and removes barriers that prevent the team from being effective. A(n) scrum team development team_ is a cross-functional team of five to nine people who organize themselves and the work to produce the desired results for each sprint. If done well, the Agile approach_ can produce several releases of useful software. _Strategic planning involves determining long-term objectives by analyzing the strengths and weaknesses, studying opportunities and threats, predicting future trends, and projecting the need for new products and services. A(n) _weighted scoring model is a tool that provides a systematic process for selecting projects based on many criteria. A(n) _change control board is a formal group of people responsible for approving or rejecting changes to a project. A(n) rough order of man estimate is done very early in a project or even before a project is officially started. Function Ponits__ are a means of measuring software size based on what the software does for end users. A(n) _cost-baseline_ is a time-phased budget that project managers use to measure and monitor cost performance. _EVM_ is a project performance measurement technique that integrates scope, time, and cost data. The EV_ is the measure of work performed expressed in terms of the budget authorized for that work. artifacts var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"软件过程与项目管理/PART4-简答题.html":{"url":"软件过程与项目管理/PART4-简答题.html","title":"PART4-简答题","keywords":"","body":"1.What are the triple triple constraints? scope、cost 、time 2.What are the 49 Project Management Processes? Using a table. 3.What are 8 project management techniques WBS work breakdown structure CPM critical path method Scrum SAFe Kanban 看板 Gantt Chart PERT Waterfall 4.difference between scrum and waterfall ( at least 5 difference) 方面 Scrum Waterfall release scrum can have multiple releases waterfall has only one release customer scrum keeps customer informed about every stepduring project development Waterfall only contacts customerat the dilivery date changes scrum welcomes changes of requirements at early and latestages of the project Waterfall welcomes changes only at requirement phase and making changesis not allowed at late stage divide Scrum divide work into sprints and then assign work with the team members Waterfall divides work into stages(phases)and process continues one after another advantage srcum works well for difficult and complex projects, in which requiremnets are not entirely clear before development Waterfall model works well with smaller projects in which requirements are clear before development 5.difference project phase and 5 project management process groups. Processes are performed within Phases; and Phases are performed within the Lifecycle 6.Critical path methods, forward and backward pass, find critical path and slack or float of the activity, and find project duration critical path：F-G project duration：13 7.List and describe each of the 10 project management knowledge areas. Integrated management：its function is like the thread in the necklace Scope management：do and only do what should be done Time management：let everything proceed according to the established schedule Cost management：calculate and spend money properly Quality management：the purpose is to meet the demand Human resource management：let team members work with you efficiently Communication management：let the right person convey the right information to the right person at the right time in the right way Risk management：\"look for trouble without trouble\", so as to make the project \"trouble - free\" Procurement management：be Party A Stakeholder management：keep good relationship with the project stakeholders and make them saisfied 8.What are the phases in a traditional project life cycle initiating planning executing closing 9.What are the 4 scrum ceremonies Sprint planning Daily Scrum Sprint Review Sprint Retrospective 10.What is performance reporting? What are some methods used for performance reporting? Performance reporting keeps stakeholders informed about how resources are being used to achieve project objectives • Progress reports describe what the project team has accomplished during a certain period of time • Status reports describe where the project stands at a specific point in time • Forecasts predict future project status and progress based on past information and trends 11.What are the 12 principles behind the Agile Manifesto? satisfy the customer through early and continuous delivery of valuable software Welcome changing requirements, even late in development Deliver working software frequently Business people and developers must work together Build projects around motivated individuals. Give them the environment and support they need, and trust them. The most efficient and effective method of conveying information is face-to-face conversation Working software is the primary measure of progress. The sponsors, developers, and users should be able to maintain a constant pace indefinitely. Continuous attention to technical excellece and good design Simplicity–the art of maximizing the amount of work not done–is essential. The best architectures, requirements, and designs emerge from self-organizing teams. The team reflects on how to become more effective and adjusts its behavior accordingly. 12.What are the 5 stages of the Tuckman model？ Forming Storming Norming Performing Adjourning 13.What are the associated activities and deliverable along Project Process Groups？ var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"保研算法练习AcWing训练/about.html":{"url":"保研算法练习AcWing训练/about.html","title":"保研算法练习AcWing训练","keywords":"","body":"var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"保研算法练习AcWing训练/基础算法.html":{"url":"保研算法练习AcWing训练/基础算法.html","title":"基础算法","keywords":"","body":"CH1：基础算法 1.1 排序 包含两个典型的排序算法 \\begin{cases}归并排序\\\\快速排序\\end{cases} 程序实现如下： // // Created by BlancheSun on 2022/8/4. // #include #include using namespace std; // 工具函数 void printVec(vector& vec); // 归并排序 void MergeSort(vector& vec, int start, int end); void Merge(vector& vec, int start, int mid, int end); // 快速排序 void quickSort(vector& vec, int start, int end); int partition(vector& vec, int start, int end); int main() { // 归并排序 vector vec = {1,6,4,9,10,2,-1,6,5,8,7}; MergeSort(vec, 0, vec.size()-1); printVec(vec); // 快速排序 vector vec2 = vec; quickSort(vec2, 0, vec2.size()-1); printVec(vec2); return 0; } // 归并排序 void MergeSort(vector& vec, int start, int end) { if(start & vec, int start, int mid, int end) { // 拷贝初始化 vector vec1(vec.begin()+start, vec.begin()+mid+1); vector vec2(vec.begin()+mid+1, vec.begin()+end+1); // 末尾置一无穷大值，方便扫尾 int infty = 999999; vec1.push_back(infty); vec2.push_back(infty); // merge的核心过程 int i = 0, j = 0, k = start; while(k & vec) { for (int i = 0; i & vec, int start, int end) { if (start & vec, int start, int end) { int pivot = vec[end]; int i = start - 1, j = start; while (j 1.1.1 归并排序 分、治、合并三个步骤，重点在于合并的步骤； 合并步骤采取的方法是使用两个临时数组，存储目前已经有序的两段，将这两段通过双指针的形式扫描后合并。 特别的合并时可以在两个临时数组末尾各插入一个无穷大的数字，这样扫尾只需要一个循环即可。 否则还需要额外的循环做扫尾工作：两个for，检验i和j是否有未到某尾的，将其直接续接即可。 1.1.2 快速排序 英语描述快排思想： 快排算法是基于分治思想的一种算法，包括基本的分、治、合并三个步骤。 与归并排序不同，快排的核心在于分解的过程。在算法中具体体现在partition的部分。paritition的过程本质是选择一个数，让数组以这个数所在的位置为界，左侧的数据小于该数字，右侧的数大于该数字。实现时常采用两个指针扫描的方式不断交换下标所在的数字来实现。“治”的步骤则是对数组中以该数分成的两段分别递归处理。算法不需要进行合并步骤。 Fast sort is a kind of algorithm based on divide and conquer idea, including three basic steps: divide, conquer and merge. Unlike merge sort, the key of quick sort is the devide step. The algorithm is embodied in the 'partition' part. The essence of the process of 'paritition' is to select a number, so that the array is bounded by the position of the number, the data on the left is less than the number, and the number on the right is greater than the number. The implementation often uses two pointer scanning method to constantly exchange the number of the subscript to achieve. The \"conquer\" step is to recursively process the two segments of the array divided by that number. The algorithm does not require a merge step. 快排的partition是核心，partition的实现方法有很多种： 暴力解法：辅助数组a[],b[]分别存储小于等于pivot和大于pivot的数 分别存储完毕后，将a[],b[]中的数字分别赋值给vector 这样求解需要额外的存储空间，但是时间复杂度上还是O(n) 常见解法：使用两个指针i,j，分别置于数组开始位置和末尾位置，向中间扫描 若出现vec[i]>pivot && vec[j]，那么交换vec[i]和vec[j]对应的数据 优雅解法 int partition(vector& vec, int start, int end) { int pivot = vec[end]; int i = start - 1, j = start; while (j 1.2 二分 \\begin{cases}整数二分\\\\浮点数二分\\end{cases} 二分的循环结束条件：r ，长度为1时循环结束； 性质一定是有边界的。通过性质判断有无解 1.2.1 整数二分 二分和单调性的关系：有单调性一定可以二分，没有单调性可能也可以使用二分。 二分的本质： 寻找区间边界 寻找两个区间的端点（绿色点和红色点）对应两个不同的算法模板： 1.2.1.1 二分下界：红色点 $mid = \\frac{l+r+1}{2}$ check函数检验是否满足红色部分的性质 if(check(mid))\\begin{cases}true：答案区间[mid, \\ r],l=mid\\\\ false：答案区间[l, mid-1],r=mid-1\\end{cases} 1.2.1.2 二分上界：绿色点 $mid = \\frac{l+r}{2}$ check函数检验是否满足绿色部分的性质 if(check(mid))\\begin{cases}true：答案区间[l, \\ mid]，\\ r=mid\\\\ false：答案区间[mid+1, r]，\\ l=mid+1\\end{cases} 1.2.1.3 具体应用 如在数组1 1 2 2 3 3 4中求解3的起始下标和终止下标 #include #include using namespace std; int main() { vector vec = {1, 1, 2, 2, 3, 3, 4}; int l = 0, r = vec.size()-1; int target = 3; // 寻找下界 while (l > 1; if (vec[mid] >= target) { r = mid; }else{ l = mid + 1; } } if (vec[l] != target) cout > 1; if (vec[mid] 1.2.2 浮点数二分 浮点数二分不需要处理边界，比如(r-l) ； 和整数二分一样，需要保证的是一定在区间内。 1.2.2.1 平方根的例子 浮点数二分，找到一个数的1/2的值，保证其精度为precision void floatBinarySearch(double x, double precision) { double l = 0, r = x; while (r - l > precision) { double mid = (l + r) / 2; if (mid * mid >= x) r = mid; else l = mid; } printf(\"%lf\\n\", l); } 习题练习 Day1 这里没有对应AcWing上习题练习，而是去力扣找了对应的题进行练习： 快速排序 剑指 Offer II 076. 数组中的第 k 大的数字 - 力扣（LeetCode） 剑指 Offer 40. 最小的k个数 - 力扣（LeetCode） 归并排序 剑指 Offer II 078. 合并排序链表 - 力扣（LeetCode） 剑指 Offer II 074. 合并区间 - 力扣（LeetCode） 剑指 Offer 51. 数组中的逆序对 - 力扣（LeetCode） 二分 34. 在排序数组中查找元素的第一个和最后一个位置 - 力扣（LeetCode） 69. x 的平方根 - 力扣（LeetCode） // // Created by 孙蕴琦 on 2022/8/8 // 寻找乱序数组中第k大/小的数 // #include #include #include using namespace std; // 前k小的数 int randomizedPartition(vector&vec, int start, int end); int partition(vector& vec, int start, int end); int randomizedSelect(vector& vec, int start, int end, int k); // 逆序数 void Merge(vector& vec, int start, int mid, int end, int& count); void MergeSort(vector& vec, int start, int end, int& count); /****** partition算法的应用 ******/ class Solution { public: vector getLeastNumbers(vector& arr, int k) { vector res(0); if (k == 0) return res; int kIndex = randomizedSelect(arr, 0, arr.size()-1, k); for (int i = 0; i & nums) { int count = 0; MergeSort(nums, 0, nums.size()-1, count); return count; } }; /*** 二分：算术平方根 ***/ class Solution3 { public: int mySqrt(int x) { double l = 0, r = x; while (r - l >= 1e-6) { double mid = (r + l) / 2; if (mid * mid >= x) { r = mid; }else{ l = mid; } } return r; } }; class Solution4 { public: vector searchRange(vector& nums, int target) { vector res(0); int l = 0, r = nums.size() - 1; while (l > 1; if (nums[mid] >= target) { r = mid; }else{ l = mid + 1; } } if ( r> 1; if (nums[mid] nums = {1, 3, 2, 3, 1, 1}; // Solution2 s; // cout nums = {5,7,7,8,8,10}; int target = 8; vector res = s.searchRange(nums, target); cout & vec, int start, int end, int& count) { if (start & vec, int start, int mid, int end, int& count) { vector vec1(vec.begin() + start, vec.begin() + mid + 1); vector vec2(vec.begin()+ mid + 1, vec.begin() + end + 1); vec1.push_back(65536); vec2.push_back(65536); int k = start, i = 0, j = 0; while (k & vec, int start, int end) { int pivot = vec[end]; int i = start - 1, j = start; while (j &vec, int start, int end) { int pivot_index = rand() % (end - start + 1) + start; swap(vec[pivot_index], vec[end]); return partition(vec, start, end); } int randomizedSelect(vector& vec, int start, int end, int targetRank) { if (start == end) return start; int pivot_index = randomizedPartition(vec, start, end); int k = pivot_index - start + 1; if (k == targetRank) { return pivot_index; }else if (targetRank 1.3 高精度 C++考虑高精度，Java有大整数类，Python默认数的范围是无穷大 高精度考察的类型： 大整数相加 A和B的位数大概是10^6 大整数相减 A和B的位数大概是10^6 大整数乘以一个小整数 $len(A)\\leq 10^6,a\\leq10^9$ 一个大整数除以一个小整数 【不常用】：大整数相除，大整数相乘 1.3.1 大整数的存储和计算 1.3.1.1 存储 将大整数的每个位存在数组里面去 存储：个位放在数组的第一个元素，原因是考虑到高位的进位，数据结构是数组时方便在末尾加上进位数。 1.3.1.2 列竖式计算 加法的列竖式 计算公式：$A_i+B_i+t=C_i$，其中$t$代表进位，值为0或者1。 减法的列竖式 A_i-B_i-t=\\begin{cases}A_i-B_i-t,A_i-B_i-t\\geq 0\\\\ A_i-B_i+10-t,A_i-B_i-t\\leq 0\\end{cases} 乘法的列竖式 A2 A1 A0 * b —————————————— C2 C1 C0 \\begin{cases}t_0=0\\\\ C_0 = (3 \\times b +t_0) \\%10, t_1 = (3\\times b +t_0)/10\\\\ ...\\\\ C_i = (A_i \\times b + t_i)\\% 10,t_i = (A_i\\times b+t_{i})/10\\end{cases} 除法 1.3.2 高精度模板 1.3.2.1 高精度加法模板 class Solution { public: string addStrings(string num1, string num2) { vector Num1, Num2, Num3; // 字符串放入数组中： for (int i = num1.size() - 1; i >= 0 ; --i) { Num1.push_back(num1[i] - '0'); // 转换为数字放入数组中 } for (int i = num2.size() - 1; i >= 0 ; --i) { Num2.push_back(num2[i] - '0'); // 转换为数字放入数组中 } // 从数组第一位往后加 int t = 0; for (int i = 0; i = 0; --i) { num3 += Num3[i] + '0'; } return num3; } }; 1.3.2.2 高精度减法模板 步骤： 判断：若$A\\geq B$，那么正常计算，否则交换A和B，计算B-A A_i-B_i-t=\\begin{cases}A_i-B_i-t,A_i-B_i-t\\geq 0\\\\ A_i-B_i+10-t,A_i-B_i-t\\leq 0\\end{cases} 根据是否$A\\geq B$输出时考虑负号 // 高精度减法 // 判断是否有 A>=B bool cmp(vector& A, vector& B) { if (A.size() != B.size()) return A.size() > B.size(); // 否则长度不相等，从最高位开始判断 for (int i = A.size() - 1; i >= 0; --i) { if (A[i] != B[i]) return A[i] > B[i]; } return true; } vector gaoJingDuMinus(vector& A, vector& B) { vector C; int t = 0; for (int i = 0; i 1 && C.back() == 0) C.pop_back(); // 避免出现003的情况 return C; } string sub(string& a, string& b) { // 将字符串形式的数据存储在数组中 vector A, B, C; // 存储时数组的最低位存储数据的个位，以方便最高位的进位 for (int i = a.size() - 1; i >= 0; --i) { A.push_back(a[i] - '0'); // 减去偏移量得到数值 } for (int i = b.size() - 1; i >= 0 ; --i) { B.push_back(b[i] - '0'); // 减去偏移量得到数值 } // 首先要判断A B哪个大，返回的数组C是逆序的，即数组的第一位是个位 string c; if (cmp(A, B)) C = gaoJingDuMinus(A, B); else { C = gaoJingDuMinus(B, A); c.push_back('-'); // 结果应该是负数，添加一个符号 } for (int i = C.size()-1; i >= 0; --i) { c += C[i] + '0'; } return c; } 1.3.2.3 高精度乘法模板 vector mul(vector &A, int b) { vector C; int t = 0; for (int i = 0; i 1.3.2.4 高精度除法模板 // 高精度除法 A/b，商是C，余数是r A若正存储的话比较方便，此处为了一致，仍然采取最低为 vector div(vector& A, int b, int& r) { vector C; for (int i = A.size() - 1; i >= 0; ++i) { C.push_back((r * 10 + A[i]) / b); r = (r * 10 + A[i]) % b; } // 和A保持低位高位一样，所以reverse一下，其实不reverse的结果就是我们要输出的数据 reverse(C.begin(), C.end()); // 去除前导0 while (C.size() > 1 && C.back() == 0) C.pop_back(); return C; } 1.4 前缀和与差分 1.4.1 前缀和的概念与应用 1.4.1.1 一维前缀和 前缀和$S[i]$：数组中的前i个数的和 $a_1+a_2+...+a_3$ 两个问题： 如何求$S[i]$？：for循环一遍即可$S[i] = S[i-1] + a[i]$ 前缀和有什么作用：快速求出来原数组中一段数的和$[l,r]$的数和——$S[r]-S[l-1]$ 即用一次计算计算出任意一段的和 1.4.1.2 二维前缀和 主要是公式的推导，尝试题目： 剑指 Offer II 013. 二维子矩阵的和 题解 - 力扣（LeetCode） 304. 二维区域和检索 - 矩阵不可变 - 力扣（LeetCode） 注意多减的要加回来。 1.4.2 模板 #include #include using namespace std; int main() { int n, m; vector vec, S; vec.push_back(0); scanf(\"%d%d\", &n, &m); for (int i = 1; i 1.4.3 差分 差分是前缀和的逆过程。设有数组A，要求构造出一个数组B，使得数组A的元素$A[i]$是$B[1]，B[2],...,B[i]$的前缀和。 b称为A的差分，A是b的前缀和 所以对A求一遍差分可以得到数组b，对B求一遍前缀和得到数组A 时间复杂度都是$O(n)$ 1.4.3.1 差分数组的构造 输入数组A[i]:A[1],A[2],...,A[i]，构造其差分数组的步骤： 初始化b[i]为全0 插入A[i]等价于操作： b[i] = b[i] + A[i]; b[i+1] = b[i+1] - A[i] 每输入一个A[i]，进行一次B数组的对应操作 输入完成，A的差分数组构造完成 1.4.3.2 差分的应用 构造原始的数组b[i] 对于在区间[l, c]中每个数加上c等价于操作： b[l] += c b[c+1] -= c 对数组B求一次前缀和得到最终的序列 1.4.4 模板 #include #include using namespace std; // 注意书写前缀和和差分的代码时，数组下标从1开始存 int main() { int n, m; scanf(\"%d%d\", &n, &m); vector nums(n+1), res(n+2,0); // 在输入的同时构造差分数组 for (int i = 1; i 习题练习 Day2 对应力扣题目： 高精度 415. 字符串相加 - 力扣（LeetCode） 306. 累加数 - 力扣（LeetCode） 43. 字符串相乘 - 力扣（LeetCode） 前缀和 303. 区域和检索 - 数组不可变 - 力扣（LeetCode） 437. 路径总和 III - 力扣（LeetCode） 剑指 Offer II 013. 二维子矩阵的和 题解 - 力扣（LeetCode） 304. 二维区域和检索 - 矩阵不可变 - 力扣（LeetCode） 差分 1109. 航班预订统计 - 力扣（LeetCode） 1526. 形成目标数组的子数组最少增加次数 - 力扣（LeetCode） var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"计网复习笔记/about.html":{"url":"计网复习笔记/about.html","title":"计算机通信与网络保研复习","keywords":"","body":"针对哈深的笔试题复习，每章结束会列出相关章节的常见面试题 var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"计网复习笔记/补充：常见协议的上下层协议.html":{"url":"计网复习笔记/补充：常见协议的上下层协议.html","title":"补充：上下层协议","keywords":"","body":"ARP封装在以太网帧中 RARP封装在以太网帧中 BOOTP封装在UDP中 RIP封装在UDP中 SNMP封装在UDP中 TELNET封装在TCP中 var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"计网复习笔记/数据链路层.html":{"url":"计网复习笔记/数据链路层.html","title":"数据链路层","keywords":"","body":"数据链路层 [TOC] 按照IEEE标准，数据链路层可以被分为两个子层： 数据链路层\\begin{cases}逻辑链路层LLC\\begin{cases}成帧\\\\流量控制\\\\差错控制\\end{cases}\\\\ 介质访问控制层MAC\\end{cases} 1. 差错控制 1.1 差错控制简介 1.1.1 错误的类型 single-bit error：在给定的数据单元，仅有一位发生从0到1或者1到0的变化。 burst error：数据单元中有两位或者更多位发生1到0或者0到1的错误。 burst error并不意味这差错在连续位上出现 The length of burst error is measured from the first corrupted bit to the last corrupted bit 1.1.2 错误检测和纠正 Detection：只看差错是否发生，只回答是否。 Correction：知道破坏位的个数，在报文中的位置 纠错方法：向前纠错，重传 1.2 块编码 1.2.1 数据字和码字 datawords：在块编码中，把报文划分成块，每块有 k 位，称为数据字datawords codewords：并增加 r个冗余位使其长度变为 n = k + r，形成 n 位的块称为码字codewords invaild or illegal：$2^n-2^k$冗余码 1.2.2 错误检测的条件 可以进行差错检测的条件： 接收方有有效码字的列表 原来的码字变成无效的码字 如果码字在传输中被破坏，但接收到的码字仍然是一个有效的码字，差错则无法被检测到。 1.2.3 汉明距离 Hamming distance between two words $d(x,y)$：两个相同长度的字的汉明距离是对应位不同的数量。 计算：对两个字异或后计算1的个数 d(000,011)=2;d(000,101) = 2 1.2.4 最小汉明距离 minimum hamming distance：一组字中所有可能对的汉明距离的最小值。 1.2.4.1 编码方案的表示 datawords 长度 ： k codewords 长度：n minimum hamming distance ：$d_{min}$ 编码方案写成$C(n,k)$和一个单独的$d{min}$表达式。如上的编码方案可以写成：$C(5,2),d{min} = 3$ 1.2.4.2 汉明距离和错误 检测出s个错误，那么汉明距离满足：$d_{min}=s+1$ 纠正s个错误，那么汉明距离满足：$d_{min} = 2s+1$ 1.3 线性块编码 1.3.1 线性块编码的特点 两个有效码字异或后得到另一个有效码字 线型块编码的最小汉明距离：具有最小1的个数的非0有效码字中1的个数 1.3.2 线性编码 1.3.2.1 简单奇偶校验码 基本思路：n = k+1。冗余位使codewords中的1的个数为偶数。 最小汉明距离$d_{min} = 2$ simple parity check codes单个位检错编码，不能纠正任何差错 1.3.2.2 二维奇偶校验 数据以表格形式组织，分别放在各自的行中。 对于每一行和每一列，计算出一个奇偶校验位。 two dimensional parity check可以检测出表中任意位置发生的三个差错。 1.3.2.3 汉明编码 只讨论最小汉明距离为 $d_{min} = 3$ 的汉明码，它最多能检测出 2 位差错和最多纠正 1 位差错。 当$d_{min} = 3$时，m和n的关系：$n = 2^m - 1$ 汉明码要求： \\begin{cases} m = r>=3\\\\ k = n -m\\\\ n = 2^m-1 \\end{cases} s在正确情况下一定是0，三个校正子异或得结果 注意接收方和发送方要使用相同的等式。 生成器不关心奇偶位($q_0,q_1,...,q_n$)的错误和无差错。其他情况相应的位必须要反转，但是若出现2位错误反转后也未必正确。 1.4 循环码 1.4.1 循环校验 数据位，码字和除数等位数关系 数据位：k位 码字：n位 被除数补充：n-k位 除数：n-k+1位 1.4.2 循环码分析 一些表示： 数据字d(x)\\quad 码字c(x)\\quad 生成多项式g(x)\\\\ 校正子s(x)\\quad 差错e(x) $s(x)≠0$：一位或者多位被破坏 $s(x)=0$： 没有被破坏 某些位破坏但检测不出来 接收到的码字：$c(x)+e(x)$===初始发送的码字+错误项 \\frac{接收到的码字}{g(x)} = \\frac{c(x)+e(x)}{g(x)} = \\frac{c(x)}{g(x)}+\\frac{e(x)}{g(x)} = \\frac{e(x)}{g(x)} Single bit error 单个位差错： e(x)=x^i\\\\ \\frac{e(x)}{g(x)} = \\frac{x^i}{g(x)} 若g(x)有两项（一般来说），$x^0$项系数不为0，那么不能除尽，可以检错 1.5 校验和 用校验和进行简单检错的方法常用于Internet的其它高层协议中。 发送数据时，同时还发送它们的和（用于检错校验，因此称为校验和）。 校验和的步骤：【发送方】 报文被划分为16-bit 字。 校验和字的初始值设为0。 所有字包括校验和使用反码运算相加。 对累加和求反码变成校验和。 校验和随数据一起发送。 2. 成帧 成帧：添加发送方地址和接收方地址，成帧将一条从源端到目的端的报文分开来，或者将不同目的端的报文分开来 2.1 固定长度成帧 不需要定义帧的边界，长度本身就是限制。 2.2 可变长度成帧 帧的开始和帧的结束要加上分隔符。 方式\\begin{cases}面向字符\\\\面向位\\end{cases} 2.2.1 面向字符的协议 \\begin{cases}flag：标志位，分隔这一帧和下一帧\\\\ Header：源地址和目的地址\\\\ Tailer：检错或者纠错冗余位\\end{cases} 2.2.2 面向字的协议 需要分隔符：01111110作为分隔符，标志帧的开始和结束 位填充bit-stuffing：遇到1个0和连续5个1时，便增加一个0，不管后面的那个位是什么。额外的位被接收方移走。 3. 流量和错误控制 数据链路控制\\begin{cases}成帧\\\\流量控制\\\\差错控制\\end{cases} 3.1 协议 协议\\begin{cases}无噪声通道\\begin{cases}最简单协议\\\\停止等待协议\\end{cases}\\\\噪声通道\\begin{cases}停止等待ARQ\\\\回退N帧ARQ\\\\选择性重发ARQ\\end{cases}\\end{cases} 3.1.1 无噪声通道 假设不会丢失帧，复制帧，或者损坏帧。 最简单协议不使用流量控制，Stop and Wait使用流量控制。 但是都不使用差错控制，因为是完美通道。 3.1.1.1 最简单协议 没有差错控制和流量控制。假设接收方能及时处理所有接收到的帧，不会超载。 两个驱动事件： 对发送方来说：触发事件为来自网络层的报文 对接收方来说：触发事件来自物理层 3.1.1.2 停止等待协议 如果接收方的数据帧的到达速度大于能被处理的速度，那么帧在使用前必须被存储。为避免接收方超负荷，让发送方减缓速度。 协议内容：当发送方发送了一个帧后必须停下来，直到收到来自接收方的ACK（可以继续了），然后再发送一个帧。 半双工链路 发送方两个驱动事件： 来自网络层的报文 ACK 3.1.2 噪声通道 3.1.2.1 Stop-and-Wait ARQ 在停止等待协议中增加了错误控制。 错误控制的条件： 对数据帧增加额外的冗余位 帧到达，错误，丢弃，由silence实现【注意，若是帧的序号不匹配但是是正确帧，那么也会发送ACK 】 正确，保留 为帧编号 保留已发帧的副本，启动定时器，如果定时器到时且没有收到ACK那么重发该帧，保留副本并且重启定时器。 ACK有冗余位和序列号 （1）序列号 sequence number 对帧进行编号，序列号是可以循环的。 序列号基于模2运算 有必要使用的序号是x和x+1。 （2）ACK号 acknowledgment ACK号 = 接收到帧的序号 + 1 表示： 已经收到帧x 期待收到帧x+1 （3）设计 $S_n$：保存下一个将要发送帧的序列号 $R_n$：保存下一个期待接收的帧的序列号 /******************** 发送方 ******************/ Sn = 0; canSend = true; while(true){ WaitForEvent(); if(Event(RequestToSend) and canSend){ GetDate(); MakeFrame(); StoreFrame(); // 保存该帧的副本 StartTimer(); // 计时器启动 Sn = Sn+1; // 指向下一帧 canSend = fasle; } WaitForEvent(); // sleep until event occur if(Event(ArrivalNotification)){ // ACK arrive ReceiveFrame(ackNo); if(not corrupted and ackNo = Sn) //有效帧 { StopTimer(); PurgeFrame(Sn-1); canSend = true; } } if(Event(TimeOut)){ StartTimer(); ResendFrame(Sn-1); // 重发 } } /********************** 接收方 **********************/ Rn = 0; while (true) { WaitForEvent(); // 等待事件发生 if (Event(ArrivalNotification)) { // Data frame arrives ReceiveFrame(); if (corrupted(frame)){ sleep(); } if (seqNo == Rn) { ExtractData(); DeliverData(); Rn = Rn + 1; } SendFrame(Rn); // 序号不匹配时也会发出ACK } } 停等ARQ的例子: 第0帧发送并确认。 第1帧丢失，超时后重传。重传的第1帧确认，定时器停止计时。 第0帧发送，但确认帧丢失。超时后，再次重传第0帧，并被确认。 （4）带宽迟延积 在一个停等ARQ系统中，带宽为1Mbps，往返传播时间是 20ms，求带宽时延积。如果帧长度为 1000bit，则链路的利用率是多少？ 带宽时延积为: ​ $1×10^6×20×10^{-3} = 20000bit$ 一次往返只能发送1000bit，所以利用率为 ​ $1000 / 20000 = 5\\%$ 大量带宽资源被浪费 3.1.2.2 回退N帧 ARQ 停止等待ARQ中大部分带宽被浪费，目标是提高传输的效率。 （1）序列号 sequence number 允许序列号有m位，模$2^m$，序列号范围是$0$~$2^m-1$ 序列号可重复 （2）滑动窗口 sliding window 滑动窗口定义发送方和接收方关心的序列号范围。【发送方和接收方只需处理可能的序列号部分】 sliding\\ window\\begin{cases}发送滑动窗口\\\\接收滑动窗口\\end{cases} 发送滑动窗口 窗口的最大大小是$2^m-1$ 窗口分为4部分： \\begin{cases}已确认，不用保存副本\\\\ 待确认帧，保存副本\\\\ 能够发送，但未从网络层接收数据\\\\ 直到滑动窗口才能使用\\end{cases} 三个参数： $S_f$：发送窗口，第一个待处理帧 $S_n$：发送窗口，第一个待发送帧 $S_{size}$：窗口大小，一般为$2^m-1$ 有效确认到达时，发送窗口能够发送一个或者多个时隙。 接收滑动窗口 接收窗口是一个抽象概念，用变量 Rn定义了大小为 1 的接收窗口。正确的帧到达时，接收窗口滑动到下一个时隙。 $R_n$定义了期待接收的帧，除了$R_n$外任何失序帧到达都会被丢弃。 （3）定时器 timer 协议只使用一个定时器，第一个待处理的帧的定时器总是先到时，到时时，我们重发所有的待处理帧。 （4）Acknowledgment 如果一个帧安全有序到达，那么接收方发送一个肯定的确认 如果帧被损坏或者失序，那么接收方不响应并且丢弃所有后来的帧，直到它收到一个它期待的帧。【与停止等待ARQ区别：失序时不会发送ACK 】 接收方可为多帧发送一个累计确认cumulative acknowledgment （5）帧的重发 定时器到时时，发送方会重发所有的待确认的帧。 （6）设计 多个帧能在前向方向传输，在反向传输多个确认。 /***************************** 回退N帧ARQ ****************************/ Sw = 2^m - 1; // 窗口大小 Sf = 0; // 待处理的帧：第0帧 Sn = 0; // 待发送的帧：第0帧 while (true) { waitForEvent(); if (Event(RequestToSend)) { if (Sn - Sf >= Sw) { // 窗口满了 sleep(); } GetData(); MakeFrame(Sn); StoreFrame(Sn); // 副本 Sn = Sn + 1; if (timer not running) { StartTimer(); } } if (Event(ArrivalNotification)) { // ACK arrive Receive(ACK); if (corrupted(ACK)) { sleep(); } if ((ackNo > Sf) && (ackNo （4）Go-Back-N ARQ Versus Stop- and -Wait ARQ 停止等待ARQ其实是回退N帧ARQ的一种特殊情况：只有两个序列号且窗口的大小是1 3.1.2.3 选择性重发ARQ Selective Repeat ARQ 回退N帧ARQ存在的问题： 接收方只有一个变量，不能解决帧失序问题 在有噪声通道效率低小，因为需要重发多个帧 （1）窗口大小 发送窗口 窗口尺度为$2^{m-1}$ 窗口的缩小意味着对管道有效填充性减少，但事实上副本帧会少很多。 接收窗口 接收窗口大小和发送窗口一样$2^{m-1}$ 允许和接收窗口一样多的帧失序到达，并保留到有一组有序帧能交付给网络层： 每个窗口位置只发送一个NAK并指明窗口中的第一个时隙 （2）设计 定时器的数量与Go-Back-N不同，每发送或者重发一个帧都需要有一个定时器，定时器也要编号：只有在这个帧的ACK达到后才会停止计时器。 Note: 一组连续的帧到达且从窗口开始，则可向网络层交付 每个窗口位置只发送一个NAK并指明窗口的第一个时隙 当数据被交付到网络层才发送ACK【一个窗口一个ACK，一个窗口一个NAK】 3.2 HDLC高级数据链路控制 HDLC是一种面向位的点到点和多点链路进行通信的协议。实现了ARQ 3.2.1 配置和传输模式 \\begin{cases}正常响应方式normal\\ response\\ mode\\\\异步平衡响应方式asynchronous\\ balanced \\ mode\\end{cases} 正常响应模式 一个主站（primary station）和多个从站（secondary station） 主站只能发命令，从站只能响应。 异步平衡模式 每个站既是主站又是从站。 3.2.2 帧的类型 信息帧，监控帧，无编号帧 type\\ of frame\\begin{cases}information\\ frames,I-frames：传输用户数据以及用户数据相关的控制信息\\\\supervisory\\ frames,S-frames：传输控制信息\\\\unnumbered\\ frames,U-frames：作为系统管理\\end{cases} 3.2.2.1 帧的格式 3.2.2.2 控制域 信息帧的控制字段 如果控制字段的第一位是0，那么这是一个信息帧。 N(S)定义序号0-7 P/F是单个位，设定为1的时候有意义，意味着轮询或者终止。发送方为主站时（地址字段包含接收方的地址，意味着轮询；帧由从站发向主站时，意味着终止） 管理帧的控制字段 如果控制字段的前两个位是10，那么是管理帧。 管理帧没有信息字段。 最后三个位，称为N(R)，与确认号（ACK）或者否定确认（NAK）对应，取决于管理帧的类型。 code字段定义管理帧的类型： code对管理帧类型的定义\\begin{cases}准备接收RR：00\\\\不准备接收RNR：10\\\\拒收REJ：01\\\\选择性拒收SREJ：11\\end{cases} a. Receive Ready【RR】：编码字段是00，即ACK，N（R）即是确认号 b. Receive Not Ready【RNR】：编码字段是10，对一个或一群帧进行确认，宣布不能接收更多的帧，要求发送方减速 c. Reject 【REJ】：编码字段是01，是一个NAK帧，是一个能在回退N帧中使用的NAK，告知最后一个帧丢失或者损坏，N（R）的值是否定确认号 d. Selective Reject：编码字段是11，选择性重复ARQ的NAK帧，选择性拒收。 无编号帧的控制字段 无编号帧负责在连接的设备之间交换会话管理和控制信息。无编号帧包含一个信息字段，信息字段用作系统管理而不是用户数据。 4. 多路访问 上述的链路访问是假定发送方和接收方之间有专门的专用链路的。 实际上：非专用链路，数据链路层需要提供 data link control && media access control 数据链路层分成两个子层\\begin{cases}\\text{data link control}\\\\\\text{Multiple-access resolution}\\begin{cases}随机访问协议\\\\受控协议\\\\通道化协议\\end{cases}\\end{cases} 4.1 随机访问协议 in random access or contention：没有任何站点是优于其他站点的，没有站点能控制其他站点。 当一个站点要发送数据时，都使用协议来决定要不要发送。 Random Access Protocol的特点： 站点没有规定特定的时间表 没有规则来规定下一个将要发送的站点是哪一个 但是一个以上的站点发送时就会产生冲突---->帧损坏 4.1.1 ALOHA 4.1.1.1 Pure ALOHA 概念：一个站点有帧要发送，那么发送这个帧。存在冲突 ----> 帧损坏 ----> 重发 纯ALOHA依赖于接收方的确认。发送后等待接收方的确认，如果超时后还未到达，站点就认为帧被损坏了。 [resend] back-off time：如果超时后都重发帧，那么可能再次冲突collide again，超时后随机等待一定时间wait a random amount of time。称这个时间为back-off time $T_B$ 一个站点在经过最大次数$K_{max}$之后，必须放弃尝试，并且等待以后尝试 其中超时时间$Wait\\ time\\ out\\ time = 2\\times T_p$，为两倍的传输时间 $T_B$的公式取决于实现，其中一种方法是二进制回退binary exponential back-off： 每次传输随机选择0~$2^k-1$范围内的一个数，该数乘以$Tp$（最长传播时间），或者乘以$T{fr}$，得到$T_B$的值。 每一次冲突后，k的值变大，随机等待的时间变长 $K_{max}$的常用值是15 【脆弱时间 vulnerable time】 vulnerable time：可能发生冲突的时间 纯ALOHA的$vulnerable\\ time =2\\times T_{fr}$ 【吞吐量Throughput】 吞吐量是指每秒实际发送的，与带宽不同。 G：1个帧传输时间$T_{tf}$内，系统产生帧的平均数 S：纯ALOHA成功传输帧的平均数量 S = G\\times e^{-2G} 当$G = \\frac{1}{2}$时，$S_{max}=0.184$. 4.1.1.2 时隙ALOHA 在时隙ALOHA中，将时间分隔成$T_{fr}$秒的时隙，并强制站点只有在时隙开始的时候才能发送。 冲突发生在同时在一个时隙中发送的情况： 脆弱时间$vulnerable \\ \\ time = T_{fr}$ 【throughput】 $S = G\\times e^{-G}$，当G=1时，$S_{max} = 0.368$ 4.1.2 载波监听（CSMA） 载波侦听多路访问CSMA(Carrier Sense Multiple Access)要求每一个站点在发送前先要监听介质，以减少冲突发生的概率。但是它不能消除冲突，冲突概依然存在的原因是传播的延迟。 $vulnerable\\ \\ time = T_P$ 4.1.2.1 监听策略 1-坚持 非坚持 p坚持 4.1.3 CSMA/CD CSMA/CD给出了检测到冲突之后的做法： 是否成功：监控介质观察\\begin{cases}成功，完成发送\\\\失败，重发\\end{cases} 任意站点都可以发送帧，之后监控介质查看传送是否成功。如果成功，站点完成发送；如果不成功，说明存在冲突，需要重新发送此帧。 同时，要想监测到异常，那么要满足条件： T_{fr} ≥ 2T_p 4.1.3.1 Minimum Frame Size 满足$T_{fr} = 2T_p$的，即是最小帧长。 叙述CSMA/CD的流程—— 在开始发送帧之前，增加了持续程序 传输和冲突检测同时进行，持续监测两个过程：传输完成或者是监测到冲突，这两个事件都能使传输停止 同时，若是有检测到冲突发生，那么发送一个短小的干扰信号。 与纯ALOHA相比： 增加了持续程序 传输与冲突检测是一个过程，ALOHA的冲突检测是等待ACK 增加干扰 4.1.4 CSMA/CA 由于在无线网络中大量发送信号的能量在传输中丢失，所以冲突检测起不了什么作用，需要避免冲突。 避免冲突的办法： 帧间间隔 interframe space，IFS 监听到空闲时，并不马上发送，等待一段时间后再发送【使得源端的信号能传输到】，这段时间等于竞争时间。 IFS能定义一个站点/帧的优先权：IFS时间越短，优先级越高 竞争窗口 Contention Window 竞争窗口将时间分隔成时隙，选择一个随机时隙作为等待时间。 时隙个数：补偿策略中的二元指数变化。（IFS后不空闲则时隙数量加倍。） 在CSMA/CA中如果站点发现通道忙，那么不重启竞争窗口的计时器，而是停止计时器发现通道空闲时再启动计时器。 确认 acknowledgment ACK+定时器 过程 4.2 受控访问协议 受控访问的形式： 预约 轮询 令牌环 4.2.1 预约 时间划分为时隙：N个站点，N个预约子时隙，每个时隙均属于一个站点。 每个时隙内先发送一个预约帧reservation station，预约完的站点可以在预约后发送数据帧。 4.2.2 轮询 Polling一个设备作为主站primary station；另一些设备作为从站secondary station; 所有的数据交换都要通过主站点进行，即使最终的目的站点是从站点。 主设备决定那个设备允许使用通道，主设备始终是一个会话的发起者。 polling：主设备希望接收数据，叫做轮询 select：主设备希望发送数据 4.2.3 令牌环 网络中的站点被组织在逻辑环中，每个站点有前驱后后继。 当前正在使用令牌的节点：令牌从前驱来，不用时往后继去 4.3 通道化 不同的站点在时域、频域、码域上正交化来共享信道 \\begin{cases}FDMA\\\\TDMA\\\\CDMA\\end{cases} 4.3.1 FDMA 可用带宽被划分为频带，每个站点都是用分配的频带来通信。 guard bands：保护频带 4.3.2 TDMA 所有站点在时间上共享带宽。 每个站点被划分时隙，只有在该时隙才能发送数据。 4.3.3 CDMA CDMA： 一个通道占用所有的带宽 所有节点可以同时发送，无时间限制 思想： n个站点分配n个编码：c1,c2,...,cn 编码特性： 两个不同的编码相乘为0 自身相乘为4 5. 有线局域网——以太网 局域网(local area network LAN)应用于有限的地理范围。 5.1 IEEE Standards IEEE将数据链路层划分为两个子层： 数据链路层的两个子层\\begin{cases}逻辑链路控制层 LLC\\\\介质访问控制层MAC\\end{cases} 5.1.1 Data Link Layer 5.1.1.1 Logical Link Control (LLC) 逻辑链路层是用来： 成帧 流量控制 差错控制 LLC为所有IEEE局域网提供一个单一的数据链路控制协议。 5.1.1.2 Framing LLC定义了一个协议数据单元PDU，一定程度上与HDLC相似。 头部包含控制字段 用以流量控制和差错控制 另外两个头部界定了使用LLC的源和目的的上层协议，称为目的业务接入点 destination service access point [DSAP]和源业务接入点source service access point [SSAP]。 HDLC中定义的帧被分为LLC子层的PDU和MAC子层的一个帧： HDLC帧\\begin{cases}LLC\\ PDU\\\\MAC帧\\end{cases} 5.1.1.3 LLC的需求 LLC的目的是为需要流量控制和差错控制的上层协议提供这些服务。 IP协议不需要LLC服务。 5.1.1.4 media access control 介质访问控制层为每个局域网定义特定的访问方法。 MAC定义的访问方法\\begin{cases}以太网：CSMA/CD\\\\令牌环：令牌传递\\\\令牌总线局域网：令牌传递\\\\......\\end{cases} 5.1.2 physical layer 每种以太网的实现都有不同的物理层规范。 5.2 标准以太网 以太网的发展： 标准以太网 快速以太网 千兆以太网 Gigabit Ethernet 10千兆以太网 Ten Gigabit Ethernet 5.2.1 MAC子层 MAC子层将上层的数据成帧并传输给物理层。 5.2.1.1 帧的格式 以太网的帧包括7个字段：preamble，start frame delimiter (10101011)，destination address, source address, Length or type, Data and padding和CRC 5.2.1.2 帧的长度 以太网帧的最小长度：64bytes 以太网帧的最大长度：1518bytes 对应到有效载荷： 最小的有效载荷为64 - 18 = 46 最大的有效载荷为1518 - 18 = 1500 5.2.1.3 地址 以太网的地址是6字节（48位）的，通常用十六进制表示，字节间用冒号断开。 Unicast，Multicast，and Broadcast Address 源地址永远是一个单播地址——帧只来自一个站点 目的地址可以是单播地址也可以是多播地址，还可以是广播地址 地址的区分和传送 \\begin{cases}单播地址：地址的第一个字节的最后一位是0\\\\多播地址：地址的第一个字节的最后一位是1\\\\广播地址：地址全为1\\end{cases} 5.2.2 物理层 5.2.2.1 编码和解码 曼彻斯特编码 5.2.2.2 标准以太网分类 （1）10Base5 粗缆以太网，使用收发器，收发器负责： 传输 接收 检测冲突 收发器通过收发器线缆与站点相联，收发器电缆能为发送和传输提供独立的路径，冲突只会发生在粗轴电缆中。 粗轴电缆的最大长度不能超过500米。最多分成5段，使用中继器连接。 （2）10Base2 收发器是网卡的一部分。每个分段的长度最多是185米。 （4）10Base-T：双绞线以太网 使用物理星型拓扑结构，使用双绞线连接到网络集线器上。 双绞线在站点和网络集线器之间形成了两条路径（一条发送一条接收），冲突发生在集线器中。 （5）10Base-F：光纤以太网 使用星型拓扑结构将站点与网络集线器联机。 5.3 标准的改变 5.3.1 桥接以太网 以太网发展的第一步是将局域网利用网桥分割。 网桥分隔，提高了带宽，分隔了冲突域。 5.3.2 交换式以太网 多个端口的网桥可以变成N个端口的交换机，站点的带宽由交换机和站点共享。冲突域分为N个： 一个2层交换机就是一个N个端口的网桥： 5.3.3 全双工以太网 10Base5和10Base2是半双工的（10BaseT始终是全双工的） 下一步就是从交换式以太网到全双工以太网。全双工模式将一个域的能力从10Mbps增加到20Mbps。 在全双工模式中，在站点与交换机之间不是使用一条链路，而是使用两条链路： 一个用于传送，一个用于接收： 6. 无线局域网 无限LAN包括： IEEE802.11无线局域网 蓝牙 6.1 IEEE 802.11 IEEE定义的无线局域网的规范为IEEE802.11，该规范覆盖数据链路层和物理层。 6.1.1 架构 \\begin{cases}基本服务集Basic\\ service \\ set\\\\扩展服务集合Extended\\ service \\ set\\end{cases} 6.1.1.1 基本服务集 基本服务集：无线网络的积木 组成： 固定的或者移动的站点 可选的中间基站，称为访问点access point（AP） 其中，带AP的为基础网络，不带AP的为特别网络 基础网络infrastructure network：能够向其他的BSSs发送消息 特别网络ad hoc：不能向其他的BSS发送数据，他们能够相互定位，并且承诺是BSS的一部分 BSS\\begin{cases}ad\\ hoc\\begin{cases}固定的站点\\\\移动的站点\\end{cases}\\\\infrastructure\\ network\\begin{cases}固定的站点\\\\移动的站点\\\\访问点AP\\end{cases}\\end{cases} 6.1.1.2 扩展服务集 ESS由两个或者更多个带有AP的BSS组成。 各个BSS之间由分布式系统distribution system连接。分布式系统连接BSS中的AP。 对分布式系统没有严格限制，可以是任何类型的局域网，如：以太网。 扩展服务集ESS使用两种类型的站点： \\begin{cases}移动的\\\\固定的\\end{cases} 在连接BSS时 可以互达的站点之间可以相互通信而不必使用AP 位于两个BSS的两个站点间一般要跨过两个AP 6.1.1.3 站点类型 三种站点类型： 不迁移 BSS迁移 ESS迁移 \\begin{cases}不迁移non-transition\\begin{cases}固定不移动的站点\\\\只在BSS内移动\\end{cases}\\\\BSS迁移 BSS-transition：只在一个BSS内移动，但被限制在ESS内\\\\ESS迁移ESS-transition：可以从一个ESS移动到另一个ESS\\end{cases} 6.1.2 MAC子层 IEEE802.11定义了两个MAC子层：分布式协调功能（DCF）和点协调功能（PCF） 6.1.2.1 Distributed coordination function（DCF） DCF使用的是CSMA/CA而不是CSMA/CD。 不能使用CSMA/CD的原因： 冲突检测对站点要求高，且带宽需求高 隐藏站点存在，可能检测不到冲突 站点间距离可能很大，信号衰减可能使得一端的站点无法侦听到另一端的冲突。 a.处理流程图 b.Frame exchange time line 在发送一个帧前，源站点通过检测载波频率的能量来侦听介质 在通道空闲之前使用带有补偿的持续策略 站点发现通道空闲之后，他等待一个被称作分布式帧间间隔（DIFS）的时间周期，然后发送一个叫做请求发送（RTS）的控制帧。 接收到RTS并且等待一个叫做短帧间间隔（SIFS）的短在时间后，目的站点向源站点发送清除发送CTS的控制帧，表明站点准备接收数据。 在等待一个SIFS后，源站点发送数据 在等待一个SIFS后，目的站点发送确认说明已经接收到帧。 由于不检测，所以无法得知是否发生冲突，所以需要ACK。 c.NAV 网络分配矢量 网络分配矢量：当一个站点发送RTS帧时，它包含了需要占据通道的时间。受到这一传送影响的站点建立一个叫做网络分配矢量NAV的计时器，该定时器指出： 在允许这些站点检测通道是否空闲之前还需要等待多长时间。即：NAV不到时，不需要侦听通道。 d.Collision During Handshaking 在RTS或者CTS正在发送时，这一期间叫做握手周期handshaking period。如果两个或者多个产生了冲突，但是没有检测冲突的机制，因此发送方在没有从接收方接收到CTS就以为产生了冲突，于是采取补偿策略并重新发送。 6.1.2.2 点协调功能（PCF） a.PCF的概念与功能 点协调功能PCF在基础网络的BSS中是可选的。主要用作对时间敏感的传输。 PCF是集中式的，无竞争的轮询访问方式，站点依次被轮询，将数据发给AP。 b. PCF的IFS PCF的优先级高于DCF，定义了另一套帧间间隔： PIFS：PIFS比DIFS短 SIFS：和DCF中的SIFS一样 意味着：一个站点只使用DCF，而一个AP使用PCF，那么AP有优先权。 c. 重复间隔的设计 由于PCF的优先级比DCF的优先级高，可能导致只使用DCF的站点得不到对介质的访问。于是设计了重复间隔repetition interval。 重复间隔repetition interval 会持续重复，开始于一个信号帧beacon frame的特殊控制帧，终结于PC发送CF。 6.1.2.3 帧格式 MAC层包括9个字段： 6.1.3 地址 FC中的两个字段from DS和to DS定义，每个字段可能是0或者1。 定义四种情况： to DS from DS 地址1 地址2 地址3 地址4 0 0 目的地址 源地址 BSS ID N/A 0 1 目的地址 发送AP 源地址 N/A 1 0 接收AP 源地址 目的地址 N/A 1 1 接收AP 发送AP 目的地址 源地址 地址1：总是下一个设备的地址 地址2：总是前一个设备的地址 如果目的地址没有被地址1定义，那么地址3是目的地址；如果源地址没有被地址2定义，那么地址3是源地址。 7. 常见网络设备 7.1 Connecting Devices 连接设备分为5类： 7.1.1 无源集线器 无源集线器只是个连接器，连接来自不同分支的线路。 在星型拓扑中，无源集线器只是一个来自不同站点的信号冲突点，集线器是冲突点。无源集线器工作在物理层以下。 7.1.2 中继器 7.1.2.1 工作层次 repeater仅工作在物理层。 7.1.2.2 功能 信号的重生 中继器能够接收信号，在信号变得很弱或者被破坏前，重新生成原始的位模式，然后发送新生成的信号。中继器只重新生成信号，并不放大信号。 连接一个局域网的两段 中继器实际并不能连接两个局域网，连接的是同一局域网的两个分段。所连接的网段仍然是一个局域网的一部分。中继器不能连接采用不同协议的两个局域网。 中继器可以克服10Base5以太网标准的长度限制。使用中继器连接各个网段segement。 没有过滤能力 过滤帧的能力：读取帧首部信息，决定是否转发，如何转发。 中继器转发每一帧，没有过滤能力。 中继器常用于星型拓扑结构中，可以多级级联。 7.1.3 有源集线器 7.1.3.1 工作层次 有源集线器是一个多端口的中继器。常用于星型拓扑中。 集线器和网线一样工作在物理层，功能和网线一样，只是将数字信号发送到其他的端口，不能识别帧首部的信息。 7.1.3.2 功能 数字信号发送到其他的端口。 7.1.3.3 带宽和广播域 带宽 集线器组建的以太网共享带宽，计算机数量越多，平均带宽就越低。 安全性 无论MAC地址是否是自己的，都能捕获。 冲突域 级联以后的以太网计算机处于一个冲突域内。增大了冲突的概率，每台计算机分到的带宽也降低了。 接口带宽 相联的接口带宽要一样。如果数据速率不一致，那么工作在较低的数据速率，因为集线器接口不能缓存帧。 7.1.4 网桥 7.1.4.1 工作层次 网桥工作在物理层和数据链路层。 用作物理设备时，重新生成接收到的信号。 作为数据链路层设备时，可以检查帧包含的MAC地址 7.1.4.2 过滤 网桥与中继器不同的地方在于网桥有过滤功能。 网桥具有一个用过过滤决策的表，有过滤作用。转发帧时必须指定端口。检查帧的目的地址。 7.1.4.3 网桥组网的特点 网桥基于MAC地址转发帧，转发之前运行CSMA/CD算法。 网桥的一个接口是一个冲突域，冲突域的数量增加，但是冲突的概率减少。 实现帧的存储转发，增加了时延。 网桥的接口可以是不同的带宽。 7.1.4.4 透明网桥 透明网桥指的是站点意识不到桥的存在。 802.1d规定了透明网桥的特点： 帧必须能从一个站点转发到另一个站点 学习帧中的地址，自动建立转发表 避免形成循环Loop问题 7.1.5 两层交换机 两层交换机是一个拥有许多端口并且有更好更快性能的网桥。 多端口的网桥可以给每个站点分配唯一的端口，每个站点都作为独立的实体。没有冲突。 7.1.5.1 两层交换机的特点 端口独享带宽，Hub是共享带宽 安全：交换机根据MAC地址只转发到目标端口 全双工通信 不再使用CSMA/CD 接口可以工作在不同的频率，交换机使用存储转发技术 转发广播帧：转发除了发送端口以外的其他端口 7.1.5.2 二层交换机的类型 a.存储转发式 Store and forward 从输入线路上接收帧，缓存，通过路由选择将其发送到适当的输出线路上。发送方和接收方存在延迟，增进了网络的整体一致性。 b.直通式 Cut through 利用了目的地址总是出现在MAC帧的最前面的特点。交换机识别出目的地址后就将帧转发到适当的输出线路能够达到很高的吞吐量。 7.1.6 路由器 路由表中包含了下面的信息： 目的地址 掩码 输出接口 下一跳的IP地址：说明IP数据报所经由的下一个路由器的接口地址 7.1.7 Three Layers Switches 三层交换机是路由器，但是更快且更复杂 7.2 Virtual LAN 7.2.1 VLAN的概念 通过软件而不是物理线路来配置一个局域网，称为虚拟局域网。 7.2.2 VLAN的特点 一个LAN可以划分为多个VLAN，每个VLAN是一个工作组。 允许连接在不同的交换机上的站点组成一个VLAN。 同一个VLAN中的站点通信时，就像他们属于同一个物理网段一样。 VLAN将属于一个或者多个物理站点的LAN分组到一个广播域中。 7.2.3 VLAN的划分方式 基于端口：使用交换机的端口 基于MAC地址：使用48位MAC地址，规定某个MAC地址的主机属于某个VLAN 基于IP地址：32位IP地址 基于多播IP地址 7.2.4 默认VLAN 默认VLAN是交换机初始就有的VLAN，通常ID为1，所有的接口都处于这个VLAN下，这就是所有设备连接到交换机上就能相互通信的原因。 VLAN ID最多有$2^{12}$个，VLAN0和VLAN4095保留。 7.2.5 交换机的三种链路类型 access模式：与计算机端口直连 trunk模式：允许多个VLAN帧通过 hybrid模式 var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"计网复习笔记/网络层.html":{"url":"计网复习笔记/网络层.html","title":"网络层","keywords":"","body":"网络层 网络层的通信：主机到主机 1. 逻辑寻址 IP address：TCP/IP中的逻辑地址。 IPv4——32位，$2^{32}$个地址 IPv6——128位，$2^{128}$个地址 1.1 IPv4地址 IPv4地址是唯一的。唯一指的是每一个地址定义了在因特网上仅有一个设备。因特网上的设备永远不会有同样的地址。 1.1.1 地址空间 地址空间指的是指该协议能用的地址的总个数。 IPv4能用的地址的总个数为$2^{32}$。 1.1.2 表示法 点分十进制表示法，每个点分数的范围为0~255 1.1.3 分类寻址 分类寻址中，地址空间被分为A，B，C，D和E五类 当一个地址用二进制或者点分十进制表示时，可以由开头前几位求出地址的类型： 注意，D类和E类是没有主机号的。 1.1.3.1 类和块 （1）A类地址 为那些具有大量的主机或者路由器的大型组织机构设计 IP:={\\,\\} 网络号：$2^7-2=126$ 网络号字段全为0的IP地址为保留地址，意为本网络 网络号为127（01111111）保留为本地软件环回测试（loopback test）本主机进程之间的通信用 主机号：$2^{24}-2$ 全0的主机号表示是“本主机”连接到的单个网络地址 全1主机号字段表示的是该网络上的所有主机 A类地址占所有的地址的50% （2）B类地址 为中型机构设计 IP:={\\,\\} 网络号：$2^{14}-1$ 网络号全0的128.0.0.0不指派，B类的最小网络地址是128.1.0.0 主机号：$2^{16}-2$ 去除全0和全1的主机号 B类地址空间占整个IP空间的25% （3）C类地址 为小型机构设计 IP:={\\,\\} 网络号：$2^{21}-1$ 全0的不予指派 主机号：$2^8-2=254$ 扣除全0和全1的主机号 C类地址占整个IP空间的12.5% （4）D类地址 多播可发送一个消息给同一多播组中的一组成员设备。 两种多播 （5）E类地址 为将来使用而保留 1.1.3.2 掩码 A类，B类，C类的掩码如下： 以/n的形式表示掩码，在classful Addressing中n是8,16和24.这种标记法称为Classless Interdomain Routing（无类域间路由选择 CIDR） D类和E类没有掩码. 1.1.3.3 私有网络 在IP地址空间中，保留了几个用于私有网络的地址。私有网络常用于公司，组织和个人网络，他们没有置于因特网中 A类：10.0.0.0~10.255.255.255 B类：172.16.0.0 ~ 172.31.255.255 C类：192.168.0.0~192.168.255.255 1.1.3.4 子网化 划分子网纯属一个单位内部的事情。单位对外仍然表现为没有划分子网的网络。 从主机号借用若干个位作为子网号subnet-id，而主机号Host-id也就相应减少了若干个位 IP ::= \\{,,\\} 凡是从其他网络发送给本单位某个主机的IP数据报，仍然是根据 IP 数据报的目的网络号net-id，先找到连接在本单位网络上的路由器。 然后此路由器在收到 IP 数据报后，再按目的网络号 net-id 和子网号 subnet-id 找到目的子网。 最后就将 IP 数据报直接交付目的主机。 当没有划分子网时，IP地址是两级结构； 划分子网后IP地址变成了三级结构 划分子网只是把IP地址的主机号host-id这部分再进行划分，而不改变IP地址原来的网络号net-id 从一个 IP 数据报的首部并无法判断源主机或目的主机所连接的网络是否进行了子网划分。 使用子网掩码可以找出IP地址中的子网部分 1.1.3.5 子网掩码和网关的作用 两台计算机通信的过程： 1.判断自己与对方是否在同一网段 自己的IP地址与掩码进行AND运算得到自己所在的网段 对方的IP与自己的网段掩码进行AND 比较二者是否相同，不相同转2，相同转3 2.不相同，二者不在同一网段。封装帧时以网关的MAC地址作为目的MAC地址，交换机会把帧交给路由器接口 3.相同，二者在同一网段。封装帧时直接使用目标主机IP的MAC地址作为目的MAC地址，直接将帧发给目标地址 EXAMPLE: （a）A和B可以互通 （b）A可以发给B，但是B无法发给A 1.1.4 无类寻址 无类编址仍提供了地址块 网络前缀来替代网络号和子网号 三级编址 -----> 两级编址 1.1.4.1 地址块 在无类寻址中，当一个小的或者大的实体需要连接因特网时，给他分配一个合适的地址块。 块的大小（地址的个数）按实体大小规模与性质来决定。 Restrictions： 块中的地址必须是一个接着一个连续的 一个块中的地址的个数是2的整数次幂（1,2,4,8...） 块的起始地址必须能被地址的个数整除 1.1.4.2 CIDR CIDR的特点： CIDR 消除了传统的 A 类、B 类和 C 类地址以及划分子网的概念，因而可以更加有效地分配 IPv4 的地址空间。 CIDR使用各种长度的“网络前缀” (network-prefix)来代替分类地址中的网络号和子网号。 IP ::= \\{,\\} IP地址从三级地址又回到了二级地址 CIDR把网络前缀都相同的连续IP地址组成“CIDR地址块” 1.1.5 NAT路由转换 背景：家庭用户和小型商业公司的需求增加，IP地址短缺 NAT：使用户在内部拥有大量的地址，在外部拥有少量的地址。 Address for private networks专用地址：组织内部唯一，全球范围内不唯一。使用时不必向因特网管理机构申请 global address全球地址：全球唯一IP地址，使用必须向因特网管理机构申请 路由器将一个专用网络与全局因特网相连的路由器有两个地址： private address:172.18.3.30 global address:200.24.5.8 1.1.5.1 地址转换 所有外发的分组都通过NAT路由器发送出来，该路由器用全球NAT地址来替代分组中的源地址。 所有的输入也要通过NAT路由器，该路由器用相应的专用地址来代替分组中的目的地址。 1.1.5.2 转换表 如何知道来自因特网的分组的目的地址？每个专用的IP地址属于某个特定的主机，NAT路由器有一个转换表。 （1）使用一个IP地址 NAT只有一个external address 实现私有地址和全球公有地址的一对一映射，公有地址分配给唯一且固定的内网主机。 转换表有两列： Private address & External address （2）Using a pool of IP Address NAT有多个地址。 当NAT路由器具有n个全球IP地址时，专用网内最多可以同时有n个主机接入到因特网。NAT路由器IP地址数量有限时，专用网内较多数量的主机可轮流使用NAT路由器的全球IP地址。 （3）Using both IP address and Port Numbers 同时使用IP地址+端口号 为了更有效地利用NAT路由器上的全球IP地址，常用的NAT转换表把传输层端口号也利用上。 使多个拥有本地地址的主机，共用一个NAT路由器上的全球IP地址，因而可以同时和因特网上的不同主机进行通信。 1.1.5.3 NAT的类型 静态NAT：实现了私有地址和全球公有地址的一对一映射，一个公有IP只会分配给唯一且固定的内网主机 动态NAT： 将内部网络的私有IP地址转换为公有IP地址时，IP地址对是不确定的、随机的，所有被授权访问Internet的私有IP地址可随机转换为任何指定的公有IP地址。 当ISP提供的共有IP少于网络内部计算机数量 网络地址端口转换PAT（Port address Translation）：把内部地址映射到外部网络的一个IP地址的不同端口上。PAT与动态地址NAT不同，它将内部连接全部映射到外部网络中的一个单独的IP地址上，同时在该地址上加上一个由NAT设备选定的端口号。 PAT NOTE： PAT把专用网内不同的源IP地址，都转换为同样的全球IP地址。 对源主机所采用的TCP端口号（无论是否相同），转换为不同的新的端口号。 从层次的角度看，PAT的机制有些特殊。 普通路由器在转发IP数据报时，源IP地址或目的IP地址都是不改变的，但NAT路由器在转发IP数据报时，一定要更换其IP地址（转换源地址或目的地址）。 普通路由器在转发分组时工作在网络层，但PAT路由器要查看和转换运输层的端口号，属于运输层的范畴。 PAT路由器工作在传输层！ 1.2 IPv6地址 1.2.1 地址结构 128位，十六进制冒号表示法 缩短： 1.2.2 地址空间 $2^{128}$个地址，划分为多个类，可变长类型前缀 基于提供者的单播地址前缀： 定义一个单独的计算机，发送到单播地址的分组必须传递到这个指定的计算机。 多播地址： 定义的是一组主机，而非一个主机。报文会发给每一个成员 任播地址： 发送给改组的任意一个成员 2. IP协议 \\begin{cases}当前：IPv4\\\\将来主流：IPv6\\end{cases} 2.1 网络工作 由A发送数据报到D，仅仅数据链路层和物理层，无法帮助路由器做出从哪个端口转发出去的选择。 需要设计网络层，IP地址进行路由选择。 2.1.1 网络层的必要性 网络层不仅负责主机间的传递，而且还负责通过路由器或者交换机对分组进行路由选择。 将来自传输层的输入数据生成为一个分组，分组的头部包含源和目的逻辑地址及其他信息。 网络层负责检验路由表，进行路由选择 分组太大时需要分段 2.1.2 数据报网络 网络层中的交换是通过Packet Switching数据报交换的方式实现的。 2.1.3 无连接服务 packet\\ switching\\begin{cases}面向连接的服务\\text{connection oriented service}\\\\ 无连接的服务\\text{connectionless service}\\end{cases} connection oriented service 源端在发送一个分组之前首先与目的端建立一个连接，建立连接后，分组可以按照顺序依次从相同的源端发送到相同的目的端。 分组逻辑上连接在一起。 connectionless service 无连接是指交换机或路由器不保存有关连接状态的信息，不需要建立连接，也不需要拆除连接。 网络层协议独立地对待每个分组，而且每个分组与其他的分组没有任何关系。 分组可能不会沿着同样的路径到达目的地 2.2 IPv4 Internet Protocol version4 网际协议第四版是TCP/IP协议使用的传输机制。 特点： IPv4是一种不可靠的无连接的数据报协议，它尽力传递（Best-effort delivery）数据报，但是不提供差错控制或流量控制（除首部的检验和之外），因此不保证可靠性。 当可靠性很重要时，IPv4需要和一个可靠协议TCP配合起来使用 2.2.1 数据报 数据报20-65536bytes\\begin{cases}头部Header：20-60bytes\\begin{cases}固定首部:20bytes\\\\选项:40bytes\\end{cases}\\\\数据Data\\end{cases} 2.2.1.1 字段说明 VERSION：IP协议版本，现为IPv4，后将被IPv6取代 HLEN：头部长度，占4bit，表示20~60bytes——单位是4byte HLEN = 字面值 × 4byte 没有选项时，头部长度为20bytes，则$HLEN_{min} = \\frac{20}{4}=5$，即最小是：0101 当选项长度为最大值时，头部长度为60bytes，则$HLEN_{min} = \\frac{60}{4}=15$，即最大是：1111 Service：有服务类型Service type和差分服务Differentiated Service两种解释，占8bit Service Type 当做服务类型解释时，前三位为优先位Precedence，后四位为服务类型TOS位 a. Precedence Precedence的3bit值从000到111,共8个优先级，当出现了拥塞等问题时，优先级较低的数据报将被丢弃。 IPv4中未使用优先级字段 b. TOS位 Differentiated Service 前6位为码点codepoints，后2位不用。 codepoint的两种使用方法\\begin{cases} 当码点字段最右边3位都是0时：最左边3位与服务类型中的优先级相同。\\\\最右边三位不全为0，则六位含义为64种服务类型\\begin{cases}第一类：IETF分配32种\\\\第二类：本地机构16种\\\\第三类：实验目的16种\\end{cases}\\end{cases} Total Length： 总长度 = 数据长度 + 首部长度 = 总长度 + HLEN * 4 某些网络不允许65536bytes长度的数据报，则需要进行分段。总长度不得超过MTU。 IP数据报在以太网中 【标准以太网允许的最小报文长度为64bytes，数据部分最小为64 - 18 bytes = 46 bytes】 【标准以太网允许的最大报文长度为1518bytes，数据部分最大为1518-18bytes = 1500 bytes】 数据长度\\begin{cases}最小：46bytes\\\\最大：1500bytes\\end{cases} 所以当IP数据报封装在标准以太网的帧中，当长度不足46Bytes时需要进行位数填充。 超过1500bytes时，需要进行分段。 identification：16bits 计数器，用于产生数据报的标识，在分段中使用 flag ：标志，后两位有效 Fragmentation offset：片偏移 13bit 该片在原片中的位置，占13bits，以8byte为偏移单位 Time to live：生存时间，占8bit 标识数据报可经过路由器的最大值。 原因：若路由表故障，那么报文可能在两个或者更多的路由器之间传输很长的时间。 含义\\begin{cases}原：维护时间戳，统一时间，比较复杂\\\\现：路由器数，约定为任意两主机之间的路由器个数的2倍\\end{cases} Protocol：高层的协议，如TCP，UDP 以便接收方网络层将数据交付给那个处理过程。 Header checksum：占16bits 只检验数据报的首部，不包括数据的部分。 Source IP Address and Destination IP Address：均为32位二进制 2.2.2 分段 数据报可以通过不同的网络进行传播 \\begin{cases}刚刚经过的网络：收到的帧的格式，长度\\\\将要传输的网络：发出去的帧的格式，长度\\end{cases} 最大传输单元MTU(maximum transmission unit)：数据字段的最大长度。 数据报封装成帧时，数据报的总长度必须小于这个最大数据长度。 由网络所使用的硬件和软件给出的限制所定义的。 IP数据报的最大长度时65535bytes。如果使用Hyperchannel那么不用进行分段。然而对于其他的物理网络，就要对数据报进行分割。 数据报被分段时，每个分段都有自己的头部，其中大部分的字段是重复的，但有些发生了变化。 数据报在到达最终的终点前，如果遇到更小的MTU的网络，那么已经分段的数据报还可以继续分段。 数据报的分段可能被主机或者路径中的任何路由器分段。 重组只能在目的主机上进行，在传输器件重组会造成传输效率的降低。 不管是否分段，校验和字段总是重新计算的 分段中改变三个字段的值：identification，flag，fragmentation offset （1）identification 16bits，标识一个从源主机发出的数据报。数据报离开源主机后，这个字段与IPv4地址唯一定义这个数据报。 使用计数器来标识数据报。 IPv4发送一个数据包时，就将当前计数器中的值复制到identification字段中，并将此计数器的值+1。 当数据报分段时，标识字段的值就复制到所有的分段中：所有的分段有与原始数据报相同的identification。 帮助在目的端重组数据报。 （2）flag 3位的字段。 第一位保留为以后使用 第二位称为“不分段”位 Do not fragments DF = 1：机器不能对该数据报进行分段。 如果无法将此数据报通过任何可用的物理网络，那么丢弃数据包，并向主机发送ICMP差错报文 DF = 0：根据需要对数据报进行分段 第三位为“多分段”位More fragments MF = 1：此段不是最后的一段，还有更多的分段 MF = 0：他是最后的唯一分段 （3）fragmentation offset 13bit，表示这个分段在整个数据报中的相对位置。他是在原始数据报中的数据偏移量，以8字节为度量单位。 要求第一个字节编号能被8整除 所有分段的标识部分都相同 除了最后一个分段，所有flag的MF都是1 每一个段的$offset值=第一个字节的编号/8$ 对一个分段本身再进行分段时，分段的偏移量所表示的位置都是相对于原始的数据 2.2.3 选项 选项部分最多为40bytes。 2.3 IPv6 2.3.1 IPv6优点 更大的地址空间：32---->128位 【解决IPv4地址耗尽问题】 更好的头部格式：首部中不含有选项 【简化路由选择，路由器不用再检查选项】 改进的选项：新选项实现附加功能 允许继续扩充 支持即插即用 支持资源预分配 【音频，视频传输增加，需要最小】 支持更多的安全性 【IPv4不提供加密和鉴别】 IPv6首部改为8字节对齐 2.3.2 数据报格式 分组 = 基本头部 + 有效载荷 = Base header + Payload \\begin{cases}Base\\ header：40bytes\\\\Payload:up\\ to \\ 65535 bytes\\begin{cases}Extension\\ headers\\\\Data\\ packet\\ from\\ upper\\ layer\\end{cases}\\end{cases} 2.3.2.1 基本首部 Version：版本，IPv6，即0110 Priority：优先级，定义了发生通信拥塞时的分组的优先级 IPv6的优先级字段定义了从相同源端发出每一个分组相对于其他的分组的优先级。 网络拥塞时，丢弃优先级低的分组 IPv6的通信量划分\\begin{cases}congestion-controlled可进行拥塞控制\\\\noncongestion-controlled不可进行拥塞控制\\end{cases} congestion-controlled 可进行拥塞控制的通信量 可进行拥塞控制的通信量允许分组延迟到达，或丢失，或不按顺序接收 被指定为0-7的优先级。0是最低的，7是最高的。 noncongestion-controlled 不可进行拥塞控制的通信量 期待最小延迟的通信量，丢弃分组是不希望的，重传也是不可能的。 即，源端不能自己适应拥塞，实时音频和视频是这类通信量的很好的例子 优先级8~15被分配给不可进行拥塞控制的通信量 noncongestion-controlled traffic flow label：流标号，用来对特殊的数据进行专门处理 从特定源端向特定目的端发送的分组序列，如果需要路由器的特殊处理，则称为分组流。 一个流是共享某些特性的分组序列，源地址和流标号的值唯一定义了一个分组流。 如相同的路径，使用相同的资源，具有相同的安全性，等等。 支持流标号的路由器有一个流标号表，这个表为每个活动的流标号设置一个项目，项目定义流标号需要的服务。 简单应用：加速路由器对分组的处理。 不用查找路由表并用路由选择算法确定下一跳的地址，直接在流标号表中查找下一跳的地址 复杂形式：支持实时音频和视频的传输 进程可以事先对这些资源进行预留。 流标号使用的三个原则 流标号由源主机指定给分组，是1到$2^{24} - 1$之间的随机数。 如果主机不支持流标号，则置为0 所有属于同一个流的分组必须具有相同的源地址、目的地址、优先级和选项。 Payload length：2字节定义了除了基本头部在内的IP数据报的总长度 Next header：跟在基本头部之后的下一个头部。 可以是扩展首部 也可以上层协议的UDP或者TCP的头部 Hop Limit：跳数限制 和IPv4中的TTL功能相同 2.3.2.2 扩展首部 6个扩展头部，很多是IPv4的选项 扩展头部\\begin{cases}\\text{hop by hop option}\\\\\\text{Source routing} \\\\\\text{Fragmentation}\\\\\\text{Authentication}\\\\\\text{Encrypted security payload}\\\\\\text{Destination option}\\end{cases} （1）hop-by-hop option 包括Pad1、PadN和特大有效载荷。 （2）Source Routing 将IPv4的严格的源路由和松散的源路由的概念结合在一起。 （3）Fragmentation 和IPv4概念相同，但是发生的地方不同。 \\begin{cases}\\text{IPv4：源端或者路由器进行分段}\\\\\\text{IPv6：只有源端才能进行分段，源端使用路径MTU发现技术，找到最小的MTU，进行分段}\\end{cases} 2.4 Transition from IPv4 To IPv6 IPv4到IPv6的过渡需要平滑，设计了三种策略： Transition\\ strategies\\begin{cases}\\text{双栈协议}Dual\\ stack\\\\隧道技术Tunneling\\\\头部转换Header\\ translation\\end{cases} 2.4.1 双栈策略 一个站点同时运行IPv4和IPv6。 当把分组发送到目的端时，主机要向DNS进行查询。 DNS返回IPv4地址，那么发送IPv4分组 DNS返回IPv6地址，那么发送IPv6分组 2.4.2 隧道策略 两台使用IPv6的计算机通信，但是分组要经过IPv4的区域，那么分组需要有IPv4的地址 IPv6分组封装成IPv4分组，离开时去掉封装 2.4.3 头部转换 头部格式通过头部转换彻底改变： IPv6头部---->IPv4头部 IPv4头部---->IPv6头部 3. 和IP协议配合使用的其他协议 IP：best-effort delivery protocol，尽力传输协议。 没有流量控制和差错控制等特性，是使用逻辑寻址的主机到主机的协议。 IP协议需要其他的协议的帮助。 \\begin{cases}分组组装成帧，需要物理地址（hop-to-hop）：ARP地址解析协议\\\\物理地址到逻辑地址的映射\\begin{cases}RARP\\\\BOOTP\\\\DHCP\\end{cases}\\\\流量控制和差错控制：ICMP协议\\\\多播协议：IGMP协议\\end{cases} 3.1 地址映射 物理地址 本地地址，管辖范围是本地网络。 物理地址在本地范围内是唯一的，但是在全局上不是。 物理地址大多是用硬件实现的。如以太网的48位的MAC地址，被写入主机或者路由器的网卡上 分组传递到主机/路由器需要两级地址： \\begin{cases}物理地址\\\\逻辑地址\\end{cases} 两种映射实现物理地址逻辑地址 3.1.1 静态映射 将一个逻辑地址与物理地址联系起来，这个表储存在网络上的每个机器上。 通过【查表】，由IP地址得到物理地址。 局限性：物理地址可能因为某些原因改变 （1）更换网卡 （2）LocalTalk，计算机加电时，地址改变 （3）移动计算机从一个物理网络转换到另一个物理网络，引起物理地址的改变 3.1.2 动态映射：协议 当机器知道逻辑地址和物理地址之一时，可以利用协议求出另一个地址。 3.1.2.1 逻辑地址到物理地址的映射：ARP IP地址的获得： 发送方是主机：从DNS求得（域名到IP地址） 发送方是路由器：从路由选择表获得 但是IP数据报需要封装成帧，需要有接收方的物理地址。 主机或路由器发送一个ARP查询分组，该分组： ARP分组\\begin{cases}发送方的物理地址\\\\发送方的IP地址\\\\接收方的IP地址\\end{cases} ARP查询在网络上广播broadcast： 该物理网络上的每一个系统都接收到此分组，但是只有系统B才会回答。 系统B会发送一个包含他的物理地址的ARP回答分组。【单播unicast】 然后系统A使用接收到的地址来发送到该目的地的所有地址。 ==会不会出现：B不在本网络上，那B没法回复，广播到了路由器，由路由器检查后返回路由器的物理地址。路由器怎么知道没人回复A== 不会，A会先查自己的路由表，如果B不在本网络，那么一定广播的是路由器的IP，问路由器的MAC ==路由器路由选择时为什么要运行ARP？和IP匹配后直接从路由表指示的那个端口发出去不就行了？== 要获得下一跳的MAC地址 （1）Cache Memory 若系统A到系统B的每个分组均需要ARP请求广播：低效 系统通常发给多个分组到同一个目的地。接收到ARP回答的系统将他的映射保存在高速缓存中，保持20-30分钟（除非高速缓存已满）。之后发送ARP之前，现在高速缓存中寻找。 （2）数据报格式 Hardware Type：指出运行ARP的网络类型。ARP可以运行在任何物理网络上 Protocol Type：发送方使用的协议类型，IPv4是0800H Hardware length：定义字节为单位的物理地址的长度。 Protocol length：以字节为单位的逻辑地址的长度 （3）封装 ARP分组是直接封装在数据链路帧中的，以太网帧如下： Type字段指出了此帧携带的是ARP分组 （4）操作 ARP的工作过程： 发送方知道目标的IP地址 IP请求ARP协议产生一个ARP请求报文，填入发送方的物理地址，发送方的IP地址，目标的IP地址。目标的物理地址未知填入0 将报文发送给数据链路层，被封装成帧，使用发送方的物理地址作为源地址，而将物理广播地址作为目的地址。 每一个主机和路由器都收到这个帧。因为这个帧包含了广播的目的地址，所有所有的站点都将此报文送给ARP。除了目标机器外，所有的机器都丢弃这个分组。目标机器识别这个IP地址。 目标机器使用ARP回答报文进行应答，此回答报文包含了他的物理地址。使用单播 发送方接收到这个回答报文，他现在知道了目标机器的物理地址 携带发送给目标机器的IP数据报现在封装成帧，用单播发送给目的端。 （5）四种情况 情况1：发送方是一个主机，发给同一个网络上的另一个主机。这时必须将IP地址映射为物理地址，并将逻辑地址作为数据报头部的目的IP地址。 情况2：发送方是一个主机，希望发给另一个网络上的主机，这时候路由器的IP需要映射成物理地址。 情况3：发送方是一个路由器，收到了数据报，要将数据报发送给另一个路由器。另一个路由器的IP就是要映射成物理地址的IP 情况4：路由器收到了数据报，要将数据报发送给同一个网络上的一个主机。数据报的目的IP就是要映射成物理地址的那个逻辑地址 （6）代理ARP Proxy ARP有子网化的效果 代理ARP是可以代表一组主机的ARP。 每当运行代理ARP的路由器收到一个寻找这些主机中的其中一个主机的IP地址的ARP请求时，ARP发送一个ARP回答，宣布他自己的物理地址，真正收到数据报后转发给相应的主机。 3.1.2.2 物理地址到逻辑地址的映射：RARP，BOOTP，DHCP 主机只知道其物理地址，不知道IP地址的情况： 无盘站点正在被引导 一个机构无足够的IP地址，只能按需分配 （1）RARP反向地址解析协议 Reverse Address Resolution Protocol：为仅知道物理地址的机器寻找他的IP地址而设计的。 每一个主机都有一个或者多个IP地址，这些地址是唯一的，并与物理地址无关。要创建一个数据报，那么主机就要知道他自己的IP地址。一个机器的IP地址通常可以从存储在磁盘文件中的配置文件中读出。 对于上面的无法知道IP地址的情况。可以根据自己的物理地址使用RARP协议从物理地址求得IP地址。 a. 过程 创建RARP请求，在本地网络上广播 本地网络上知道所有IP地址的另一个机器使用RARP来响应 请求机器必须运行RARP客户程序，响应机器必须运行RARP服务程序 b. RARP缺点 不能通过网络边界，需要为每个子网指定一个RARP服务器。（几乎不用） （2）BOOTP协议 引导程序协议：客户机/服务器程序。 BOOTP是一个应用层协议。 BOOTP 报文被封装在UDP分组中，UDP分组被封装在IP数据报中 客户机使用： 全0作为源地址 全1作为目的地址——广播地址，不能跨过路由器------>若不在一个网络，需要代理主机【优于RARP的地方】 两种情况： 客户机和BOOTP服务器在同一个网络上 客户机和BOOTP服务器不在一个网络上 使用一个主机或者路由器作为中介，中介知道BOOTP服务器的单播地址。 relay agent中继代理：收到这种类型的分组时，他在单播的数据报中封装报文并发送到BOOTP服务器。 BOOTP知道来自中继代理的报文，因为在请求字段中定义了中继代理的IP地址。接收到回答后，中继代理向BOOTP客户机转发它。 ​ 缺点：只能静态配置，不能动态配置。 ​ 主机请求IP地址，BOOTP查表，寻找与物理地址匹配的IP地址：关系必须已经存在。 （3）DHCP协议 动态主机配置协议：Dynamic Host Configuration Protocol 提供\\begin{cases}静态/动态\\\\人工/自助\\end{cases}地址配置 a. static address allocation 与BOOTP相同，查询数据库，返回与物理地址匹配的IP地址 b. dynamic address allocation 有一个可用的IP地址池。DHCP客户机请求一个临时地址时，DHCP服务器查找可用的IP，指定一个在可协商期内有效的IP地址。 c. 请求过程 客户机发出请求时，DHCP先查找静态的，有则返回；否则在动态IP地址池中选择一个并返回，添加到动态的数据库 d. Manul and Automatic Configuration DHCP可人工，可自动 3.2 ICMP协议 IP协议缺少差错控制和流量控制，需要ICMP配合IP使用。 3.2.1消息的类型 message\\ type\\begin{cases}\\text{error reporting message}：向主机或者路由器报告错误（无法纠错）\\\\\\text{query message}：帮助主机/网络管理员从一个路由器/主机得到特定信息\\end{cases} ICMP特点： 为了提高 IP 数据报交付成功的机会，在网际层使用了因特网控制报文协议 ICMP。 ICMP 允许主机或路由器报告差错情况和提供有关异常情况的报告。 ICMP 不是高层协议，而是 IP 层的协议。 ICMP 报文作为 IP 层数据报的数据，加上数据报的首部，组成 IP 数据报发送出去。 ICMP不能纠错，只能报告错误。 3.2.2 报文格式 ICMP报文有一个8字节的头部和可变长的数据部分，8字节头部 前四字节对所有类型的ICMP相同 后四个字节格式不同 3.2.3 错误报告 ICMP使用IP数据报中的源IP地址，向原始的源方发送差错报告报文 差错报文的原因： ICMP不产生差错报告的情况： \\begin{cases}ICMP错误报告本身不再产生差错报告\\\\分段的报文，不是第一个分组不产生错误报文\\\\多播的ICMP不产生差错报文\\\\特殊的地址：全0/全1不再发送差错报文\\end{cases} 3.2.3.1 目的端不可达 当路由器不能找到路由或者主机不能传递数据时候，丢弃这个数据报，然后发回目的端不可达报文。 目的端不可达报文或者由路由器产生，或者由目的主机创建。 3.2.3.2 源端抑制 IP无流量控制，可能在路由器或者目的主机中产生拥塞，当来不及处理溢出的缓存队列时，只能将数据报丢弃。 使用ICMP的目的有两个： 告诉源端数据报被丢弃 通知源端存在拥塞，减缓发送速度 3.2.3.3 超时 TTL减为0时，数据报被丢弃，发送超时的ICMP报文 所有的分片没有在有限的时间内到达 3.2.3.4 参数错误 IP首部中产生错误或者二义性，路由器或者主机丢弃这个分组，然后向源方发送参数问题报文。 3.2.3.5 重定向 路由器参与路由选择更新，但是主机不参与路由选择更新。 通常主机只知道一个默认路由，当主机向另一个网络发送报文时，就错误地发送给了这个默认路由 默认路由需要： 转发给正确的路由器 重定向报文 3.2.4 查询报文 ICMP对某些网络进行诊断，4种报文实现 3.2.4.1 echo-request and reply message 回送请求和回答报文：诊断目的设计。确定两个系统是否能够通信 e.g. ping命令 3.2.4.2 时间戳请求和回答 时间戳请求和回答：确定IP数据报在两个机器之间的往返时间。 可用于时钟同步。 3.2.4.3 地址掩码请求和回答 主机知道自己的IP，但是可能不知道自己的掩码。获取对应地址的地址掩码，向路由器发送地址掩码请求报文。不知道路由器地址时进行广播。路由器收到，使用地址掩码回复报文回复。 3.2.4.4 路由器询问和通告 主机需要知道路由器是否正常工作。 3.2.5 Debugging Tools 3.2.5.1 ping ping：确定一个主机是否正常工作 如果目标主机工作，那么他用ICMP报文回答 3.2.5.2 traceroute程序 traceroute程序：追踪中间路由的地址。 利用：【时间超时TTL】+【目的端不可达】两种差错报文。 4. Delivery, Fowarding and Routing Delivery：在网络层的控制下利用底层网络对一个分组进行处理 Forwarding：将一个分组传递到下一个站点的方法 Routing：转发过程中创建路由表的方法 路由选择协议routing protocol：用于不断更新在转发和路由选择中要查找的路由表。 4.1 Delivery delivery：网络层控制下利用底层网络对一个分组进行处理。 直接交付 最后一个路由器与目的主机 源端和目的端在同一个网络 间接交付 源端与目的端不在同一个网络上 ​ Note： 一个传递永远包含一个直接传递和0或若干个间接传递 最后的传递总是直接传递 4.2 Forwarding 转发：将分组路由到他的目的端，转发要主机或者路由器有一个路由表。当主机有分组要发送时，或是路由器已收到一个分组要转发时，就要查找路由表以便求得到达最终目的端的路由。 4.2.1 向前交付技术 路由表的设计： 下一条方法 vs 源路由方法 特定网络 vs 特定主机 默认方法 4.2.2 向前处理过程 假定主机和路由器使用classless addressing。在无类寻址中，路由表对涉及到的每一个地址块都有一行信息。 路由表需要根据网络地址进行查询，但是分组中只有目的地址而没有网络地址，所以我们还需要掩码mask。 在无类寻址中，一个路由表至少要有4列： 其中next-hop address指的是下一个路由器的ip地址。 Example：制作R1的路由表 4.2.2.1 最长掩码匹配规则 路由表中的掩码存放按照从长到短的原则排列，不按此顺序可能出现问题。 使用 CIDR 时，路由表中的每个项目由“掩码”、“网络地址”和“下一跳地址”组成。在查找路由表时可能会得到不止一个匹配结果。 应当从匹配结果中选择具有最长掩码的路由。 掩码越长，其地址块就越小，因而路由就越具体 4.2.2.2 地址聚合 路由汇总 classless addressing将地址空间划分成可管理的地址块。 地址块的增多将增大路由器的寻找： Example： 4.2.3 路由表 a. 路由表 路由：从某一网络设备出发去往某个目的地所经过的路径。路由器通过查询路由表为数据报选择转发路径。 路由表只存在于终端计算机、路由器及三层交换机中，二层交换机中不存在路由表。 路由表中的常用字段： b. 三种路由 直连路由：设备自动发现的路由信息，路由器可自动发现与自己接口直接相连的网络的路由 静态路由：人工输入，无法自动更新。用于小型互联网或试验网络 动态路由：可周期性更新，适合大型网络 c. 动态路由优先级 静态路由的优先级高于动态路由的优先级。 4.3 单播路由协议 static routing table：有人工输入项目，大型网络不适用 dynamic routing table：使得路由表自动更新 需要有动态路由表，所以产生了多种路由选择协议。 4.3.1 优化协议 路由器将收到的分组转发到哪个网络？取决于最优化原则 取决于度量metric meric取决于协议的类型\\begin{cases}RIP：同等对待所有的网络，即通过每个网络的代价都是一样的，跳数都是1\\\\OSPF：允许管理员基于服务类型指定通过网络的代价\\begin{cases}最大吞吐量\\\\最小延迟\\\\....\\end{cases}\\\\BGP：可由网络管理员设置的策略\\end{cases} 4.3.2 域内和域间路由选择 互联网划分为自治系统autonomous system。 autonomous system ：一个单一的管理机构管辖下的一组网络和路由器。 在自治系统内的路由选择称为域内路由选择interadomain routing 每一个autonomous system可以选择一种或者多种域内路由选择协议处理域内路由选择 自治系统之间，通常使用一种域间路由选择协议 \\begin{cases}RIP\\text{ [Routing Information Protocol]}：基于【距离向量Distance\\ vector】的协议\\\\ OSPF\\text{ [Open Shortest Path First]}：基于【链路状态\\ link\\ state】的协议\\\\ BGP\\text{ [Border Gate Protocol]}：基于【路径向量path\\ vector】的协议\\\\\\end{cases} 4.3.3 距离向量路由 在距离向量路由选择中，任何两个节点之间路由的最低代价是最小距离的路径。 每个节点都保留一张到其他的节点的最小向量距离表。每个节点也用这张表表示路由中的下一个节点指导分组流向目的节点。 4.3.3.1 初始化 最开始时：每个节点仅知道与他直接连接的邻站的距离 我们假定一个节点能向邻站发送报文并得到与这些邻站的距离。 初始的表如下： 4.3.3.2 共享 距离向量路由选择的总的思想是与邻站共享路由信息 每个站点向邻站发送完整的表，让邻站决定哪个信息是有用的。 next是没有用的，邻站收到时，需要用发送方的节点名代替 周期性或者有变化时共享表 4.3.3.3 更新 step1：接收节点在表的第二列加上它与发送节点之间的代价值。 step2：将发送节点名作为第3列【发送节点作为next】 step3： 如果下一节点的项目相同，选取新行 如果下一节点项目不同，选取具有代价较小的行，最小代价相同时保持旧项目 什么时候更新？ \\begin{cases}周期性：通常30s\\\\触发更新，路由表有变化时\\begin{cases}节点接收邻站的表，引起自己的表的更新\\\\节点检测到邻站链路有故障\\end{cases}\\end{cases} 4.3.3.4 两个结点循环不稳定性和三个结点循环不稳定性 解决方案： 定义无穷大defining infinity：将一个较小的值定义为无穷大，RIP使用16 分割范围 split horizon：每个节点仅能通过接口发送表的一部分，B的信息是从A获得的，那么这条信息将不会通知给A 在上图中，删除最后一样发送给A，那么问题不会发生 分割范围与毒性逆转Poison Reverse：分割范围与毒性逆转结合起来。节点B依旧通知X的值，但是如果信息源是A，那么用无穷大的距离表示警告 4.3.3.5 RIP协议 RIP：路由选择信息协议，在自治系统内使用域内路由选择协议 RIP基于的事实： 度量为跳数hop 16定义为无穷大——RIP只适用于小型网络 next为发送方 路由器有路由表，网络没有 分类 RIPI：有类路由选择，通知IP可知道地址类型，无需通告掩码 RIPII：支持可变长掩码，掩码需要通知 RIP优点：实现简单，开销较小 RIP缺点： 网路故障时，需要经过较长时间才能将信息传送到所有的路由器 RIP限制了网络规模，他能使用的最大的距离为15 路由器之间交换的路由信息是完整的路由表，因而随着网络的扩大，开销也增大 RIP算法： 注意收到的相邻的节点，所以默认两个节点直接的距离是1.即+1. 4.3.4 链路状态路由 链路状态路由选择与距离向量路由选择基本原理不同：每个节点有该区域的全部拓扑结构 全部拓扑结构\\begin{cases}所有节点和链路的列表\\\\如何连接\\begin{cases}类型\\\\代价\\\\条件\\end{cases}\\end{cases} 基于假设：整个拓扑可以由每个节点的知识复合而成——迪杰斯特拉算法 如果网络中的任意一个点改变，就必须更新整个拓扑。 4.3.4.1 建立路由表 step1：为每个节点建立LSP（link state packet） LSP携带信息： 节点标识 链路清单 序列号：洪泛区别新的LSP和旧的LSP 寿命 LSP生成的时刻： 区域的拓扑发生变化时，让周围的节点知道 周期性：实际上不需要，且周期较长 step2：使用一种可靠的方法向其他的路由器扩散LSP，称为flodding洪泛 洪泛：一个节点准备好LSP后，必须向其他的节点扩散，不仅是相邻节点。 创建节点的LSP，并从每个接口发送LSP 接收到的LSP的节点与已有的副本比较。如果到达的LSP是比较旧的，那么丢弃。如果是比较新的，那么执行 丢弃丢的，保留新的 节点通过每个接口，但是除了接收到分组的接口再发送分组的副本——确保洪泛的停止 step3：为每个节点构成一个最短路径树——Dijkstra step4：基于最短路径树计算路由表 4.3.4.2 OSPF Open Shortest Path First 开放最短路径协议：基于link state的协议 O：”开放”表明 OSPF 协议不是受某一家厂商控制，而是公开发表的。 SPF：“最短路径优先”是因为使用了 Dijkstra 提出的最短路径算法 OSPF 只是一个协议的名字，并不表示其它的路由选择协议不是“最短路径优先”。 a. 区域area OSPF在自治系统的基础上划分区域。一个area是包含在autonomous system中的一些网络，主机和路由器的集合。 自治系统可以划分为不同的区域，在一个区域中的所有网络必须是互相连接的。 区域内：一个区域内通过洪泛传送路由选择信息。——减少通信量 区域边界有区域边界路由器 area border router：将本区域的信息概括起来发送给其他的区域 自治系统中有一个特殊的area称为主干backbone，其他的区域称为从区域secondary area。 自治系统中的所有的区域必须连接到backbone上。 每个区域有一个区域标识，主干区域的标识是0. 4.3.5 路径向量路由 path vector：自治系统之间的路由选择。 原理与距离向量路由选择相似。 4.3.5.1 speaker node path vector routing中，假定每个AS中有一个节点的行为代表了整个自治系统，该节点称为代言节点speaker node。 一个自治系统的speaker node生成一个路由表并且通知相邻的自治系统中的代言节点。 通知的是他的自治系统或者其他自治系统中的路径，而不是节点的跳数 4.3.5.2 初始化 初始化：每个代言节点只知道自己的自治系统内的节点的可达性。 4.5.3.3 共享 每个代言节点与邻站的speaker node共享路由表 A1与C1和B1共享，C1与A1和D1共享........ 4.5.3.4 更新 当代言节点从邻站收到一个两列的路由表时，更新自己的路由表。 更新内容\\begin{cases}增加不在表中的节点\\\\AS与发送方之间的路径\\end{cases} Path Vector Routing优点： 预防回路：避免距离向量路由选择协议的不稳定性和回路问题 策略路由选择：路由器检查报文路径，如果路径中列出的某自治系统不符合策略，则忽略。 优化路径：符合组织机构标准的路径及保密、安全、可靠性等其它原则。 4.3.5.5 BGP 边界网关协议 Border Gateway Protocol 自治系统的类型： 残桩 多接口 转送 特点： 节点数量是自治系统的数量级，比网络数要少很多 BGP代言节点数目很少，交换不复杂 支持CIDR 边界网关协议 Border Gateway Protocol 自治系统的类型： 残桩 多接口 转送 特点： 节点数量是自治系统的数量级，比网络数要少很多 BGP代言节点数目很少，交换不复杂 支持CIDR var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"计网复习笔记/传输层.html":{"url":"计网复习笔记/传输层.html","title":"传输层","keywords":"","body":"传输层 传输层存在的基本理由：进程到进程的传递。 （网络层不对数据报分组进行排序） 传输层的协议的类型\\begin{cases}UDP：简单的协议\\\\TCP：复杂的传输层协议\\\\SCTP：为多媒体这样的多接口与多流应用而设计\\end{cases} 1. 进程到进程的传递 需求： 数据链路层：相邻节点之间的帧传递——节点到节点的传递 node - to - node delivery 网络层：两台主机之间的数据包交换——主机到主机的传递 host - to - host delivery 实际的通信发生在两个进程之间，我们需要进程到进程的传递。 但是任何时刻，源主机上运行着多个进程，并在目的主机上也运行着多个进程。需要某种机制，将源主机上的某个进程的数据传输到目的主机上的对应进程上。 1.1 客户机/服务器模式 Client/Server Paradigm 实现进程到进程间通信的方式：两个进程以客户client/server的方式进行通信。 客户机client：本地主机上的进程称为client，通常需要来自远程主机上的进程提供的服务。 服务器server：远程的主机称为服务器。 这两个进程（客户机和服务器）有着相同的名字。 e.g. 客户机从远程机器上获取日期和时间，需要在本地主机上运行Daytime客户进程和远程机器上运行Daytime服务进程。 目前OS支持多用户和多程序运行的环境。一个远程计算机在同一时间可以运行多个服务器程序。 我们必须定义： 本地主机 local host 本地进程 local process 远程主机 remote host 远程进程 remote process 1.1.1 寻址 需要传送消息到多个目的地之一的某个特定目的地时，需要一个地址。 1.1.1.1 数据链路层的寻址 如果不是点到点连接（点到多点），那么需要一个MAC地址从多个节点中选择一个节点。数据链路层的帧需要： 一个目的端MAC地址用于传送数据 一个源地址用于下一节点的回答 1.1.1.2 网络层的寻址 网络层，需要一个IP地址来选择百万主机中的一个主机。 网络层中的数据报需要一个目的IP地址用来传送数据 需要源IP地址用来接收目的主机的回答 1.1.1.3 传输层 端口号 port number：传输层地址，利用这一地址从目的主机上运行的多个进程中选择相应的进程。 目的端口号用于传送 源端口号用于接收回答 端口号为0~65535之间的16位整数 1.1.2 临时端口号与熟知端口号 客户机的端口号（ephemeral port number）：自己定义的，运行在客户机上的传输层软件随机选择，这是临时端口号（ephemeral port number ）。 服务器的端口号（well-known port number）：这个端口号不能随机选择。如果随机选择，那么访问这个服务器时将不知道端口号。使用全局端口号——熟知端口号（well-known port number）。 当然，有时，一些客户端也被分配了熟知端口号。 1.1.3 IANA范围 端口号地址被IANA划分成三种范围： 端口号地址的范围\\begin{cases}Well-known\\ \\ ports\\begin{cases}范围：0--1023\\\\性质：由IANA分配\\end{cases}\\\\Registered\\ \\ ports：\\begin{cases}范围：1024--49152\\\\性质：IANA不分配也不控制，可以在IANA注册防止重复\\end{cases}\\\\Dynamic\\ \\ ports\\begin{cases}范围：49152--65535\\\\性质：不受控制也不需要注册，可以由任何进程使用\\end{cases}\\end{cases} 1.1.4 套接字地址 进程到进程传递需要两个标识符：IP地址和端口号。 套接字地址Socket Address：IP地址和端口号的结合。 \\begin{cases}客户套接字：唯一定义了客户机进程\\\\服务器套接字：唯一定义了服务器进程\\end{cases} 传输层协议需要一对套接字地址：客户机套接字地址和服务器套接字地址。 IP头部：IP地址 UDP/TCP头部：端口号 1.2 无连接的服务和面向连接的服务 传输层协议可以是无连接的或者是面向连接的服务。 1.2.1 面向无连接的服务 分组从一方发给另一方，不需要建立连接和释放连接。 隐患：分组没有编号。可能延迟，丢失，无序到达。无确认过程。 UDP是无连接的。 1.2.2 面向连接的服务 面向连接的服务中，在发送方和接收方之间建立一个连接，然后传送数据，最后释放连接。 TCP和SCTP是面向连接的。 1.3 可靠服务和不可靠服务 1.3.1 可靠服务和不可靠服务的应用 传输层的服务有可靠的和不可靠的，主要是使用可靠的协议或者是不可靠的协议实现的。 传输层服务\\begin{cases}可靠服务\\begin{cases}需求：应用层需要可靠性，那么使用可靠服务\\\\传输层实现流量控制和差错控制\\\\服务较慢或者更复杂\\end{cases}\\\\不可靠服务\\begin{cases}需求：不需要可靠性，使用自己的流量和差错控制\\\\需要快速服务或者本质特性不要求流量和差错控制（如，实时应用）\\end{cases}\\end{cases} 1.3.2 协议的可靠性 UDP：不可靠协议 TCP和SCTP：可靠协议 1.3.3 传输层提供可靠性的必要性 原因： 数据链路层的可靠性只存在于两个节点之间，而我们需要端到端的可靠性。 网络层是不可靠的（尽力传递），必须在传输层实现可靠性。 TCP使用滑动窗口协议实现差错控制和流量控制。 1.3.4 三种协议 三种协议在TCP/IP协议簇中的位置。 TCP和UDP的应用场景： TCP应用场景 （1）客户端和服务器需要多次交互才能实现特定功能。如接收邮件和发送邮件。 （2）接收的邮件需要分段传输。如浏览器访问网页时，网页中的图片和HTML文件需要分段后发送给浏览器，QQ传送文件时也需要分段，此时使用TCP协议 UDP应用场景 （1）客户端程序和服务器端程序通信，应用程序发送的数据包不需要分段。如域名解析时的请求报文和返回的解析结果。 （2）实时通信。 （3）多播或者广播。 2. UDP（User Datagram Protocol） 用户数据报协议（UDP）：无连接不可靠传输层协议。 UDP提供服务： 提供进程到进程通信而不是主机到主机通信，没有给IP服务增加任何东西。 提供非常有限的差错检验。 UDP优点： 开销最小。如果一个进程要发送很短的报文，且不在意可靠性，那么可以使用UDP。 2.1 熟知端口号 UDP使用的熟知端口号： 2.2 用户数据报 UDP分组称为用户数据报 User datagram：8字节固定头部 用户数据报的字段： 源端口号 在源主机上运行的进程使用的端口号：16位。端口号范围为0-65535。 对于客户端：大多是情况下是临时端口号 服务器：大多数情况下是熟知端口号 目的端口号 和源端口号类似 总长度 16位字段，定义了用户数据报的总长度，头部加上数据。 总长度是65536.但是UDP数据报必须比这个小，UDP数据报存放在具有总长度为65536字节的IP数据报中。 实际上这个字段是没有必要的。IP数据报中有定义总长度字段。 UDP长度 = IP长度 - IP头部长度 2.3 校验和 UDP分组的校验和和IP以及ICMP校验和的计算不一样。UDP校验和包括三个部分： UDP校验和\\begin{cases}伪头部\\\\UDP头部\\\\从应用层来的数据\\end{cases} 2.3.1 伪头部 IP分组头部的一部分，其中某些字段要填入0，用户数据报封装在IP分组中。 伪头部在IP数据报头部破坏时，确保不会被提交到错误的主机 协议字段可确保这个分组属于UDP，而不属于其他的传输层协议。如果在传输过程中这个值改变了，在接收端计算校验和时可以检验出来，UDP可以丢弃这个分组，不会传递给错误的协议 2.3.2 可选校验和 校验和的计算以及在用户数据报中包括的校验和都是可选的，如果不进行校验和的计算，那么这些字段就填入全1。 注意：校验和时全1是不可能的（想象一下，只有数据全是0时才会出现校验和是全1的情况，而这是不可能的） 2.4 UDP操作 2.4.1 无连接的服务 connectionless service 无连接服务：UDP发送出去的每一个用户数据报都是独立的数据报，每个数据报之间没有关系。 用户数据报不进行编号。 不进行连接的建立和连接中止——每一个用户的数据报可以沿着不同的路径传递。 2.4.2 流量控制和差错控制 流量控制 UDP没有流量控制，没有窗口机制，如果到达的报文太多，接收方可能会溢出。 差错控制 UDP没有差错控制，假如接收方使用校验和检测出差错时，就丢弃 由于缺少流量控制和差错控制，使用UDP的进程必须要提供这些机制。 2.4.3 封装和拆封 从一个进程发送到另一个进程，UDP协议就要将报文在IP数据报中进行封装和拆封。 2.4.3.1 排队Queuing 端口的实现：队列与端口的实现是联系在一起的。 客户机端，进程启动时从OS请求一个端口号。 请求的端口号\\begin{cases}有些实现创建一个入队列和一个出队列，与每一个进程相关联\\\\有些只创建与每一个进程相关联的入队列\\end{cases} note：如果一个进程想与多个进程通信，那么也只得到一个端口号，而最后也只有一个出队列outgoing queue和入队列 incoming queue。进程撤销时，队列撤销。 排队过程： a.客户机的队列创建 客户机进程使用在请求中指明的源端口号将报文发送到出队列。UDP逐个将报文取出，加上UDP头部交给IP。 出队列可能会发生溢出，操作系统要求客户进程在继续发送报文之前要等待。 当报文到达客户端时，UDP检查一下确认用户数据报中的目的端口号字段指明的端口号有创建入队列。 如果有：UDP将接收到的用户数据报放在该队列的末尾 如果没有：UDP丢弃该数据报，请求ICMP发送目的端不可达报文 入队列可能会溢出，溢出时向服务器发送端口不可达报文。 b.服务器的队列创建 最简单的形式：服务器在开始运行的时候就用熟知端口请求入队列和出队列。只要服务器运行，那么队列就一直是打开的。 2.4.4 UDP的使用 UDP适用的应用如下： 需要简单的请求-响应通信，较少考虑流量控制和差错控制 适用于内部有流量控制和差错控制的进程 多播 可用来管理进程，如SNMP 可用于路由选择更新协议，如RIP 3. TCP 传输控制协议Transmission Control Protocol： 面向连接的协议。为发送数据在两个TCP之间建立一个虚拟连接。 TCP在传输层适用差错控制和流量控制 TCP是可靠的协议，为IP服务增加了面向连接和可靠性的特性 3.1 TCP服务 3.1.1 进程到进程的通信 TCP's well known ports 3.1.2 流传递服务 3.1.2.1 字节流形式的传递 TCP是面向流的协议。TCP允许发送进程以字节流 stream of bytes的形式传送数据。 TCP建立一种环境，两个进程好像是由一个假象的“管道”进行连接，管道通过因特网传输进程的数据。发送进程产生（写入）字节流，接收进程消费（读出）这些字节流。 3.1.2.2 发送和接收缓冲区 由于发送和接收进程可能以不同的速度写入和读出数据，所以TCP需要用于存储的缓冲区。 每个方向都有一个缓冲区 缓冲区\\begin{cases}发送缓冲区\\begin{cases}空存储单元，可由发送进程填充\\\\已经发送但未确认\\\\将要发送的字节\\end{cases}\\\\接收缓冲区\\begin{cases}空存储单元\\\\接收到的存储单元，可以由接收进程读出\\end{cases}\\end{cases} 缓冲区用于实现TCP的流量控制和差错控制 实现缓冲的一种方法：使用循环数组； 缓冲区通常是上百或者上千个字节，取决于实现方法。 实际上缓冲区的大小也不一定是一样的。 3.1.2.3 段 IP层作为TCP服务的提供者，需要以分组的形式而不是以字节流的形式发送数据。 段：传输层中，TCP将多个字节分组合在一起成为一个分组。这个分组称为段。 TCP给每个段添加头部（控制目的），然后将该段传递给IP层。段被封装到IP数据报中，然后再进行传输。 这些段可能被无序接收，丢失，损坏和重发。均由TCP处理。 一切对接收进程透明。 3.1.3 全双工服务 数据可以在同一时间双向流动。每一方TCP都有发送和接收缓冲区，他们能在双向发送和接收段。 3.1.4 面向连接的服务 TCP是面向连接的协议。站点A的一个进程要发送和接收来自站点B的数据时，步骤如下： 在两个TCP之间建立一个连接——虚连接 在两个方向交换数据 连接中止 3.1.5 可靠的服务 TCP使用确认机制acknowledgment mechanism来检查数据是否安全和完整到达。 3.2 TCP特点 3.2.1 序号系统 TCP的段没有段特有的段序号，TCP在段头采用序号（sequence number）和确认号（acknowledgement number） 字节序号byte number：TCP为每一个字节进行编号。 byte number的特点： 每个方向上的序号都是独立的。 存储在缓冲区时进行编号 在$0\\sim 2^{32}-1$之间生成一个随机数作为第一个字节的序号（不一定是从0开始编号的） （1）序号 Sequence Number TCP对发送的每一个段分配一个序号，每个段的序号是这个段中的第一个字节的序号。 当一个段携带数据和控制信息时，使用一个序号；如果一个段没有携带用户数据，那么逻辑上不定义序号。虽然字段存在，但是是毫无意义的。 （2）确认号 acknowledgment number TCP通信是全双工的，每一方使用确认号来确认已经收到的字节。 确认号定义了该方预期接收的下一个字节的序号。确认号是累积的（累计确认）：确认号 = 收到的最后一个字节 + 1 = 预期接收的下一个字节。 3.3 TCP段格式 段\\begin{cases}头部：20--60\\ bytes\\begin{cases}固定头部：20bytes\\\\选项\\end{cases}\\\\ 应用层的数据\\end{cases} 源端口地址Source port address：16位字段，定义发送方的端口号 目的端口地址Destination port address：16位字段，定义接收方的端口号 序列号 Sequence Number：32位字段，是段中的第一个字节的编号。 确认号Aknowledge Number：32位字段，定义了期望从发送方接收到的字节号。确认号 = 发送方的字节号 + 1。捎带：确认和数据可以一起发送，称为捎带。 头部长度Header Length：4位字段，单位为4字节。头部的长度在20bytes到60bytes之间，因此，min = 0101 = 5，max = 1111 = 60 保留 reserved：保留，未使用 控制 control：定义了6种不同的控制位或者标记，同一时间可以设置一位或者多位 control\\begin{cases}URG:紧急指针有效，置1时表示数据紧急，将紧急数据放在段的开始\\\\ACK：确认有效\\\\PSH：请求急迫，发送端的TCP窗口不必等待窗口被填满，这个段包含的数据必须尽快地发送给解释程序\\\\RST：连接复位\\\\SYN：同步序列号\\\\FIN：终止连接\\end{cases} 窗口大小Window Size：16位字段，对方必须维持的窗口大小，单位为bytes：窗口的最大长度为65536字节。称为接收窗口rwnd，由接收方确定。——流量控制 校验和CheckSum：16位字段，TCP与UDP校验和计算过程相同，但是校验和对UDP来说是可选的，但是对TCP来说是强制的。对于TCP的伪头部，协议字段的值是6。 紧急指针字段 Urgent Pointer：16位字段，当紧急指针标志位置位时才有效，当段包含了紧急数据时使用。这个数字加上序列号就是紧急数据的最后一个字节。——紧急数据放在段的最开始 选项Options：TCP只规定了一种选项，即最大报文长度MSS。MSS是TCP数据报中的数据字段的最大长度。数据字段加上TCP首部才是整个的TCP数据报。 3.4 TCP连接 网络层提供的服务不可靠，给传输层带来了很大的困难： 段丢失 段失序 传输层需要解决的问题： 连接的建立和终止 【虚拟链接，获得相同的服务】 有序交付 副本检测 【新段or重发段】 重传策略 故障恢复 流量控制 拥塞控制 TCP是面向连接的协议：源端和目的端之间建立一条虚路径，属于一个报文的所有段沿着虚路径发送——有利于处理帧的丢失和丢失帧的重发。 IP不知道TCP的重新排序的过程。 面向连接的传输有三个阶段： 连接建立 数据传输 连接中止 连接建立要解决的问题： 要使每一方都能确认对方的存在 允许双方协商参数 参数\\begin{cases}最大报文长度\\\\最大窗口大小\\\\服务质量\\end{cases} 能够对传输资源进行分配 传输资源\\begin{cases}缓存大小\\\\连接表中的项目\\end{cases} 3.4.1 连接建立 TCP：全双工，数据传输双方都需要对通信进行初始化，并得到对方的认可。 3.4.1.1 三次握手 Three- Way Handshaking （例子背景：客户要与服务器建立连接），过程如下： 服务器请求被动打开：服务器告诉TCP，他已经准备好接收一个连接，称为请求被动打开passive open 客户机请求主动打开：想要与服务器进行通信的客户机告诉他的TCP，需要连接到特定的服务器，TCP进行三次握手的过程： （1）客户发送第一个SYN段，这个段仅有SYN被置位，用于序列号同步。 SYN占用一个序列号。当数据开始传输时，序列号加1。（仅有ACK不会+1） （2）服务器发送第二个段，两个标志位SYN和ACK被置位。表示另一方向通信的SYN段，并且用ACK标志表示对第一个SYN的确认，占用一个序列号 （3）客户机发送第三个段，仅仅是一个ACK段，用ACK标志和确认号序列表示已经收到的段。这个段的序列号与SYN段的序列号相同，ACK段没有占用任何序列号。 Note: 单独的ACK如果不携带数据，则它不占用序列号。 SYN不携带数据，但是占用一个序列号 SYN+ACK不携带数据，但是占用一个序列号 3.4.1.2 同时打开 Simultaneous Open 两个进程都发出主动打开的情况，极少发生。这种情况下，双方同时发出SYN+ACK段，在他们之间建立一条单独的连接。 3.4.1.3 SYN洪泛攻击 SYN洪泛攻击：攻击者将大量的SYN段发送到一个服务器，在数据报中通过伪装IP地址假装这些段来自不同的客户端时就发生了这种情况。 属于拒绝服务供给，使服务器资源耗尽。 TCP某些实现有减轻SYN攻击影响的策略： \\begin{cases}在短期内对请求的链接进行限制\\\\过滤掉来自不需要的源地址的数据报\\\\使用cookie推迟资源分配直到一个完整的链接建立\\end{cases} 3.4.2 数据传输Data transfer 3.4.2.1 传输过程 连接建立后可进行双向数据传输data transfer，客户机和服务器双方都发送数据和确认。 在段内携带确认时，也可以传输数据：数据捎带确认 data piggybacked with the data 3.4.2.2 急迫数据 非急迫情况 TCP使用缓冲区存储来自发送方应用程序的数据流。发送方TCP可以选择段的大小。接收方在数据到达时也将数据进行缓存。并在应用程序准备就绪或者是接收方TCP认为合适的时候就将这些数据传递给应用程序。灵活性增加了TCP的效率。 急迫情况 比如双方的应用进行交互式通信，总是希望接收方能够立即响应，数据的延迟传输和延迟传递是不可接受的。 PUSH置位时就表示这个段包含的数据必须尽快传送给应用程序，不需要等待更多的需求。 TCP可以选择使用或者不使用这个操作。 3.4.2.3 紧急指针 URG位置位，紧急数据放在段的开始。段的其他部分可以包含普通数据。 EXAMPLE：处理数据时异常终止数据Ctrl +C 3.4.3 连接中止 Connection Termination 交换数据的任一方均可关闭连接，通常由客户端发起。关闭连接的方法有两种： \\begin{cases}三次握手Three-Way Handshaking：大多数实现\\\\带有半关闭选项的四次握手Half-Close\\end{cases} 3.4.3.1 三次握手 （1）客户进程接收到关闭命令时，客户的TCP发送第一个段：FIN段，FIN段的FIN被置位。 FIN段可以携带客户机要发送的最后一个数据块。或者只是一个控制段。只是一个控制段时仅占用一个序列号。 （2）服务器TCP接收到FIN段后，通知他的进程，并发送第二个段：FIN+ACK段，证实它接收到来自客户端的FIN段，同时通告另一方连接关闭。这个段可以包含来自服务器的最后一个数据块。如果不携带数据，那么该段仅占用一个序列号。 （3）客户机TCP发送最后一段：ACK段。证实收到来自服务器的FIN段。包含了确认号，是来自服务器的FIN段的序号加1。该段不占用序列号。 3.4.3.2 带有半关闭的四次握手 half-close：当一端停止发送数据后，还可以继续接收数据。 任意一端可发送数据，但通常是由客户端发起的。 3.5 流量控制 TCP使用滑动窗口处理流量控制 3.5.1 特点 TCP使用的滑动窗口协议介于Go-Back-N和Selective Repeat之间 不使用NAK，看起来像Go-Back-N帧协议 保存失序帧直到丢失的段到达 TCP窗口的滑动窗口是面向字节的，数据链路层讨论的滑动窗口是面向帧的。 TCP窗口大小可变，数据链路层的窗口大小是固定大小 3.5.2 TCP窗口 使用TCP窗口使数据传输更有效，同时控制数据流，使得目的端不至因为数据来得过多而瘫痪。TCP窗口是面向字节的。 滑动窗口的数据分类： 滑动窗口数据分类\\begin{cases}左窗口外：已经发送且已经确认\\\\窗口内\\begin{cases}窗口内左侧：已经发送但未确认\\\\窗口内右侧：可以立即发送\\end{cases}\\\\右窗口外：不满足发送条件，暂时不可发送\\end{cases} 动作分类\\begin{cases}closing：得到确认\\\\opening：运行缓冲区存储符合发送条件的更新的字节\\\\shinking：废除某些符合条件的字节发送\\end{cases} 3.5.3 窗口的大小 TCP窗口大小取决于两个值中较小的一个：$\\min{rwnd, cwnd}$ 接收窗口：在确认段中宣布的值 拥塞窗口：网络防止拥塞而确定的值 TCP的发送方不必发一个全窗口大小的数据。 TCP窗口的要点如下： 窗口大小是rwnd和cwnd中最小值 发送方不必发送一个全窗口大小的数据 接收方可张开或者合拢窗口，但是不能收缩窗口 只要不引起窗口收缩，目的方随时可以发送一个确认 接收方可以暂时关闭窗口，但在窗口关闭后发送方总是发送一个字节的段 4.TCP通知窗口 通知窗口是接收方根据接受能力确定的窗口。接收方将通知窗口的值放在报文首部发送给发送方。发送方根据接收方的工作状态改变窗口大小是TCP流量控制的主要方法。 如果接收方读取速度与到达速度一样，接收方在每一个确认中发送一个非零的窗口通告。如果发送方比接收方快，造成缓冲区全部被占用，那么接收方发送一个“零窗口”通告，发送方停止发送。直到收到一个非零窗口通告。 5.坚持计时器 非零窗口通告可能会丢失，TCP为每个连接设置了一个坚持计时器，当发送方收到零窗口确认时，就启动坚持计时器。计时器到期后，发送探测报文，提醒接收方确认报文已经丢失。 6.糊涂窗口综合征 如果TCP缓存已满，而应用进程每次只从缓存读取一个字节。向发送窗口发送为1的确认报文，此时发送方会以41字节的代价发送1字节的数据。这样下去，传输效率及低。 解决方法是禁止接收方发送只有1个字节的更新报文，接收方会等待一定的时间，使得收取缓存有足够空间接收一个较长的报文，再发送窗口更新报文。 3.6 差错控制 TCP的差错控制包括检测出报文的差错，丢失，失序和重复并纠正。 差错检测和纠正的方式\\begin{cases}校验和Checksum\\\\确认Acknowledge\\\\重传Retransmission\\end{cases} 3.6.1 校验和 如果段受到损坏，那么将被目的端TCP丢弃，并且认为是丢失了。TCP在每段中强制使用一个16位的校验和。 3.6.2 ACK TCP使用确认来证实已经收到了数据段。不携带数据但是占用序列号的一些控制段也要确认，但单独的ACK段是不需要确认的。 3.6.3 重传 3.6.3.1 RTO（retransmission time-out）后重传 重传计时器 TCP对所有重要的段（已经发送但是还未确认）使用一个重传超时计时器。 当计时器到时时，即使可能是由于段被延迟，ACK被延迟或者是ACK被丢失等未接收到ACK时，重发一个最早的重要的段。 仅仅含有ACK的段没有设置超时计时器，这样的段不需要重发。 RTO计时器的值根据RTT更新 RTO的值是动态的，根据段的往返时间（Round-Trip Time）进行更新。 3.6.3.2 快速重传 收到3个重复的ACK。在重传计时器超时之前进行重传。 3.6.4 段的失序 当一个段被延迟、丢失或者废弃，后面到达的段就失序了。 \\begin{cases}TCP原先设计：丢弃失序的段，并且重传失序段后面的段\\\\TCP现在设计：\\begin{cases}不丢弃失序的段，标记他们为失序，直到缺少的段到达\\\\这些失序的段不传递给进程，TCP确保数据按序传递给进程\\end{cases}\\end{cases} 3.6.5 TCP操作 3.6.5.1 一般操作 3.6.5.2 丢失的段 TCP对于丢失的段和损坏的段做同样的处理。 丢失段在网络某处丢失，损坏段被接收方本身丢弃。 TCP在间隙指明数据存在不连续性，在这个间隙被填充之前不将这个字节传递给应用程序。 3.6.5.3 快速重传 收到三个连续的同样序号的ACK时，不必等待RTO计时器过期，立即重传期待帧 3.7 拥塞控制 网络中的载荷即发送到网络中分组的数量，超过了网络的容量，在网络中就有可能发生拥塞。 3.7.1 拥塞窗口 发送方维护一个拥塞窗口cwnd，且动态变化。发送方让自己的发送窗口小于等于cwnd。 只要网络没有发生拥塞，拥塞窗口就再增大一些，以发送更多的分组。 假如发生拥塞，那么将拥塞窗口减小一些，减少到发送到网络中的分组数。 3.7.2 拥塞策略 TCP的拥塞策略基于三个阶段： 慢启动 slow start：以很慢的传输速率启动，迅速增大到阈值 threshold 拥塞避免 congestion avoidance：达到阈值后为避免拥塞降低数据速率 拥塞检测 congestion detection：检测到拥塞返回到慢启动或者拥塞避免 3.7.2.1 慢启动：指数增长 慢启动使用 指数增长，在一开始设置拥塞窗口cwnd为一个最大段长度MSS（连接建立时由最大长度选项决定） 每次收到一个确认，窗口大小增加一个MSS值。 窗口慢速启动，但是按照指数规则增长。 EXAMPLE：假设使用段的个数而不是字节的个数（好像每个段只有一个字节）； ​ 假定rwnd比cwnd大得多，这样发送窗口永远小于等于cwnd。 ​ 假设每个段都是单独确认的。 按照传输次数观察cwnd的大小（整个窗口中的段被确认），则发现其速率是按照指数的规则增长。数据增长的规律： 开始：cwnd = 1 第一次传输：cwnd = 2 第二次传输：cwnd = 4 第三次传输：cwnd = 8 如果有延迟的ACK，那么窗口的增长小于2的幂。 慢速启动不能一直持续下去，达到阈值时必须停止该阶段。发送方保存一个称为ssthresh（慢启动阈值）的变量。 当拥塞窗口中的字节达到阈值时，开始下一个阶段，ssthresh的值是2^16字节 3.7.2.2 拥塞避免：加性增加 拥塞避免的目的：在拥塞发生之前降低指数增长的速度。这个算法是加性增加，而不是指数增加。 加性增加：每次整个窗口的所有的段都被确认时，拥塞窗口才加1。（直到检测到数据丢失） 按照传输的次数观察cwnd的大小，则发现其速率是按照加性规律增长： 开始：cwnd = 1 第一次传输后：cwnd = 2 第二次传输后：cwnd = 3 第三次传输后：cwnd = 4 3.7.2.3 拥塞检测 能够检测到拥塞唯一方法是通过重传段的要求 \\begin{cases}严重情况：RTO计时器到期\\\\接收到三个ACK\\\\\\end{cases} RTO计时器到时：非常严重的拥塞的可能性 TCP反应： 阈值减少到当前拥塞窗口大小的一半 设置cwnd为一个段的大小 启动慢速启动阶段 连续接收到三个ACK：存在轻度拥塞的可能性 TCP反应： 阈值减少到当前拥塞窗口大小的一半 设置cwnd为阈值 启动拥塞避免阶段 策略总结： 策略\\begin{cases}RTO超时\\begin{cases}阈值变为当前拥塞窗口大小一半\\\\设置cwnd为1个段的大小\\\\开启慢启动状态\\\\\\end{cases}\\\\收到三个ACK\\begin{cases}阈值变为当前拥塞窗口的一半\\\\拥塞窗口值为阈值\\\\开启拥塞避免状态\\end{cases}\\end{cases} 4. SCTP 流控制传输协议 特点： 面向报文的可靠协议 兼具UDP和TCP的最佳特性 多流的概念： 多端口的概念： 在SCTP中，数据大块按照传输序列号编号。控制信息和数据信息在分开的数据大块中携带。 为了别不同的流，SCTP使用SI。（流标识符） var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"计网复习笔记/应用层.html":{"url":"计网复习笔记/应用层.html","title":"应用层","keywords":"","body":"应用层 1. 域名系统 1.1 使用背景 在Internet的应用层中，许多应用都遵循客户机client/服务器server模式。客户端/服务器应用程序分为两类： 一种可以直接被用户使用：e-mail 支持其他应用程序的应用程序：DNS DNS是一种支持程序 TCP/IP使用IP唯一确定一台主机到因特网的连接。名字比IP更容易记忆。需要实现名字到地址或者地址到名字的映射系统。 map name to a address or map address to a name 因特网发展初期，使用主机文件(host file)实现映射。 host file构成 一列是名字 一列是地址 每台主机主机文件存储在磁盘中，并以一个标准主机文件为依据，定期进行更新。当程序或者用户需要将某一名字映射到一个地址时，主机就查询主机文件。 问题： 主机文件太大，无法存储在每一台计算机中 每次发生变化时，无法更新世界上的所有主机 解决： 方案1：存储在一台单独的主机上，允许每一台需要映射的计算机访问这个集中化的信息。 缺点：造成较大的通信量 方案2：将巨大的信息分成很多很小的部分，每一部分存储在不同的计算机中。 需要映射的计算机可以寻找最近的一台持有信息的计算机。 1.2 名字空间 分配给机器的名字必须从名字空间name space 中选择。 【IP地址唯一】----->【名字唯一】 Name Space按两种方式进行组织： \\begin{cases}Flat\\\\Hierarchical\\end{cases} 1.2.1 平面地址空间 一个名字分配个一个地址，空间中的名字是一个无结构的字符序列 a sequence of characters without structure。名字之间也可能没有公共部分；即使有公共部分，也没有实际含义。 缺点： 必须集中控制才能避免二义性和重复性 1.2.2 层次化地址空间 名字的组成\\begin{cases}part1：组织的性质\\\\part2:组织的名字\\\\part3:组织的部门\\\\.......\\end{cases} 分配和控制名字的机构可以分散化decentralied， 组织的性质和名字可以由中央组织定义，其他部分的分配可以交给这个组织自身。 1.3 域名空间 为了获得层次结构名字空间，设计了Domain Name Space。所有的名字由根在顶部的倒置的树结构定义： 树最多有128级：0级~127级 1.3.1 标签 树上的每一个节点有一个label，label最多为63个字符。根节点的标号是一个空字符串null DNS要求同一节点分出来的子节点有不同的label：确保名字的唯一性。 1.3.2 域名 每一个节点都有一个域名。 一个全的domain name是用.分割的标识号序列。 domain name总是从节点向上读到根节点。最后一个标号是根节点的标号。这表示一个完全的域名总是以一个空标号结束，即最后一个字符是. 1.3.2.1 Fully Qualified Domain Name 如果一个label以空字符串结束，那么他就是全称域名full qualified domain name 全称域名包含一台主机的所有名字的域名。它包含所有的标号，从最具体的标号到最一般的标号，能唯一定义一台主机的名字，如： challenger.act.fhda.edu. 是一个全称域名。 1.3.2.2 Partially Qualified Domain Name 如果一个域名不是以空字符串结束，那么称为部分域名partially Qualified Domain Name 当这个需要解析的名字属于和客户端相同的站点same site时，使用部分域名。解析程序能提供省略的部分，称为后缀suffix，以创建FQDN。 1.3.3 域 domain是域名空间的一棵子树。 域的名字是树顶部节点的域名。 一个域本身也可以划分为多个域，即子域subdomain 1.4 分布式名字空间 一台计算机存储的问题： 通信量大 不安全 1.4.1 名字服务器的层次结构 将信息分布在多台称为DNS服务器（DNS server）的计算机中。 一种方法：将整个空间划分为基于第一级的域，并进一步划分为更小的subdomain。 每一台服务器对一个大的域或者较小的域是负责的 与建立名字的层次结构一样，也建立了服务器的层次结构 1.4.2 空间 一个服务器responsible或者has authority的范围称为一个Zone。 Zone和Domain的区别： 如果一个服务器负责一个域，并且这个域没有被划分更小的subdomain，那么此时domain和zone是相同的。 如果被划分为更小的subdomain 子节点的信息会放在更低层次的服务器中 原来的服务器只保存这些较低服务器的某种参照 1.4.3 根服务器 Root Server：whose ZONE consists of the whole tree 根服务器通常不保存关于域的任何信息，只是将其授权给其他的服务器，并保存这些服务器的参照关系。 目前有多个根服务器，每一台都覆盖了整个域名空间， 这些服务器分布在世界各地。 1.4.4 主服务器和辅服务器 DNS定义了服务器类型\\begin{cases}\\text{primary server}\\\\\\text{secondary server}\\end{cases} primary server：存储了授权区域有关文件的服务器，它负责创建creating、维护maintaining和更新updating区域文件，并将区域文件存储在本地磁盘中。 secondary server：从一个服务器（主服务器或者是辅服务器）传输transfer一个区域的全部信息，并将文件存储在它的本地磁盘中。辅助服务器既不创建也不更新区域文件。如果需要更新，那么必须是由主服务器完成，由主服务器发送到辅助服务器。 一台服务器可能是某个特定区域的主服务器，也可能是别的区域的辅服务器。 主服务器能够从磁盘文件中装载所有信息，辅助服务器从主服务器中装载信息。 当辅助服务器从主服务器中下载信息时，这称为区域的传递。【辅服务器作为备份】 1.5 网络中的DNS 域名空间被划分为三个部分： Domain\\ name \\ space\\begin{cases}Generic\\ domains\\\\Inverse \\ domain\\\\country\\ domains\\end{cases} 1.5.1 通用域 Generic domain：按照已经注册主机的一般行为对主机进行定义。 树中的每一个节点定义一个域，他是域名空间数据库的一个索引。 1.5.2 国家域 country domain使用两个字母的国家缩写，如us代表美国，第二级Label是组织机构，如州。 1.5.3 反向域 inverse domian用于将地址映射为名字。 应用：反向或者指针PTR查询。 1.6 解析 name-address resolution：将名字映射为地址或者将地址映射为名字 1.6.1 解析程序 DNS是一个客户机/服务器应用程序，需要将地址--->名字或者名字--->地址时需要调用一个解析程序resolver的DNS服务程序。 resolver用一个映射访问最近的一个DNS服务器，然后进行递归解析或者迭代解析。 1.6.2 绑定名字到地址 名字到地址的映射：DNS服务器检查通用域或者国家与查找相应的映射 1.6.3 绑定地址到名字 地址到名字的映射：DNS服务器进行PTR查询，使用inverse domian。 IP地址必须反过来，并将in-addr和arpa两个标号附加在最后，以创建反向域能够接收的域。 1.6.4 递归搜索 客户端解析程序从名字服务器中请求递归应答的方式： 如果服务器是这一域名的授权服务器，他会检查数据库并做出相应 不是授权服务器，通常会发给父服务器，并等待响应。 ......一直迭代向上....直到找到 找到后迭代返回 1.6.5 迭代搜索 客户端解析程序从名字服务器中没有请求递归应答，那么映射可以以迭代的形式进行 如果服务器时该名字的授权服务器，那么发送应答 不是，它返回那个他认为可以解析该查询的服务器地址 1.6.6 缓存 服务器向另一个服务器请求映射并得到回应时，将回应发送回客户端之前，先将信息存储在高速缓存中。 下次查询时通过高速缓存解决问题。但是通知这个响应来自高速缓存而非授权信息。 高速缓存存在问题： 映射过期 解决方式： TTL信息添加在映射上，TTL定义了服务器可以将信息放入高速缓存的时间，超时后该信息无效 每一台服务器对每一个映射保留一个TTL计数器。高速缓存定期检查，清除TTL已经过期的映射 2. 远程登录、电子邮件和文件传输 因特网的服务\\begin{cases}remote\\ logging\\\\e-mail\\\\File\\ transfer\\end{cases} 2.1 远程登录 需求：用户希望在远程网站上运行许多个程序run application programs at a remote site，但是产生的结果能传送到本地的网站。 无法为每一个服务创建客户/服务器应用程序。 更好的方式是使用通用的general - purse 客户/服务器程序，让用户能访问远程计算机上的所有的应用程序。 允许用户在远程计算机上登录-----登录后使用计算机提供的服务------结果返回到本地的计算机上 2.1.1 TELNET TELNET是一个通用的客户/服务应用程序。 2.1.2 Logging 本地登录 local log-in ：登录到本地的分时系统，称为本地登录。 ​ 过程： 用户击键或者运行仿真程序 击键被终端驱动程序所接受 终端驱动程序将字符传递给操作系统 操作系统解释字符，调用所需的应用程序或者实用程序 远程登录 remote log-in ：需要使用TELNET 过程 使用TELNET客户程序和服务器程序 击键发送给终端驱动程序 本地OS接受字符，但并不解释 字符被送到TELNET客户机，TELNET将字符转换成网络虚拟终端NVT字符的通用字符集 传送给本地的TCP/IP协议栈 将NVT文本通过因特网传输到远程的TCP/IP协议栈 传给那里的OS 传送给远程的TELNET服务器，TELNET服务器将其转换成远程计算机可以理解的字符 字符传送给伪终端驱动程序 最后传送给OS，在传送给适当的应用程序 2.1.3 网络虚拟终端 异构的系统 heterogeneous systems 打交道：TELNET定义了一个通用的接口network virtual terminal NVT。 客户TELNET将来自本地终端的字符转换为NVT形式，然后传递给网络 而服务器TELNET将来自NVT形式的数据或者命令转换成远程计算机可以接受的形式 NVT字符集【NVT character set】 两者都是八位字符集 \\begin{cases}数据字符data \\ character：最高位为0\\\\控制字符control\\ character：最高位为1\\end{cases} 2.1.4 Embeding TELNET使用一个TCP/IP连接，服务器使用熟知端口23，客户使用临时端口 使用同一个连接发送数据字符和控制字符。 TELNET将控制字符嵌入到数据字符中：区别数据和控制字符时使用控制解释IAC 2.1.5 Options TELNET提供额外的协商选项，提供额外特性。 使用控制字符来定义选项： Options Negotiation 选项协商 为使用上述选项，使用4个控制字符： WILL：请求激活；接收激活 WONT：决绝请求激活；提供禁止选项 DO：同意激活选项；请求激活选项 DONT：同意禁止选项；请求禁止选项 希望回显的例子： suboption negotiation 子选项协商 有些选项需要附加信息，如定义一个中断的类型或者速率，协商要包括一个字符串或者数字来定义类型或者速率。 （6）Mode of Opration 操作方式\\begin{cases}default \\ mode默认方式：回显由客户完成，一行完成前不发送\\\\ character\\ mode字符方式：每一个字符从客户机发送给服务器\\\\line\\ mode行方式：行编辑由客户完成，然后客户将整行发给服务器\\end{cases} 2.2 电子邮件 电子邮件的一般架构： 用户代理 user agent 报文传输代理 message transfer agent 报文访问组件 message access agent 2.2.1 架构 2.2.1.1 架构一：仅需要两个UA 电子邮件的发送方与接收方是在一个系统内的用户（或者相同应用程序），他们直接或者间接共享一个系统。 邮箱mailbox是本地硬盘的一部分——是一个特殊文件，只有邮箱的拥有者可以访问 客户1运行用户代理UA 在客户2的邮箱中插入报文 报文中有发送方与接收方的邮箱地址（文件名） 客户2可以运行UA，检查他的邮箱 2.2.1.2 架构二：需要UA和报文传输代理MTA 发送方和接收方是不同系统上的用户。需用用户代理和报文传输代理。 客户1使用用户代理程序发送报文到他所在网站的系统——邮件服务器 邮件服务器使用队列存储报文，等待发送 客户2使用用户代理检索存储在他的网站系统中的报文 客户2使用两个报文传输代理——客户+服务器 服务器始终运行 全过程需要两个UA和两个MTA（客户机和服务器） 2.2.1.3 架构三：两个UA和两对MTA 客户机1通过广域网连接到系统。 客户2直连到系统。 2.2.1.4 架构四：两对MTA和一对MAA 客户1和客户2都通过广域网连接到系统。 涉及到邮件的两个操作：pull和push push：从MTA客户机推入报文到MTA服务器 pull：从MAA服务器中拉出报文到MAA客户机 2.2.2 用户代理 User Agent 第一个组件conponent UA，是一个用户程序 2.2.2.1 Services Provided by UA 有五种报文： Composing messages Reading messages Replying to messages Forwarding messages 转发报文 Handling mailboxes 2.2.2.2 用户代理类型 command-driven 从键盘接收打个字符的命令执行某项任务 mail,pine,elm GUI-based 图形化界面 2.2.2.3 地址 地址由两部分构成：本地部分local part和域名domain local part：特定文件的名字，称为用户邮箱，在用户邮箱中存储接收到的文件 domain：邮件交换器的domain 2.2.2.4 MIME 电子邮件有一个简单的结构。他只能发送NVT 7 ASCII格式的报文。 多用途因特网扩充 Multipurpose Internet Mail Extension MIME： 辅助协议，允许非ASCII数据通过电子邮件传送 MIME将非ASCII转换到NVT ASCII，并将其传送给MTA服务器通过因特网发出去 在接收方在转换到原来的数据 2.2.3 简单邮件传输协议：STMP 实际邮件的传输由MTA完成。 定义MTA的协议称为SMTP 简单邮件传输协议 Simple Message Transfer Protocal，协议定义了如何来回发送命令和响应。 2.2.3.1 Commands and Response commands 从客户发给服务器。命令的格式为keywords:argument(s) STMP定义了14个命令： 前5个是强制的，必须实现且支持 后三个是常用且推荐 最后6个很少使用 response 服务器发给客户端 三位数字码，附加文本信息 2.2.4 POP 和 IMAP 报文访问代理有两种协议： POP3 邮局协议版本3 IMAP4 因特网邮件访问协议版本4 2.2.4.1 POP3 用户要从邮件服务器的邮箱中下载邮件时，客户端发起邮件访问的操作。 客户端开启与使用服务器110端口之间的TCP连接 发送用户名和密码来访问邮箱 之后逐条读取信息 POP3有两种模式： 删除模式delete mode：从邮箱中读取后删除邮件 保存模式save mode：从邮箱中读取后仍保存该邮件 2.3 文件传输 传送文件最常见的协议：FTP 2.3.1 文件传输协议 FTP使用TCP服务。它需要两个TCP连接。 一个用于数据传输 一个用于控制信息传输 分开传输使得FTP效率更高。 熟知端口21用于控制连接，而熟知端口20用于数据连接。 FTP会话期间： 控制连接(control connection)始终处于连接状态。 通过命令command和响应response完成 每一条命令是一个短行，不存在文件格式或者文件结构的问题。 数据链接(data connection)在每次传输文件时打开然后关闭 客户必须定义要传送的文件的： 文件类型 传输方式 数据结构 3. WWW and HTTP 万维网（World wide web, WWW）是分布式在世界各地相互连接的信息仓库。 3.1 体系架构 WWW是分布式客户/服务器服务，客户机用浏览器能够使用服务器提供的服务。然后提供的服务分布在许多称为站点的位置上。 每个站点拥有一个或者多个文档，即web页面。 web页面可以包含一个本地站点或者是其他站点的链接。 3.1.1 客户（浏览器） 浏览器使用相同的架构： 控制程序：从键盘或者鼠标接受输入，使得用户端程序访问文档 客户协议 解释程序：获取文档后解释程序显示 3.1.2 服务器 Web页面存储在服务器中，客户机请求到达，相应文档发送给客户 可存储在高速缓存中，较快发送 3.1.3 统一资源定位符URL URL说明了因特网信息的标准 包含： 协议：HTTP 主机：IP/域名 端口：可选 路径：路径 冒号隔开 3.1.4 Cookies Cookies提供状态保存服务 web有额外的功能： 只允许注册客户访问 3.1.4.1 Cookies的创建和存储 3.2 Web文档 \\begin{cases}静态文档\\\\动态文档\\\\活动文档\\end{cases} 3.2.1 静态文档 静态文档是固定内容的文档，由服务器创建并存储。发送给客户机的是副本 3.2.1.1 超文本标记语言 超文本标记语言用于创建web页面的语言。 beginning and ending tags 起始标签格式： 终止标签格式： 文本标签 图像标签 超链接标签 3.2.2 动态文档 在有浏览器请求该文档时，才由web服务器创建。 请求到达时，运行应用程序或者脚本来创建动态文档。服务器返回程序或者脚本的输出作为浏览器文档请求的相应。 CGI技术：定义如何编写动态文档，如何将数据发送给应用程序，如何使用输出结果 输入：参数传递（URL） 浏览器到服务器的输入通过表单完成 输出：服务器站点执行CGI程序 PHP，JSP 3.2.3 活动文档 需要程序或者脚本在客户端进行。服务器发送文档或者脚本的副本。 3.3 超文本传输协议 HTTP的功能类似FTP和SMTP的结合。 FTP：但是只用一个TCP连接 SMTP：传输的数据格式与SMTP类似 HTTP在熟知端口80上使用TCP服务 3.3.1 HTTP Transaction TCP报文，发送请求和发送响应 3.3.1.1 报文 a. Request line and Status line 请求行格式：请求类型 URL HTTP版本 状态行格式：HTTP版本 状态码 状态短语 b. Header 头部格式：head_name : value 分类： 通用头部 请求头部 响应头部 c.body 3.3.2 Persistant Versus Nonpersistent Connection 3.3.2.1 Nonpersistent Connection 每一次响应都要建立TCP连接，步骤： 客户端建立TCP连接，发送请求 服务器发送响应，并关闭连接 客户端读取 3.3.2.2 Persistant Connection HTTP1.1默认持续连接。服务器响应后会保持连接处处于开启状态，等待更多的请求。如果客户请求关闭或者超时时，服务器关闭连接。 var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"论文阅读/about.html":{"url":"论文阅读/about.html","title":"论文阅读","keywords":"","body":"var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"论文阅读/ParameterServer阅读笔记.html":{"url":"论文阅读/ParameterServer阅读笔记.html","title":"ParameterServer阅读笔记-2014-OSDI-李沐","keywords":"","body":"Scaling Distributed Machine Learing with the Parameter Server 阅读笔记 OSDI会议：操作系统设计和实现，SOSP两个会议是系统领域的两大会议 相似方向：高性能计算、编译器等 使用参数服务器扩展机器学习 摘要 概述： 针对分布式机器学习问题提出了一个参数服务器架构。 数据-工作 分布在工作节点上，服务器结点维护全局的共享参数——表示为稠密或者系数的向量或者矩阵的形式。 该架构管理结点之间的异步通信，支持灵活一致性模型，有弹性的伸缩性，持续容错 实验： 验证可扩展性，在PB级的数据的基础上展示了实验结果，涉及的问题范围包括稀疏逻辑回归到LDA和分布式算法。 Introduction 问题+重要性： 解决大规模机器学习问题的先决条件——分布式优化和预演 单台机器无法完成，实现一个有效的分布式算法也并不容易 密集的计算工作量和大量的数据通信都要求对系统进行精心的设计，即一个精心的设计要包含这两个方面的考量—— 密集的工作量 数据通信量 细致分析： $10^{9}$到$10^{12}$参数，所有工作节点间共享这些模型 三大痛点 巨大的网络通信量 机器学习的问题是顺序求解的，需要在结点之间进行大量的数据同步 容灾具有重要性 为什么要容灾？ 工业界容灾非常重要。 1.1 Contribution 第一代 jeff dean -> 第二代 -> 提出第三代开源实现 好处： 共享模块抽象，实现任务比较简单 同时能够处理各种算法：Logsitic 回归，LDA 机器学习在工业界，真实抽象： 有效通信：压缩，降低通信量 灵活一致性模型：每一个计算节点数据的一致性 强一致性：适合机器学习 vs 弱一致性：适合系统 做一个权衡 弹性的可扩展性：新的结点可以加进来，不会导致任务停止； 对于非常强一致性的问题，很重要 容灾：要花多少时间去恢复——1s恢复，继续执行；使用vector colock 易用性：全局的parameter表示为向量和矩阵（当时python的numpy还没有那么流行，主要机器学习还是使用C++来开发） 新颖度：找到了合适的系统技术，适配到机器学习算法中。系统+AI很好的融合，具体的说放弃了一些一致性的要求，同时修改机器学习的算法，使其能够接受丢失的一致性 1.2 Engineering Challenges 工程上的挑战：需要不断读写全局参数 参数服务器：提供了一个有效的机制去聚合和同步模型的参数，计算结点会读取数据进行计算 别人的抽象：datastore提供的key value的抽象是不够的，key一般对应下标，开销大 我们：很多学习模型把参数表示成数学对象，比如矩阵、向量，某个时间点时这个矩阵，向量的一部分会发生改变。工作节点发送向量的一个段segment，或者是整个矩阵的一整行。去批量的发送和更新，而不是逐个更新 容灾技术：数据结点-实时复制，计算结点-替换/增加结点都是可以做到的 1.3 相关的工作 引用13使用的parameter sever，使这个名字出名。 自己的模型称为第三代：尝试做一个更通用 Machine Learning 算法1： 梯度下降的算法 ------ 如何转换为 -------> 分布式的算法 抽象： \\begin{cases}任务调度器：for循环，迭代时间\\\\计算节点Worker：本质是一个进程，可以在一台机器上出现（抽象的概念）\\begin{cases}找到那一块的结点\\\\读到后权重拿下来\\\\迭代T，拿到T时刻的w，计算梯度，总梯度push回去\\end{cases}\\\\服务结点Server：另外的进程\\begin{cases}梯度汇总，得到总梯度\\\\\\end{cases}\\end{cases} Achetecture var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"论文阅读/PATHWAYS阅读笔记.html":{"url":"论文阅读/PATHWAYS阅读笔记.html","title":"PATHWAYS阅读笔记-2022-MLSys-JeffDean-Sanjay","keywords":"","body":"PATHWAYS: ASYNCHRONOUS DISTRIBUTED DATAFLOW FOR ML 针对机器学习的异步分布式数据流阅读笔记 摘要 ​ 本篇论文介绍了用于加速器的新的大规模的编排层orchestration layer的设计——Pathways。论文新型异步分布式数据流关键在两点： 异步：通信延迟和调度延迟的处理 分布式：突破原本JAX只能在2048个TPU上运行的限制——针对模型规模变大，硬件异构的处理 一、论文研究背景、动机和主要贡献 1.1 研究背景 ​ 近10年里的趋势是机器学习（Machine Learning, ML）的算法和系统与硬件一起演进（co-evolution）这种co-evolution有一定的隐患：系统过于针对当前的任务，而不能很好地适应未来的需求。 ​ PATHWAYS：针对的是分布式机器学习，具有的相关特性会被未来的任务所需要。 ​ 目前的分布式ML系统的现状：当今大多数最先进的ML工作负载都使用MPI的“单程序多数据”（SPMD）模型。 所谓的SPMD可以类比2014年OSDI的另一篇论文参数服务器中的例子——多机在完成梯度的计算后交换信息，做一次数据的同步。 1.2 研究动机 ​ 未来ML需要一些特定的功能，哪些特性是未来ML所具有的？ 模型较大：对于大语言模型模型在一个加速器上是不够的，纯粹的数据并行是不够的 开始考虑流水线（pipeline）而不是纯的数据并行（文中以MoE为对象介绍，他是一种MPI） 存在计算稀疏性：使用细粒度的控制流和夸加速器的异构计算 硬件异构：就硬件上的变化来说，机器学习集群变得越来越异构 ​ 针对硬件的异构性，论文中提出了一个“岛”(island)的概念，“岛”指的是一组连接在一起的加速器。单机的加速器之间连接较为紧密，而多机之间的加速器连接并不紧密。如果需要维持多机之间紧密的联系需要耗费较大的带宽，这通常是比较浪费的：用户需要试图保持所有加速器持续繁忙。 ​ 这种异构性的存在，进一步推动研究人员转向“多程序多数据”(MPMD)计算，通过将整体计算的子部分映射到更容易获得的小型加速器岛的集合，从而实现更大的灵活性。为了提高利用率，一些ML硬件资源管理人员以细粒度的方式在工作负载之间复用硬件，从而支持工作负载弹性，并提高容错能力。 ​ 最后，研究人员开始标准化一套基础模型，这些模型是在大数据上大规模训练的，可以适应多种下游任务。对此类模型的训练和推断提供了通过跨许多任务多路复用资源来提高集群利用率的机会，并有效地在它们之间共享状态。 结合Jeff Dean去年的博客Pathways: A next-generation AI architecture (blog.google)（上图），能够较好地理解这个基础模型的概念。 1.3 研究贡献 ​ Pathways系统与最先进的ML系统状态的功能和性能匹配，支持未来ML工作负载所需要的功能。Pathways使用的体系结构为client-server体系结构。这个体系结构使得Pathways运行时能够代表许多客户在系统管理的计算岛上执行程序。 创新性： Pathways旨在透明有效执行跨越TPU的\"POD\"程序的系统 采用数据流执行（DataFlow Execution）模型来扩展到数千个加速器 ​ PATHWAYS使非SPMD计算变得容易，并启用了CENLALALIZED资源管理和虚拟化，改善了加速器的利用率。 二、设计动机 2.1 现有ML系统的设计 ​ 现有的ML系统的设计难以支持大型的，稀疏的，或者不规则的模型。 2.1.1 Multi-controller System ​ 用于训练最先进的SPMD模型的分布式ML系统通常采用多控制器（multi-controller）体系结构，其中相同的客户机可执行文件直接在系统中的所有主机上运行，在程序执行期间独占这些主机上的资源 训练最先进的SPMD的分布式ML系统例子\\begin{cases}MPI\\\\Pytorth\\\\ JAX\\\\ TensorFlow\\\\ ......\\end{cases} ​ 这种架构的优点是计算的低延迟：因为用户代码的相同副本运行在每个加速器的主机上，并且分派补丁只涉及到通过相对快速的PCIe链路进行通信。所有其他跨主机的通信只通过使用专用互连的集合发生，如NVLink，而不使用主机内存。 ​ 缺点： 这种架构与使用流水线或者具有计算稀疏性的线代ML工作负载不匹配。 multi-controller系统中，任何超过标准集合的通信需要用户实现他们自己的协调原语 multi-controller通常假定独占硬件资源，使得构建高效的集群范围ML设计变得复杂 2.1.2 Single-controller System ​ 单控制器（single-controller）系统，如TensorFlow v1提供了一个包括优化图内控制流的非常通用的分布式数据流模型。 ​ TensorFlow (TF) Python客户端构建一个计算图，并将其移交给协调运行时，协调运行时将图划分为每个worker的子图，并将子图的执行委托给worker上的本地运行时。worker之间的协调是通过数据和控制边缘在数据中心网络(DCN)上传递消息来执行的。 虽然单控制器设计提供了灵活的编程模型和虚拟化资源，但它提出了实现的挑战： 2.1.2.1 TF1 SPMD 通信更慢：单控制系统系统中的客户端更远，分派延迟包括DCN上的通信，通常比PCIe慢一个数量级 controller为了更好的分派子图，可能会预先编译优化图，这样的优化会使debug变得困难 在涉及许多跨主机传输的程序中，例如使用大量的阶段，这些调度延迟累积，导致低效的加速器利用率。 2.1.2.2 TF1 non-SPMD 为了支持带有SPMD的子计算的MPMD程序并发执行，运行时需要有某种机制来支持加速器计算的分组调度，否则可能会出现死锁。 计算结点变多，边变多，中央控制器指令收发成为一种瓶颈——带宽变低，通信量增多 2.2 PATHWAYS目标 ​ 而针对Pathways来说，Pathways并不是打算去解决TF1在分组调度、debug困难这样的易用性的问题，而是认为TF1这样的设计是合理的，即在系统上，把这样有一个中央controller，能够把任务分配到各个结点上。同时这个概念称为dataflow。——论文题目dataflow的由来 dataflow： 计算表示成一个计算的图，一个结点是一个计算，箭头表示依赖的关系。 系统的目标：给一个计算图，有向无环图，如何把他映射到硬件上，更好地调度执行。 ​ TF1受限的问题：TF1考虑的是比较小的图，是在几百个同构的加速器上执行。 ​ TF1 执行大图的问题： ​ TF1中图的结点和边变多，结点进行的运算较少，中央控制器进行指令收发成为了一个瓶颈——带宽变低，通信量增多了 not good ​ 现在模型更大，异构，如何修改设计？ 仍采用单控制器（single controller）：利用计算稀疏性和异构性，促进资源共享和虚拟化 异步调度来匹配多控制器系统的性能 支持集中资源管理和调度，使分片数据流系统高效协调 三、 PATHWAYS 编程模型 Google深度学习框架前置知识： 第一代深度学习框架disBlief 第二代深度学习框架TensorFlow v1：调试不方便，性能优化方便；运行得到的是一张图，而不是中间的结果；运行完后得到的完整的执行图 好处：后端可以进行性能优化；计算图与Python无关，灵活性提高 缺点：调试变得困难 TensorFlow v2：与TensorFlow v1不同，几乎是另一套框架 谷歌之后开始研究TPU，为TPU开发了编译器XLA；XLA之后也支持了GPU和TPU，是一个统一的后端 JAX：XLA的前端，设计理念是提供一个与numpy类似的前端——可以按行执行，实际上采用的是一种延后执行的方法； 从用户看：和Python按行执行似乎没有什么区别 从后端：拿到很多图，只是图大小变小很多 JAX提供自动求导等功能 3.1 JAX和TensorFlow对PATHWAYS支持 3.1.1 JAX评估的优点 ​ 目前进度：实现了使用TensorFlow和JAX编写的源程序对PATHWAYS的支持 ​ JAX优点：可以显式使用Python的装饰器（decorator），指示那些原本应该被编译成SPMD的python代码。 @pw.program # Program tracing (optional) def f(v): x = a(v) y = b(x) z = a(c(x)) return (y, z) ​ 这些XLA计算的特点是已知输入和输出类型和形状，可以提前估计计算的资源需求。称为“编译函数”（compiled function），并且每个这样的函数都映射到PATHWAYS程序中的单个（分片）计算节点。 3.1.2 PATHWAYS+JAX实现TPU数量扩展 multi-controller下的JAX 使用XLA集合传输所有数据，JAX无法扩展到单个TPU pod外——无法适应当前ML发展的需求 使用PATHWAYS作为JAX替代后端 JAX代码不需要修改 PATHWAYS可以通过ICI和DCN进行通信，可以使JAX程序扩展到多个TPU pods，可访问数千个TPU核心 3.1.3 编程模型 ​ 下面是Python用户代码应用于在多个TPU上的PATHWAYS示例： def get_devices(n): \"\"\"Allocates `n`virtual TPU devices on an island.\"\"\" device_set = pw.make_virtual_device_set() return device_set.add_slice(tpu_devices=n).tpus a = jax.pmap(lambda x: x * 2., devices=get_devices(2)) // get_devices(2)返回两个虚拟TPU，运行时再根据PATHWAYS做具体的映射与调度 b = jax.pmap(lambda x: x + 1., devices=get_devices(2)) c = jax.pmap(lambda x: x / 2., devices=get_devices(2)) @pw.program # Program tracing (optional) def f(v): x = a(v) y = b(x) z = a(c(x)) return (y, z) print(f(numpy.array([1., 2.]))) # output: (array([3., 5.]), array([2., 4.])) ​ 简要分析下程序：a(),b(),c()三个函数首先声明在什么硬件上运行，这里使用的是JAX的pmap()函数，pmap() 实现并行的映射，将函数映射到两个TPU设备上。get_devices()是PATHWAYS的函数，PATHWAYS用户可以通过get_devices()请求两个虚拟的TPU，待运行时再做具体的映射物理TPU和优化。系统将自动处理所有相关计算之间的数据移动和重分片。 3.1.3.1 无Program tracing下的PATHWAYS（默认情况） ​ 假如程序中line 11@pw.program # Program tracing (optional)不存在，那么，即如下程序： def get_devices(n): \"\"\"Allocates `n`virtual TPU devices on an island.\"\"\" device_set = pw.make_virtual_device_set() return device_set.add_slice(tpu_devices=n).tpus a = jax.pmap(lambda x: x * 2., devices=get_devices(2)) b = jax.pmap(lambda x: x + 1., devices=get_devices(2)) c = jax.pmap(lambda x: x / 2., devices=get_devices(2)) def f(v): x = a(v) y = b(x) z = a(c(x)) return (y, z) print(f(numpy.array([1., 2.]))) # output: (array([3., 5.]), array([2., 4.])) ​ 在上述程序中，f()函数会触发4次编译，4次调度：每个编译后的函数a()，b()或c()都会转换为一个独立的，仅包含一个分片计算的PATHWAYS函数。在调度时，编译好的函数发送到具体的物理TPU上运行，并返回结果。鉴于a()，b()，c()三个函数较为简单，若是采用编译为单个分片的PATHWAYS函数再发送的策略，如下图，会在RPC上耗费较大的代价。 因此，PATHWAYS使用了Program tracing。 3.1.3.2 含Program tracing下的PATHWAYS ​ 在上述代码中增加@pw.program。 @表示python中的装饰器 ​ 增加后，PATHWAYS会把f()编译称为一个单独的函数，只需要编译一次，调用时将整个完整的函数发送，以一个更大的任务形式去执行。 3.2 PATHWAYS支持的编程模型成果 硬件的抽象与映射 devices=get_devices() 额外的接口函数，打包更大任务去执行 @pw.program ​ PATHWAYS其实不是一个框架，而是一个后端，通过这样编程接口的方式嵌入到前端上。这里的前端是JAX，但也可以用到TensorFlow上。 四、PATHWAYS 系统架构 ​ PATHWAYS广泛建立在以前的ML系统的基础上，基础包括： XLA表示和执行TPU运算 TensorFlow图来表示和执行分布式CPU计算 Python编程框架，JAX等 ​ PATHWAYS能更关注一些新颖的协调方面的任务，使用更少的代码优化ML模型。 4.1 资源管理器：实现虚拟设备映射 ​ 一组加速器组成了PATHWAYS的后端，这些加速器被分组为紧密耦合的孤岛（tightly-coupled island），孤岛之间通过DCN相互连接。岛内的TPU连接是高带宽的，而岛与岛之间的连接需要使用共享的数据中心网络，速度较慢。另外一个概念为PODS，一个PODS最多有2048个TPU核，在模型较小的情况下不需要跨POD计算，而在模型较大时，单个的POD不能支持较大模型。 ​ PATHWAYS即是为了解决这样的问题提出的，其目标则是针对在一个POD无法支持较大模型的情况下，使用多个POD，类比单机来说，即是一种多机多卡的训练形式。 ​ PATHWAYS资源管理器（Resource Manager）负责集中管理岛屿上的所有设备，可以根据用户的需求进行加速器的分配。将虚拟的TPU映射到物理的TPU上。 目前：一对一的映射，按需分配 未来：支持动态的结点加与减 4.2 客户端 Client：任务执行的过程 ​ 论文这部分描述了用户任务执行的细节过程，即PATHWAYS是如何将用户的任务编译并运行的： step1：用户运行traced program step2：调用PATHWAYS客户端程序库，未之前没有运行过的计算分配物理设备，并在资源管理器中注册，触发服务器后台编译计算 step3：JAX将用户程序（任务）编译成为MILR MILR：可以认为是XLA的一个上层的语言，用于支持动态的数据流与动态形状的输入和输出，是一个高层的IR step4：IR通过一系列标准的编译器传递逐渐“降低”，最终输出一个包含物理设备位置的低级表示。 ​ 在整个过程中，需要考虑一些分布式通讯的问题，会映射到一些网络通讯架构。 PATHWAYS使用RDMA实现对远端主机内存访问，由于使用了RDMA，所以主机上的一块内存可能虽然不被本机使用，但是远端机器可能会使用。以前的single-controller和现在的PATHWAYS针对于这方面的处理有所不同： older single-controller：协调数千个数据缓冲区，比如说每个小块维护一个counter，维护数千个counter去计数引用。 PATHWAYS：使用shared buffer抽象一个可以分布在多个设备上的逻辑缓冲区，通过shared buffer分摊引用计数的成本，帮助客户扩展。 4.3 Coordination implementation：数据的收发 ​ 这部分说明的是如何在数据中心的网络上高效地收发数据。 ​ 数据中心的网络是有一定的结构的，如何选择发送的路径，发送的方式（同时发？）等是需要动态调整的。PATHWAYS使用PLAQUE进行优化，将低层次的IR表示为plaque的表示，可以满足具体的需要。 ​ PLAQUE优化支持稀疏通信，这是PATHWAYS希望启用的重要功能之一。同时也可以使用Ray做以优化。 4.4 Gang-Scheduled dynamic dispatch：死锁的预防 ​ TPU只支持单线程，多个TPU之间可能发生死锁。解决方法： 引入多线程 Gang-Schedule ​ 所谓的Gang-Scheduled指的是在每个岛上都有一个集中的调度器，调度器负责将任务进行合理的排序，避免死锁的发生。目前是按照FIFO的顺序工作。 4.5 Parallel asynchronous dispatch 并行异步分发 ​ 当在加速器上运行时，系统可以用异步API将计算与协调重叠。 4.5.1 顺序分发 Sequencial dispatch ​ 如下图，其中的正方形对应三个节点A、B和C，它们运行在主机A、B和C所连接的加速器上。所有节点计算都是常规的编译函数。 XLA在编译一段代码时必须知道这段代码的输入和输出形状，知道形状后可以在加速器上创建内存。 ​ 上图描述了一个这样的顺序处理过程： 主机A排队等待节点A，接收到A输出的future，并将future发送给主机B。（棕色箭头） 主机B分配B的输入，将输入的缓冲区地址发送给主机A，完成启动节点B功能的大部分准备工作。（红棕色箭头） 当节点A完成时，它的输出通过加速器互连直接发送到节点B的输入缓冲区，然后主机B启动节点B。 ​ 一个节点完成和下一个节点启动之间的延迟可以比数据传输时间多一点。从图中我们可以看出来，这样的顺序分配的方式存在大量的stall，效率较低。 ​ 即这样的处理回到了之前提出的存在的问题：当程序的计算图很大，结点之间的依赖很复杂，同时每个结点的计算量不是很大时，那么很大一部分的时间都消耗在stall上了。 ​ 并且如果编译的函数都是规则的，那么实际上甚至可以在前一个节点的计算进入队列之前计算后继节点的输入形状。 4.5.2 并行分发 Parallel dispatch ​ 对于函数是规则的情况下是可以进行优化的：客户端编译之后知道要发送的形状，收到的形状。在通知结点A时会同时通知结点B和结点C它们将会分别从结点A和结点B收到的输入的形状。于是等待时间得到了缩减。 ​ 由于工作只能在函数是规则（regular）的情况下进行并行调度，所以PATHWAYS将并行调度视为一种优化，并在一个节点的资源需求直到前一个计算完成后才知道的情况下(例如，由于依赖数据的控制流)，退回到传统模型。 4.6 数据管理 Data management ​ 每个主机管理一个分片的对象存储，类似于Ray的对象存储，但扩展到跟踪每个分片上的加速器HBM中持有的缓冲区。 五、评估 5.1 实验 ​ 使用的任务较小，主要还是探讨不同的决策带来的结果。 5.2 一些讨论 是否能够使用在GPU上？ GPU设计理念与TPU不同，GPU的编译上不会优化过多。文章提到的优化大部分已经在GPU上做到了。 资源的管理 何如去做到动态的资源的管理，而整个系统主要关心的是大模型的运行，动态资源管理作为未来工作。 稀疏模型 作为未来的工作 5.3 评价 ​ 帮助JAX如何突破在一个TPU Pods上进行计算的局限：不仅可以在2048个核上训练。 var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"论文阅读/Alpa阅读笔记.html":{"url":"论文阅读/Alpa阅读笔记.html","title":"Alpa阅读笔记-2022-OSDI-郑怜悯","keywords":"","body":"Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning Alpa阅读笔记 一、论文的研究背景、动机和主要贡献 背景：大模型和分布式训练 ​ 深度学习最近的进展直接导致了模型大小的变化，如：GPD3亿万级别的参数，同时在更大数据集上进行修改以支持兼容性。最新的模型上参数的数量以指数的形式增长。 ​ 训练这样大的模型是具有挑战性的。因为模型的参数众多，受限于内存大小，无法在一个单一的加速器上进行训练。同时，这会花费几百年去在一个单独的加速器上训练这样的模型。因此分布式训练是必须的。 ​ 迄今为止，分布式训练并不是那么容易，为了训练特定的模型人们必须去建立特定的系统。有一些比较流行的技术，比如数据并行（data parallel），张量并行（tensor parallel）和流水线并行（pipeline parallel）。 [细读经典]三种并行知识 ​ 三种并行之间有着不同的权衡（trade off），如果要训练一个较大的模型，你必须去找到一个方法去综合运用这三种并行，从而你可以达到一个好的训练吞吐量。以下是专家设计策略的两个例子： Megatron-LM策略：在transformer层并行化self-attention模型 ​ 对于大型的transformer模型，权重的数量非常大，因此不能使用数据并行。所以需要对权重进行分片。在这个模型里面，第一个权重矩阵已经被按列分片，第二个矩阵已经被按行分片，从而减少通信代价。 GShard Mixture-of-Expert ​ 专家层（红色部分）以专家维分片，非专家层以批处理维度分片做数据并行 ​ 为了应用这样的并行策略，模型开发者不得不去重写他们的模型定义，特定化分片策略，并且插入必要的通信原语，比如这里的all-to-all。这使得开发一个新的模型或者寻找异质模型变得困难。 ​ 在我们的论文中，我们的目标是统一所有的这样的并行化策略，并且建立一个编译器去自动产生最优的综合的并行化策略。所以，首先我们总结了现有的并行化策略，把他们分成两种： Type1：Intra-operator Parallelism ​ 我们利用了单个操作中固有的并行性，所以我们称它为Intra-operator parallelism Type2：Inter-operator Parallelism ​ 我们利用了在整个图中的更高层次的并行，但由于数据依赖，设备2不得不去等待设备1，等待它的输入数据。所以一些设备可能在一些时间内是空闲的。去解决这样的问题，典型的流水线技术被应用，比如我们可以发送多个微小的批到流水线中去实现并行化。 ​ 有了这两种定义，我们可以把传统的并行技术全部归类到这两种分类中，下图展示了一些比较流行的训练两层MLP的并行化技术： Intra-operator Parallism例子： Inter-operator Parallism例子： ​ 特别注意的是，在Device Placement的图中，如果不存在多个并行的设备分支，那么会造成时间的空闲；而在Pipeline Parallelism中通过将输入的数据分割为若干的微小的批次，从而解决了这个问题。 ​ 在这两种分类之间有着响应的权衡（trade-off）： Intra-operator Parallism需要大量的通信，比如all reduce和all-to-all，故高带宽的设备连接是必要的。 Inter-operator Parallism通常需要的是点到点的通信，通信发生在子图的边界内，需要更少的通信。但是为了解决设备的空闲，仔细的调度和分片是需要的。 Prior Auto-Parallelization Work ​ 有效的训练一个大模型通常需要上述的很多技术的综合。如果依赖于人工的设计策略，这需要很大的工程上的努力。所以研究者倾向于去寻找一种基于自动并行。在以前的工作中，有以下几种自动并行化系统： Flexflow/Tofu Pipedream/Dapple ​ 但是他们都有很多的限制，并且不能训练最先进的模型： 搜索空间有限 由于这些模型仅考虑了有限的并行化技术，并没有对所有的并行化技术予以支持。 搜索算法限制 搜索算法的搜索是基于对模型的随机搜索或者强假设的。 Our Approach ​ 本篇的论文解决方案采取了一个不同的并行化视角，将上述的两种并行化技术分类作为一个两层层次化空间。这个层次化的空间自然地与层次化常见的GPU集群结构映射起来，在GPU内部结点中是高带宽的NVLink链接，而在结点之间是较慢的连接，比如以太网。本篇论文建立了一个两层的层次化搜索空间，然后设计响应的算法去获得每个层次的最优解。 ​ 接下来是方法的详细说明。 二、Automating Intra and Inter Operator Parallelism ​ 自动并行化（Auto Parallelism）意味着用户不用特意地去修改他们的模型，论文中提到的模型将会将用户的模型从一个单设备的程序转变为一个多设备的程序。Alpa遵循编译器的架构，我们从runtime部分开始说明： 两种并行化的runtime支持 ​ 现在的GPU集群中，GPU被典型的组织成为一个两层的拓扑结构，故在结点内有高速的链接，但在结点间有着相对慢速的连接。论文使用了一个二维设备网络去指代这个拓扑结构。以下图为例，在这个设备网络中，我们有2个Worker，每个设备中有4个加速器，并且我们可以假设，在Worker内部，加速器结点之间通信速度较快，而在Worker之间，通信速度较慢。在组织时，设备之间采用Inter-op Parallesim模式，而在设备内部采用Intra-op Parallelism的形式。 编译器端 ​ 对于编译器端，输入是一个计算图和一个特定的设备集群。 ​ 我们首先运行一个Inter-op Pass将计算图分片为多个阶段，对于每个阶段我们对其分配一个设备网，故一个设备网负责一个阶段（stage）的计算。对于每个阶段之间，我们运行一个Intra-op Pass去分片所有的操作，即使是在设备网的多个GPU集群之间。 ​ 在运行时编排（runtime orchestration）阶段，编译器使用流水线的指令去调度这些阶段，并且所有的指令被静态编译为网络可执行（mesh executable），这个网络可执行被发送到相应的设备网络，然后我们在所有的设备上去执行相应的mesh executable。 故在整个阶段中，最重要的是Inter-op Pass和Intra-op Pass两个部分： Inter-op Pass可以通过动态规划为Inter-op Parallism提供一个局部的最优解； Intra-op Pass可以通过整数线性规划为Intra-op Parallism提供一个局部最优解 ​ 下面对于这两个重要的阶段进行详细的分析： Intra-op Pass ​ Intra-op Pass使用的是SPMD风格，这意味着将会对每个操作进行分片，即是是在设备网络中的所有GPU中。SPMD风格简化了许多东西，但是由于其依然可以覆盖很多传统的技术，比如数据并行（Data Prallelism）、操作并行（Operator Parallelism）和零优化器（Zero Optimizer），SPMD是足够强大的。对于Intra-op Pass我们的目标是对于每个操作找到一个分片策略。以下图为例，这是一个两层MLP的向前计算图。 ​ 对于张量的权重，它可以被按行分片、按列分片、全复制或者是部分复制，故每个结点的张量都有一个包含多种可能的分片策略的分片策略集（partition strategy set）。比如矩阵乘法有很多种并行计算的方法去解决该问题。不同的算法对输入层有着不同的要求，如某个算法可能要求权重是按列分片的，另一个算法可能要求权重是按行分片的。同时不同的算法也有着不同的输出布局。如果输入不满足算法的输入要求，那么我们需要在边缘做一个布局转化，这会造成相应的通信代价。 ​ 总之，去执行计算图，总时间代价公式如下： \\text{Total time cost = node cost(compute cost) + edge-cost(communication cost)} ​ 我们的目标即去对每个操作（operator）选择一个分片的策略，并且最小化总时间代价（Total time cost）。下面给出一个更加具体的例子，分析不同结点可能的分片策略和边缘代价： ​ 输入矩阵和权重矩阵可以是完整副本、部分副本、列分片或者行分片的形式。矩阵乘法需要三层的循环，我们可以将第一层循环或者第二次循环或者这些循环的结合做并行处理，这样会有多个不同的策略： Strategy 1：矩阵A为列分片，矩阵B为行分片，最终产生一个结果的完整副本；同时需要进行all-reduce(c)去累计部分结果。 Strategy 2：矩阵A为行分片，矩阵B在两个设备上存有完整的副本，最终产生的结果不需要进行累计，分别存储在两个设备上。 Strategy 3：矩阵A在两个设备上存有完整副本，矩阵B为列分片，最终产生的结果分别存储在两个设备上。 ​ 若布局不匹配，那么需要使用集中式通信原语进行布局转换： ​ 例如：若需得到张量并未列或行分片的副本时，需要使用all-gather原语去进行结果的合并；若进行列分片或者行分片的转换时，需要使用all-to-all原语转换；若将一个完整的副本进行分片，并不需要进行通信，在本地进行分片即可。 ​ 上述的优化问题可以使用整数线性规划求解，以下图所示的依赖关系为例：依赖关系只是在两个结点之间存在，这就产生了一个二次目标规划，将其线性化即可得到一个线性规划。 ==整数规划？如何进行？== ​ 为建模此问题，需要枚举所有操作（operator）的所有可能的分片策略，并且计算在所有边上的策略对的通信代价，最后以最小化代价为目标，进行整数线性规划。 ​ 与之前的工作对比： Comparison Advantages vs. Tofu Support general graphs. Support 2-D device mesh vs. FlexFlow Optimality guarantee. Support additional partition strategies. Note: 如果考虑通信计算重叠，由于存在复杂的依赖关系，将不再能建模成为一个整数线性规划的问题。实际中，可以先进行整数规划，得到一个较优的解后进行通信计算重叠优化。通信计算重叠（communication computation overlapping） Inter-op Pass ​ 在这部分将会针对流水线并行进行阐述，目前流水线也是针对于大模型训练的较为有效的方式。Inter-op Pass的目的是分片计算图为多个子图，以下图为例，分片完整的计算图得到了4个子图。同时，还需将输入集群分片为4个子网，将一个阶段与一个子网匹配。最终使用Pipeline的形式将各个子网之间连接，实现Inter-op Pass。 ​ Inter-op Pass的目标是最小化流水延迟。流水线延迟由两项组成，首先是预热阶段，后续是稳定阶段，稳定阶段由最长的流水段决定。 ​ 减少流水线延迟是通过动态规划算法实现的，动态规划的输出将是一个计算图的划分和设备网分片策略的结果，即流水线的各个段。下面是动态规划的细节说明： Minimize\\ Pipeline\\ latency\\quad T=\\sum_{i}^St_i+(B-1)·\\max_{1\\leq j\\leq S}\\{t_j\\} Input： 运行intra-op Pass，分析获得每个阶段的用时$ti=t{intra}((o_p,...,o_q), submesh(n,m))$。 Constraint： （1）将同一阶段的向前传递和向后传递分配到相同的子网中。 ​ 基于这个约束，我们假设向后传递的部分是对称的，故只需优化图的向前传递部分。 （2）每个子网可以完全覆盖原始的完整网络。 ​ 原始的网络是经过分片的，需要仔细选择子网的形状。有些子网的形状可以保证我们 的集群分片策略是始终有效的，并且可以完整覆盖原始的网络。 Solution： ​ 枚举$\\max{t_j}$并且将其转换为一个传统的动态规划问题——2维背包问题。 Complexity： O(k^5NM(N+log(M))) ​ 由于时间复杂度中涉及到$k^5$这样的高阶项，故此动态规划的算法不能应用于大规模的图。为了解决这个问题，论文进行了一个预处理的过程——运行图集群算法，以集群相似的图为一个大的层次。故可减少图中的操作的数量。 ​ 以上的说明覆盖了我们去构件Alpa的所有核心的技术。 Alpa 实现 ​ 实现时使用JAX作为前端，JAX的一些特点使得能够更简单地构建编译器。例如，可跟踪静态的包括向前传递和向后传递的计算图，优化器更新等，图的提供对于论文的优化是非常必要的。 编程API 论文提供了一个One-Line Auto-ParallelizationAPI，JAX程序如下： # One-line auto-parallelization: # Put @parallelize decorator on top of the Jax functions @parallelize def train_step(state, batch): def loss_func(params): out = state.forward(params, batch[\"x\"]) return jax.numpy.mean((out - batch[\"y\"]) ** 2) grads = grad(loss_func)(state.params) new_state = state.apply_gradient(grads) return new_state # A typical training loop state = create_train_state() # 模型的创建 for batch in data_loader: # 从data loader中加载批 state = train_step(state, batch) # 梯度下降计算 ​ 原始的JAX只是在一个加速器上计算，Alpa突破了这一限制，可以在加速器集群上进行计算。 Note: Alpa的并行化是基于Ray加载处理器和分布式集群，并且使用Ray去检测所有的GPU或者是集群中可用的GPU。 实现细节 Inter-op Pass 基于JAX中间层JAX PR实现。由于在此处我们仍然需要一些机器学习的语义，例如向前传递，向后传递，梯度等。 Intra-op Pass 基于XLA HLO实现。在该部分，不对forward pass和backword pass进行区分。在一个通用的计算图上运行ILP算法。然后使用XLA将策略lower为可执行程序。 Pipeline Excecution 流水线在XLA中是不支持的，故实现时使用自设计的流水指令。 ​ 对于运行时的体系架构，实现时使用XLA综合Ray。对于通信部分，使用Nico构建了一个通信库。 三、评估与总结 评估 Cluster：$8\\times AWS\\ p3.13$个结点。每个结点总共有8 V100 GPUS。 Models：GPT-3（高达39B），GShard MoE（高达70B），Wide-ResNet（高达13B） Setting：Weak scaling on model sizes 意为可用GPU的数量越多，那么训练的模型越大；但是论文固定了批处理的大小，输入的数据大小是固定的。即，模型并行化的评估与通常的数据并行化的评估是有所不同的。 GPT-3 GPT-3被很多的系统进行了相关的优化。Megatron-LM是一个针对GPT-3训练的系统，同时合并了Intra和Inter的并行。Alpa可以自动找到Megatron的所有的策略并且达到Megatron的性能。同时编译的时间也是可以接受的。 MoE Megatron是针对于GPT-3的，故无法用其训练MoE。对于MoE目前最优且可行的GPU实现是由Deep Speed实现的。Deep Speed针对MoE做了Intra和Inter的并行，但是他的性能是无法与流水线并行引擎比拟的。 W-ResNet W-ResNet是一个异质模型，因为在卷积神经网络中，活化的速度变得更慢，同时权重的大小变得更大，对于不同的层次，权重也是不同的，所以针对W-ResNet去人工设计一个策略是比较困难的，目前也没有这样的可行的人工策略。但是Alpa仍可以应用在这种类型的模型上，同时达到一个不错的性能。 总结 Alpa是一个针对自动分布式系统的新的系统设计 Alpa构建了一个两层的层次化搜索空间并且在每个层次上寻求最优解 Alpa可以匹配或者超越专门的系统，泛化到新的模型上 var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"论文阅读/FasterMoE阅读笔记.html":{"url":"论文阅读/FasterMoE阅读笔记.html","title":"FasterMoE阅读笔记-2022-PPoPP-何家傲","keywords":"","body":"FasterMoE：Modeling and Optimizing Training of Large-Scale Dynamic Pre-Trained Models FasterMoE阅读笔记 一、论文背景、动机、主要贡献 论文背景 Note：之前阅读的两篇论文：Alpa和Pathways都说明了目前深度学习模型规模逐渐变大的背景；参考RNN相关背景知识：大模型意味着有更多的参数，更多的参数能够给模型带来准确性的提高，这是为什么AI模型越来越大的原因。 ​ 混合专家（Mixture-of-Expert，MoE）：目前最流行的预训练模型，使训练万亿级别以上的参数模型变得可能。MoE由许多小模型组成，即专家模型。 小模型：计算力有限；大模型：计算量昂贵 MoE：采用了另一种思路，使用门模块（Gate Module）选择专家，达到以下效果： 模型大小被扩大，模型能力增强 专家是稀疏激活的，节省了额外的计算量 Note： MoE论文链接：MoE论文本地链接 关于预训练模型（Pre-Trained Model）：预训练模型是一类已在较大的数据集上训练好的模型，这类模型往往比较大，训练需要耗费大量的内存资源。比如NLP中常见的预训练模型Bert和GPT。预训练模型训练结束时的结果较好的一组参数值可以迁移到其他的网络中，其他的网络便学习了这个网络的特征和其拥有的知识。 详解预训练模型) 预训练模型Superb的博客 ​ 与经典的密集预训练模型相比，MoE可以显著增加同一时间段内训练的样本数量，提高模型的精度。因此，这种动态模型对于训练一个巨型模型越来越重要。 论文动机 ​ 虽然上述的MoE使得训练万亿规模的巨型模型变得可行，但是成本依然很高：GShard中一个6000亿的MoE模型需要2048 个tpu花费4天的时间来训练。为了减少训练时间，引入了专家并行（expert parallelism）：专家分布在不同的工作节点（worker）上，每个工作节点（worker）处理不同批次的训练样本。 ​ 如下图，MoE采取专家并行的模式，所有的专家被放到各个worker上，训练的数据（data, tokens）类似于数据并行，也被分布式地分布在各个worker上。图中出现了两次的all-to-all通信：输入端的all-to-all将数据（tokens）发送到期望的专家处，经过专家在各个worker上分布式地训练数据后，在输出端通过all-to-all送回原来的序列位置。 ​ 但MoE也给训练的系统带来了挑战： 动态负载不平衡（dynamic load imbalance） 存在某个专家更“受欢迎”，all-to-all操作后，较多的数据会被发送到该专家处，造成负载不均衡。此外，在不同的迭代轮次中，这种模式会发生变化，进一步影响了硬件的利用率和训练效率。 低效的同步执行模式（inefficient synchronous execution mode） 粗粒度的计算是低效的，计算和通信二者之一始终存在空闲。考虑到不统一的专家选择会导致计算和通信的严重不平衡，这种启动同步操作的方法会导致更多的开销。 拥塞的all-to-all通信 结点（Node）内部的worker之间通信较为高速，结点之间的通信常使用以太网等，带宽有限。在token分布均匀的情况下，结点之间的通信将会十分密集，造成拥塞。 论文贡献 ​ 针对上述的问题，分别给出了针对性解决方法： （1）性能模型 ​ 该模型能够准确预测特定的训练任务的不同操作的延迟，也能使用一个屋顶线型模型（roofline-like model）直观分析端到端的性能。 （2）影子专家（Expert shadowing） ​ 处理动态负载不平衡的问题。 （3）智能细粒度调度（Smart fine-grained schedule） ​ 将不同的操作分隔并并发执行。 （4）拥塞避免专家选择策略 ​ 在允许修改专家选择的情况下，以较低的迭代延迟缓解网络拥塞。 ​ 将以上的方法集成作为一个通用的系统：FasterMoE。该系统在不同的集群系统上进行评估，最多使用了 64 个GPU。与大型模型的最先进系统(包括ZeRO、GShard和基础层)相比，它实现了1.37 - 17.87的加速。 Note：Source code of FasterMoE is now available at https://github.com/thu-pacman/FasterMoE. 二、问题定义和描述 Transformer：使用MoE扩展MLP ​ Transformer是处理序列的最先进结构。一个Transformer Block 由Attention层和多层感知机(MLP)两组成。Attention层的结果被送入MLP层后，该层由两个巨大的全连接（FC）层组成。Transformer Block 中最耗时的计算是发生在MLP层的一般矩阵乘法(GeMM)。在 Transformer 中，MLP层通常用MoE扩展。 ​ 在non-MoE Transformer模型中，MLP中有两个相邻的FC层。当模型规模扩大时，这些密集的层变得巨大，使得GeMM的计算量过大。在MoE模型中，GeMM的权重矩阵沿着一定的维数分割，使得每个部分仍然产生相同大小的输出，而GeMM的计算量仍然很小。换句话说，MoE允许在不增加计算量的情况下增加模型参数，这使得它成为目前生产万亿级以上预训练模型的最可行方法。 ​ 对于一个给定的输入，一个额外的模块，门，被引入来决定哪些专家应该被激活。gate通常是一个小的FC层，用于计算每个专家的匹配分数，并选择匹配分数最高的前 k 个专家。 并行策略 ​ 数据并行、模型并行和专家并行是分布式训练中常见的三种并行策略。 数据并行（Data Parallelism） 在所有的worker上复制数据，给每个worker不同批次的训练样本。worker在每一次迭代后全局同步变化并更新模型。尽管在每轮迭代中没有通信，但是模型的大小不能超过单个worker的能力范围，这使模型的大小受限。 模型并行（Model Parallelism） 按照一定的维度分割权重向量，即模型被分区并放置在不同的worker上。所有的worker一起处理全局批处理，使用相应部分的权重划分进行计算。在每一层后，对嵌入的向量进行聚合和再分布。但是，模型的并行性受限于分区维度和层与层之间通信开销大的限制，无法高效地扩展到非常大的模型。 专家并行（Expert Parallelism） 首先被GShard提出，是一种针对MoE的特殊并行方式。专家分布在不同的worker上，并且每个worker承担不同批次的训练数据。对于非MoE层来说，专家并行和数据并行一样。在MoE层中，序列中的token被发送到它们渴望的专家处。与模型并行相似，每个MoE层的输出被再次交换，重新组织成原始序列，用于下一层的计算。由于MoE模型通常有大量的专家，专家并行度比模型并行度更能随模型规模的增大而增大。 MoE策略的挑战 ​ 主要对三个影响MoE性能的挑战进行详细描述。 倾斜的专家选择（Skewed expert selection） ​ 以Figure3为例，专家0收到3个token，比专家2多3个工作负载。结果，worker 2在下一次通信开始之前很长一段时间处于空闲状态，没有充分利用其可用的计算能力。考虑到训练数据自然遵循倾斜分布，一些专家比其他人更有可能被选中。 ​ 另外，如Figure 4(a)所示的MoE层中，专家的受欢迎程度在整个培训过程中都在不断变化。图4b展示了不同模型中的另一层，在这一层中，受欢迎程度更稳定，但仍然有很多不受欢迎的专家，特别的，放大图，可以看到虽然这些专家不受欢迎，但仍忠心的处理着相应领域的数据。 ​ 更受欢迎的专家比不受欢迎的专家收到的 token 更多，这让它们所在的worker负担更重。因此，MoE续联系统面临的第一个挑战是如何处理倾斜专家选择造成的动态负载不平衡。 同步执行模式效率低（Synchronous execution mode of operations） ​ 考虑到不统一的专家选择会导致计算和通信的不平衡，这种同步执行方法会造成更高的资源浪费。当执行通信或计算时，其他硬件最终没有得到充分利用，而它们可以用于处理其他操作。 ​ 但是，由于通信和计算之间存在依赖关系，因此很难分割到所有的通信。如果传输的顺序不合理，那么很容易造成死锁。因此，第二个挑战是如何有效地组织通信和计算任务并行执行。 网络拥塞与竞争（severe network contention） ​ 最后是专家任务与网络拓扑之间的不协调性。每个Node内部Worker之间连接是高带宽的，但是Worker与Worker之间由于使用的是以太网等通信方式，如果不对专家选择进行约束，那么在数据分布较平衡的情况下Worker与Worker之间的通信更密集，造成拥塞。因此，第三个挑战是如何设计一种网络拓扑感知token分配策略，以避免严重的网络争用。 性能建模 ​ 为了评估和分析训练任务的性能，首先分别引入建立的计算模型和通信模型。然后，进一步建立一个类似屋顶线的模型来研究通信延迟和计算延迟是如何共同影响整体训练效率的。符号标记： Load-aware计算建模 ​ GeMM是训练Transformer时的主要计算。现代大规模的计算设备对常规的计算，如GeMM运行进行了大量优化，甚至实现了峰值吞吐量的90%以上。使用下面公式预测Transformer中MLP层正向计算的时延： L a t_{\\text {comp }}=\\max _{w \\in \\text { workers }}\\left\\{\\frac{4 B_{w} \\alpha H^{2}}{P_{w}}\\right\\} $B_w$：worker w的批大小 $H$：输入的token向量的长度 $\\alpha H$：MLP中两个FC层之间的向量的长度 $P_w$：w个worker进行GeMM的平均吞吐量 ​ 由于单个FMA操作（混合乘加运算）占用两个操作，因此每次FC执行将占据$2B_w\\alpha H^2$个操作。由于有两个FC层，故系数为4。端到端延迟是每个worker的最大延迟，因此该公式反映计算中的负载不均衡。 Topology-aware通信建模 ​ 通信的整体延迟由通信开销和延迟组成。 Note：LogP模型描述计算机系统的并行计算模型 Latency（信息从源到目的地所需的时间） Overhead（处理器接受或发送一条消息所需额外开销，并且在此期间处理器不能做作任何操作） Gap（处理器连续进行两次发送或接收消息之间必须有的时间间隔） Processor（处理器的数目） LogP模型中，网络的容量是有限度的 , 在任何时刻的网上 , 从任何处理器发出或向任何处理器发去的消息个数不得超过 [L /g ]个 , 否则便会发生阻塞。 LogP是个异步模型 ,通信与计算可以重叠 , 并完全采用消息传递的方式进行通信和同步。 ​ 假设在一个节点中通常有多个加速器，每个加速器都是一个worker，不仅应该考虑节点间的连接，还应该考虑节点内的连接，如PCIe、UPI和NVLink。 ​ 论文采用一种拓扑感知模型来预测集体通信操作的延迟。假设链接$l$在单个方向上的带宽为$W{l}$，流量大小为$T{l}$。通信的端到端延迟计算如下。并且分别考虑链路两个方向的流量（两个方向流量可能在负载不平衡时差距很大） L a t_{\\mathrm{comm}}=\\max _{l \\in \\operatorname{links}}\\left\\{\\frac{T_{l}}{W_{l}}\\right\\} ​ 每条链路上的流量取决于算法和路由策略。在每个边缘上，对不同的操作采用不同的方法来计算流量。 All-to-all-v 用于将token从序列中的位置路由到它们所需的专家。由于专家选择的灵活性，每对worker之间的流量是高度可变的。我们假设all-to-all操作只是在所有worker对之间创建链接，并模拟地传输数据。根据拓扑类型的不同，采用一种算法来计算每个工作对之间的路径。对于每对worker，他们之间的流量在路径上的所有有向边上累积。 All-reduce算子广泛应用于数据同步中，如数据并行度中重复模型参数的梯度，模型并行中嵌入向量等。在每个worker上对一个大小为$S$的张量应用ring all-reduce，结果是每个worker在管道中总共发送$2\\frac{n-1}{n}$给它的邻居。 Broadcast and reduce与all-reduce一样具有规律性，利用环形连接和流水线来降低其延迟。但与all-reduce不同的是，它们只通过每个链接发送总大小为$S$的消息。 Note： 分布式训练硬核技术——通讯原语 DDL-Roofline Model ​ 使用DDL-Roofline Model描述给定集群上特定训练任务的性能。 x轴：$R_{CC}$ ​ 计算和通信是并行MoE模型的两个关键因素。因此，定义计算-通信的比率$R{CC}$，表示在DDL- Roofline的X轴上，如下所示： R_{C C}=\\frac{L a t_{\\mathrm{comp}}}{L a t_{\\mathrm{comm}}} ​ $L a t{\\mathrm{comp}}$和$L a t{\\mathrm{comm}}$分别表示由预测器估计的计算和通信延迟。$R{CC}$表示任务是受计算限制还是受通信限制。当$R_{CC}$>1时，计算时间占用端到端延迟时间，否则通信占用大部分延迟时间。这个比率表明了应用不同优化的方向。 y轴：平均计算吞吐量 ​ Y轴的变量为$\\bar{P}$，表示所有worker的平均计算吞吐量。训练一个MoE MLP层时，计算如下。 \\bar{P}=\\frac{12 \\alpha H^{2} \\sum_{w} B_{w}}{N L a t_{\\mathrm{e} 2 \\mathrm{e}}} 图像综合分析 ​ 理想情况下：通信和计算同时进行，得到了一个类似屋顶线的折线，如图5中实线所示的理论上限。计算公式如下： \\bar{P}_{\\text {ideal }}=P_{w} \\min \\left\\{1, R_{C C}\\right\\} ​ 半理想情况：以同步方式进行训练时，硬件的充分利用 \\begin{aligned} \\bar{P}_{\\text {semi-ideal }} &=P_{w} \\frac{L a t_{\\mathrm{comp}}}{L a t_{\\mathrm{comp}}+L a t_{\\mathrm{comm}}} \\\\ &=P_{w} \\frac{R_{C C}}{R_{C C}+1} \\end{aligned} ​ 在半理想情况下，端到端延迟是通信延迟和计算延迟的总和。最初的roofline模型描述的是在单个设备上的程序，内存访问和计算自然是同时执行的，与此不同的是，分布式训练程序通常需要对系统进行显著的优化，以便同时执行它们。 三、论文提出的解决方案：Model-Guided优化方法 轻量级动态跟踪策略 策略概述 ​ 策略驱动：MoE中专家选择可能存在不平衡的情况。传输单个数据的数据量可能比模型参数数量级要小，但是来自所有worker的批量输出可能等于甚至大于模型参数。 ​ 权衡点：传输向量的延迟是否可以用传输专家来代替。 ​ 如图6所示，一些expert被复制到所有的worker上，即shadow expert，它们的参数，而不是输入token，在网络上传输。它们的相关计算是在本地执行的，直观地减少了包含热门专家的工作人员的负载。 动态shadow的实现 ​ 由图4知，expert的popularity随着训练过程的变化而变化，每次迭代可能做的决策不同。此外，参数不能像普通的分布式内存系统那样缓存，因为它们在每次迭代中都要更新，并且需要在更新过程中全局收集梯度。如果它们缓存在每个worker上，那么它们应该在每次迭代中进行更新，从而引入大量的额外开销。即，跟踪有两大瓶颈： Expert的popularity随着训练过程的变化而变化，非固定 无法简单的进行缓存：参数在迭代中会更新 ​ 解决方法预测训练迭代的端到端延迟，以检查性能增益，并据此分析是否应该在运行时跟踪专家。 未使用影子专家前的时延计算 ​ 训练MLP层的一次迭代包含1个正向GeMM和2个反向GeMM，用于计算输入的梯度。all-to-all的通信有4轮，包括两次向前传递的all-to-all和两次向后传递的all-to-all。在网络带宽固定的简化情况下，训练时延的计算如下： L a t_{\\mathrm{imbl}}(B)=\\max _{w}\\left\\{3 \\frac{4 B_{w} \\alpha H^{2}}{P}+4 \\frac{B_{w} H}{W_{\\text {net }}}\\right\\} 使用影子专家后的时延计算 ​ 对于一个shadow专家，必须首先将其参数传播给所有的worker，然后使用获取的模型在本地token上运行计算。在后向阶段，每个worker分别计算其提取的专家的梯度，然后进行all-reduce操作。最后，参数更新操作在最受欢迎的专家最初所在的worker上执行。 ​ 在这种情况下，执行不平衡计算的开销被2个集合通信操作符所取代，每个通信操作符的大小为$\\alpha H^2$。由于多个受欢迎的专家被派往许多其他工作人员，负载不平衡的情况不太可能发生。投影$r$模型的延迟计算如下： L a t_{\\text {shadow }}\\left(r, B^{\\prime}\\right)=\\max _{w}\\left\\{3 \\frac{4 B_{w}^{\\prime} \\alpha H^{2}}{P}\\right\\}+2 r \\frac{2 \\alpha H^{2}}{W_{\\text {net }}} 其中B'表示修改后的批次大小。 权衡结果总结 推导后，进行模型交换而非数据交换的条件为： 传输输入的总开销高于传输模型 B_{\\max }>r \\alpha H 减少的计算延迟大于增加的通信开销 \\frac{3\\left(B_{\\max }-B_{\\max }^{\\prime}\\right) \\alpha H}{r \\alpha H-B_{\\max }}>\\frac{P}{W_{\\text {net }}} ​ 在这两种情况下，都启用了动态阴影来减少端到端延迟。否则，通信开销太大，而且模型交换不能为减少延迟带来好处，因此不能执行。这种情况通常发生在不同worker的工作量平衡时。图5中的箭头(1)表示，由于减少了空转，计算的延迟缩短了，导致了更低的$R_{CC}$和更高的$\\hat{P}$. 算法实现[贪心] 在每个迭代的运行时选择专家进行跟踪。在每个worker上执行一个轻量级算法，如算法1所示。根据上面的公式，它返回一组需要对其进行跟踪的专家。 Note：核心还是一种贪心的思想 异步细粒度智能调度 细粒度任务的划分 问题：当通信和计算分开执行时，程序不能超出半理想曲线。 解决方案：将任务划分为更小的部分，并重新调度细粒度的通信和计算操作，以提高效率。细粒度调度允许计算和通信异步执行，从而更好地利用硬件，使其能够超越图5中箭头(2)所示的半理想曲线。 划分通信：专家并行中，通信遵循all-to-all的模式，使用启发式算法将worker划分更细粒度的组，分割所有人的通信。使用分组的pairwise交换算法去执行all-to-all。 分组划分与环形通信 group pair-wise算法：n个由worker构成的组组成一个大小为n的环，以0到n-1递增的步长向其他的组发送数据。第k步的发送步骤如下描述： 在$step_i$时： $wj$向$w{j-i}$发送数据 $wj$从$w{j+i}$接收数据 具有依赖关系的计算和通信的进行：在一个MoE层的前向或后向阶段，涉及两个对称的all-to-all，并在它们之间进行计算。按照两两交换的方式分割计算，为重新组织它们留出空间。3n个操作由n个组中的所有worker分n个步骤执行。在步骤j中，组i中的worker执行以下3个操作，由图7中的示例实例化。 $S{i,j}$：发送到组$t{i, j}=(i-j)$并从$f_{i, j}=(i+j)$接收token(都对n取模)。 $C{i,j}$：使用本地专家从$f{i,j}$，在token上进行计算。 $R{i,j}$：从$t{i,j}$接收本地 token 的输出并把计算结果送回到$f_{i,j}$ ​ 调度的目标是并行地执行计算和通信。为每个worker创建一个通信流和一个计算流，以执行不同类型的操作符。但所有操作都必须遵循它们的数据依赖关系，并在启动自己之前等待之前的任务执行。 Note：数据依赖关系可以由下图表示 ​ 不同的遵循数据依赖关系的调度方式如下： ​ 可以看出，在计算流始终繁忙的情况下如图8(b),(c)，能够优化时间的主要机会是第一个S和最后一个R。pairwise调度能保证对于任何一个worker来说，最快的两个操作$S{i,0}$为第一个，$R{i,n-1}$为最后一个，最大限度的减少开销。 避免竞争的专家选择策略 ​ MoE模型中，最终目标是用足够多的样本来训练专家，而不是每个样本都被期望的专家处理。并且由于采用拟合分数作为权重，改变专家的选择并不会造成数值上的错误。如前文所述，在树形结构的普通集群中，上层连接的带宽通常低于本地连接。与其他常规的集体交流不同，all-to-all 会导致链路上更高的竞争。因此可以通过限制通过上层链接的token数量减少上层连接的竞争压力。限制的具体方法： ​ 假设交换机连接 N 个节点和每个节点上的M 个 workers。worker和主机之间的流量大致为$T{w}=\\frac{M N-1}{M N} B H$。同时，每个节点网口的流量为$T{n}=\\frac{M(N-1)}{N} B H$，大约比$T_w$大M倍。 ​ 为了减少拥塞，允许将最多 $L=\\frac{W{\\text {net }}}{M W{\\text {local }}} B$ 个token定向到另一个节点。这里，$W{net}$和$W{local}$分别表示节点间和节点内的通信带宽。具体来说，如果有超过L个token，其最佳选择位于另一个节点上，则允许其中得分最高的L个token。它们的其余部分与其他token一起留在本地节点中重新选择它们所需的专家。 四、实验和评估 实验设置 FastMoE：实验是基于FastMoE，FastMoE是全球首个基于PyThorch的可以专家并行训练网络的框架。实验实现时修改了其中的某些操作，添加了若干的门网络验证实验。 Megatron-$LM^6$：训练Transformer的框架 实验比较对象 和若干不同的系统进行了相关比较： 支持k个专家选择的baseline 未优化的FastMoE：专家并行baseline DeepSpeed+ZeRO：数据并行baseline MoE 使用专家选择修改达到优化的baseline GShard：state-of-art MoE系统（by Google） 限制了每个专家的能力（输入数量），达到负载均衡的情况。去掉多余的输入。 FairSeq+BASE Layers：另一个state-of-art MoE系统（by Facebook） 使用匹配算法，在完美的负载均衡的情况下提升分数总和。 硬件和实验模型 硬件： johnny cluster：16 NVIDIA V100 PCIe GPUs in 2 nodes trevor cluster：64 NVIDIA V100 PCIe GPUs in 16 nodes 模型： 实验结果 第一组baseline下的实验结果 比较训练单个MoE层的加速： More than 17x speedup over DeepSpeed + ZeRO baseline. More than 5x speedup over FastMoE baseline. 第二组baseline下的实验结果 因为修改了模型本身的行为，对比了收敛的速度： Both baseline systems take significantly more steps to converge. Convergence speed is 1.37x shorter than GShard, and 2.19x shorter than BASE Layers. The topology-aware gate makes iterations 9. 4% faster. 评估总结 背景：MoE模型较大且具有动态性 在分布式环境下训练MoE提出了三个策略解决三个问题： 解决专家选择倾斜的问题：影子专家 解决粗粒度计算：计算和通信重叠 解决信道竞争：门网络减少拥塞 提出DDL-roofline可以评估系统的性能。 实验：与大型模型的最先进系统(包括ZeRO、GShard和基础层)设计实验比较，FasterMoE实现了1.37 - 17.87的加速。 var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"论文阅读/SEUSS阅读笔记.html":{"url":"论文阅读/SEUSS阅读笔记.html","title":"SEUSS阅读笔记-2020-EuroSys-JamesCadden","keywords":"","body":"SEUSS 阅读报告 一、论文研究背景、动机与主要贡献 研究背景与动机 ​ 首先论文引入了一个计算机领域普遍存在的问题：计算冗余。 ​ 计算冗余具体在Serverless 中，可以用Figure1说明：一次完整的函数调用可以细分为多个阶段，如果我们在中间某个阶段保有缓存，下次函数调用从缓存开始，那么一次函数的启动速度将大幅加快（启动时间大幅缩短）。这就是用计算缓存的思想解决Serverless中的计算冗余问题。 在传统的解决方案里，我们对于每一次函数调用开启一个专用的容器或者虚拟机，这样的方法是资源密集的，会进行大量重复步骤，出现大量重复的状态 本论文提出了一个轻量级的解决方法：从快照部署 主要贡献 ​ 论文提出了SEUSS(serverless excution using snapshots) 操作系统。SEUSS在FaaS环境中实现，在性能上具有快速部署和高密度缓存的特点，通过从Unikernel快照部署函数来实现这些期望的属性。 ​ 具体实现时，将函数逻辑、语言解释器和SEUSS OS三者打包到unikernel中，并且应用页面级共享的技术（如下图(a)）实现缓存技术。 ​ Unikernel的平面地址空间机制使得我们可以方便地将函数运行的某个具体的状态捕获，成为一个内存中的快照。这样从快照去开启一个unikernel跳过了： 启动单内核 初始化语言 导入代码和编译项 ​ 也可以说，SEUSS的核心思路是通过unikernel捕获到的快照可供后续使用：可以从unikernel快照部署函数。 2. SEUSS方法论 ​ 下面我们详细分析整个SEUSS的设计。首先是Unikernel Context： 2.1 Unikernel Context ​ Unikernel提供了一种机制，用来封装和观察无服务器函数的执行状态。 ​ 在SEUSS中，每个单内核上下文(UC)由一个高级语言解释器(例如，Node.js, Python)组成，它可以导入和执行函数代码。 2.2 SnapShots ​ 快照的概念，类似于VMWare中某个虚拟机的快照，我们可以快速从一个虚拟机快照，启动一个处于某个状态的虚拟机。在本论文中，快照是一个只读的数据对象，它表示一个UC的瞬时执行状态（即它的地址空间和寄存器）。快照可以在函数执行的任意一个时间点保存快照，但是如果每次都保存一个完整的快照，就会导致多个快照之间存在重复内容。 ​ 为了解决该冗余问题，本论文引入了快照栈的概念。 2.3 SnapShots Stack ​ 快照堆栈表示快照之间跨时间的沿袭关系，将每一个快照视为快照堆栈中上一个快照的页面级差异。怎么理解呢？ ​ 简单的说，可以认为他只存储差异部分。可以类比于去计算求解一个大规模问题时采用的增量计算的概念——每次只在上次计算的基础上计算一个$\\Delta$。这里是存储上一个页面基础上的差异部分，也就是说我们存储一个增量快照。 ​ 以下图为例：一个FaaS平台想要快照JavaScript函数Foo()和Bar()的完全初始化状态。 第一种情况：只使用快照机制： 平台需要两个UC快照，每个功能对应一个。如果解释器是100MB，每个函数增加1MB，我们需要202mb的存储空间。 第二种情况是我们引入快照栈： 我们需要使用三个快照，一个缓存初始化的JavaScript解释器，第二个缓存Foo()差异，第三个缓存Bar()差异。这需要102mb，因为两个函数快照共享解释器 ​ 这就是SEUSS解决重复和冗余的一个重要思想。 Anticipatory Optimizations ​ 方案的最后一点是预期优化。AO 的思想是我们在捕获快照之前进行预估，确定在捕获快照的合理时间点，避免过多捕获快照导致的空间冗余和捕获时间不当导致的安全性问题和函数运行错误。 3.SEUSS 实践 ​ 我们重点讲解这个 SEUSS 实践的案例。 过程C与快照B ​ 从时间轴向后看，最开始是一个构造环境和运行时的过程，语言解释器和Invocation Driver会被加载。在调用驱动程序启动之后，将获取运行时快照B。快照B是一个基本快照，基本快照的数量很少，每个语言的解释器只有一个。可以看到这个快照也是体积最大的。从快照B部署UC，即为coldest path 过程W与快照S ​ 接着向后，Invocation Driver将函数和命令发送到单内核，经过编译后，我们若在这里进行一个快照就是快照S，若从快照S部署UC，我们称作Warm path 过程H ​ 最后，我们向其中传入参数，参数传入后，就可以运行了。对于这个过程我们称为hot path。 ​ 上述的快照B和快照S如何使用呢？ 当我们不存在具体函数的快照时，我们从基本快照 快照B 部署UC 这样可以有效减少构建环境和初始化运行时的时间开销 若存在函数的快照时，我们从该快照创建UC，跳过代码导入，编译阶段。 从这个快照部署UC，那么直接导入参数就可以运行。 这样通过快照的使用实现计算缓存。 4.实现 下面是整个实验实现的架构。 EBBRT [35]框架构建的SEUSS OS原型 Rumprun UCS在用户模式（环3）中执行，并具有基于页面的硬件保护 Seuss OS中的网络层伪装了进入UCS的流量，允许外部TCP连接从访客功能中初始化 ​ 对于实现部分，这里详细说明的是快照技术的实现和写时复制的思想，这是SEUSS减少冗余的核心之一。 ​ Seuss OS使用对硬件页表的直接访问来捕获快照，部署UCS，并在快照堆栈和UCS上启用页面级共享。我们针对下面三个方面说明： 何时触发快照的捕获？ ​ 使用x86 debug寄存器来触发快照的创建。在希望保存位置设置断点，当发生单步中断时，就会陷入到内核模式之后跳转到中断处理程序，中断处理程序将UC状态进行快照。 快照的使用？ ​ 为了保持快照的轻量，我们每个快照仅将肮脏的页面克隆，即采用copy-on-write的思想。在论文实现中使用了硬件语义，通过X86 Dirty Bits跟踪页面使用。 怎样部署快照？ ​ 从快照部署始于创建新的UC，进行的是页面的浅拷贝。 5.总结 论文的优点： 快照的不同：基本快照和特定状态的快照 前者具有消除冗余计算的长期价值，后者是短暂可丢弃的。做这样的区分可以显著提高性能 页面级共享 减少冗余的关键思想 使用的技术较为简单 由于缓存存在能够处理爆发式的请求 缺点： 页面级的共享：容易受到侧通道攻击和硬件级别漏洞的影响 未来若考虑并行程度和规模的提高，需要采用更加新进的共享技术 var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"离散数学/about.html":{"url":"离散数学/about.html","title":"离散数学","keywords":"","body":"var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"离散数学/集合论基础.html":{"url":"离散数学/集合论基础.html","title":"集合论基础","keywords":"","body":"集合论基础 1.集合的初见 1.1 集合定义 什么是集合： 集合：由指定范围内满足特定条件的所有对象聚集在一起构成，每一个对象称为这个集合的元素。 公理化集合论： 外延公理 + 空集存在公理 + 无序对公理 + 并集公理 + 幂集公理 + 无穷公理 + 替换公理 + 正则公理 + 选择公理。(ZFC 公理化集合论) 这些公理描述的都是集合的一些属性 集合的例子： 1.2 集合的表示 集合的表示法： 大写字母$A,B,C...,A_1,A_2,C_1$表示集合 小写字母$a,b,c...,a_1,b_1,c_1,...$表示集合中的元素 属于关系： a是集合A中的元素，则称a属于A，记为$a\\in A$ 若a不是集合A中的元素，则称a不属于A，记为$a∉ A$ 集合的表示法： 枚举法：$A={a,b,c,d},B={2,4,6,8,10....}$ 叙述法：刻画集合中元素的特性表示集合 $P={x|P(x)}$ $A={x|x是英文字母中的元音字母}\\ B= {x|x∈Z, x 文视图：用平面上的点做成图示 1.3 基数 集合包含的元素的数量称为集合的基数（base number），记为$|A|$ 若一个集合的基数是有限的，则称该集合为有限集 若一个集合的基数是无限的，则称该集合为无限集 2.特殊集合与集合间的关系 2.1 空集 不含任何元素的集合称为空集，记做$\\empty$ 空集可以符号化为：$\\empty = {x|x\\neq x}$ 空集是绝对唯一的 2.2 全集 针对一个具体范围,我们考虑的所有对象的集合叫做全集(universal set) ,记作U或E.在文氏图一般使用方形表示全集。 2.3 相等关系 2.3.1 元素的基本特性 集合中的元素是无序的。 集合中的元素是不同的。 2.3.2 集合的外延性公理 ==集合的外延性原理== 两个集合相等，当且仅当他们的元素完全相同，记为A=B，否则A和B不相等，记为$A\\neq B$ 2.4 包含关系 2.4.1 包含关系的定义 A中含有B中的所有元素，这种情况称为A包含B \"\\subseteq ”关系的数学语言描述为：B\\subseteq A\\Leftrightarrow 对\\forall x，如果x\\in B，那么x\\in A 2.4.2 集合相等与包含关系 证明集合相等： ==设A和B为两个任意的集合，则$A=B\\Leftrightarrow A\\sube B并且B\\sube A$==【important】 2.4.3 n元集合的子集 n元集合的子集： ★推广:对于任意n元集合A，它的m元(0≤m≤n)子集个数为$C_n^m$个，所以不同的子集个数为: $C_n^0+C_n^1 +...+ Cn^n = (1+ 1)^n= 2^n$. 2.5 幂集 定义：设A为任意集合，把A所有不同的子集构成的集合称为A的幂集，记做$P(A)$，即： P(A) = \\{x|x\\sube A\\} 幂集也叫作集族或集合的集合，对于集族的研究在数学方面，知识库和表处理语言以及人工智能等方面都有重要的意义。 x\\in P(A)\\Leftrightarrow x\\sube A 3. 集合的运算 3.1 并集 3.2 交集 3.3 补集 3.4 差集 3.5 对称差集 4.集合的运算定律 4.1 运算定律 幂等律：$A\\cup A=A;A\\cap A=A$ 交换律：$A\\cup B=B\\cup A; A\\cap B=B\\cap A$ 结合律：$A \\cup(B \\cup C)=(A \\cup B) \\cup C, A \\cap(B \\cap C)=(A \\cap B) \\cap C$ 同一律：$A \\cup \\varnothing=A, A \\cap U=A$. 零律：$A \\cup U=U, A \\cap \\varnothing=\\varnothing$. 分配律： $A \\cup(B \\cap C)=(A \\cup B) \\cap(A \\cup C), A \\cap(B \\cup C)=(A \\cap B) \\cup(A \\cap C)$.——与加减法不同，并也满足分配 吸收律： $A \\cup(A \\cap B)=A, A \\cap(A \\cup B)=A$. 矛盾律和排空律： $\\bar{A} \\cap A=\\varnothing, \\bar{A} \\cup A=U$. 双重否定律：$\\overline{\\overline{A}}=A$ 德摩根律：$\\overline{A \\cup B}=\\bar{A} \\cap \\overline{B}, \\overline{A \\cap B}=\\overline{A} \\cup \\overline{B}$. 4.2 证明 证明方法： 5.可数集合和不可数集合 5.1 自然数集 5.1.1 皮亚诺公里 皮亚诺公理：基于序数的自然数定义公理。定理包括： 0是自然数 每个自然数n都有一个后继，这个后继也是一个自然数，记为$S(n)$ 两个自然数相等，当且仅当他们有相同的后继，即$m=n$，当且仅当$S(m)=S(n)$ 没有任何自然数的后继是0 （归纳公理）若$φ$是一个自然数的预测 如果$φ(0)$为真 当$φ(n)$为真，则有$φ(S(n))$为真 则$φ(n)$对任何自然数成立 5.1.2 冯诺依曼的自然数定义 5.2 等势 如何比较集合之间元素的多少？ 有限集合：基数 无限集合：看集合之间是否存在一种一一对应关系【等势】 设A，B为两个集合，若A，B之间存在一种一一对应关系： \\Psi:A\\rightarrow B\\\\ 则称A和B是等势的，记做： A\\sim B note：由等势的定义可以看出，如果 A = B，那么$A\\sim B$，反之不成立 5.3 可数集合 凡是与自然数集合等势的集合，称为可数集合（countable set），该集合的基数记为$\\aleph_0$（读作阿列夫0） 两个无限集合的大小不能用集合中的元素的个数来衡量，$\\aleph_0$表示一切可数集合的基数，是一种抽象的表达 表面上个数完全不相等的两个集合之间仍然可能存在等势关系，如集合与其真子集之间，体现了有限集合和无限集合的根本差别 5.4 不可数集合 定义：开区间$(0,1)$称为不可数集合，凡是与开区间$(0,1)$等势的集合，称为不可数集合，该集合的基数记为$\\aleph$（读作阿列夫） var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"离散数学/命题逻辑.html":{"url":"离散数学/命题逻辑.html","title":"命题逻辑","keywords":"","body":"命题逻辑 1.命题的概念 1.1 命题 数理逻辑研究的中心问题是推理，而推理的前提和结论都是命题，因而命题是基本的推理单元。 定义： 具有确切真值的陈述句称为命题（proposition）。该命题只可以取一个“值”，称为真值。真值只有“真”和“假”两种，分别用“T”（或“1”）和“F”（或“0“）表示。 一切没有判断内容的句子都不是命题 有时需要依靠环境、条件、时间、地点判断命题的真值，而一个句子本身是否能够分辨真假与我们是否知道他的真假是两回事，也就是说，对于一个句子，有时我们可能无法判断他的真假，但这个句子本身是有真假的。 1.2 原子命题与复合命题 1.2.1 概念 原子命题(简单命题) :不能再分解为更为简单命题的命题。 复合命题:可以分解为更为简单命题的命题。这些简单命题之间是通过如\"或者\"、“并且”、\"不”、\"如果则....“， “当且仅当\"等这样的关联词和标点符号复合而成。 1.2.2 表示法 通常使用大写的带或者不带下标的英文字母表示命题（包括原子命题和复合命题） 1.3 命题连接词 主要的命题连接词有5个： 或者 并且 不 如果……则…… 当且仅当 1.3.1 否定连接词 定义：设P是任意一个命题，复合命题\"非P\"(或“P的否定”)称为P的否定式(negation) ，记作$\\urcorner P$ ，“$\\urcorner$”为否定联结词。P为真当且仅当$\\urcorner$ P为假。 1.3.2 合取连接词 定义：设P、Q是任意两个命题,复合命题\"P并且Q\"(或\"P和Q\")称为P与Q的合取式(conjunction) ,记作$P\\land Q$,“A\"为合取联结词。$P\\land Q$为真当且仅当P, Q同为真。 1.3.3 析取连接词 设P、Q是任意两个命题，复合命题“P或Q”称为P与Q的析取式(disjunction) ,记作$P\\vee Q$, “V\"为析取联结词。$P\\vee Q$为真当且仅当P, Q至少有一个为真。 代表的是自然语言中的“可兼或”，“不可兼或”是异或。 1.3.4 蕴含连接词 设P、Q是任两个命题,复合命题“如果P，则Q”称为P与Q的蕴涵式(implication) ，记作P→Q,“→\"为蕴涵联结词。P→Q为假当且仅当P为真且Q为假。一般把蕴涵式P→Q中的P称为该蕴涵式的前件, Q称为蕴涵式的后件。 前件为假，那么不管后件真假如何，命题为真。 在自然语言中，前件为假，不管结论真假，整个语句的意义,往往无法判断。但对于数理逻辑中的蕴涵联结词来说,当前件P为假时,不管Q的真假如何，则P→Q都为真。此时称为“善意推定”。 1.3.5 等价连接词 设P、Q是任两个命题,复合命题\"P当且仅当Q\"称为P与Q的等价式(equivalence) ,记作“$P\\leftrightarrow Q$“，\"$\\leftrightarrow $\"为等价联结词(也称作双条件联结词)。$P\\leftrightarrow Q$为真当且仅当P、Q同为真假。 2. 命题符号化及其应用 联结词是两个命题真值之间的联结，而不是命题内容之间的连接，因此复合命题的真值只取决于构成他们的各简单命题的真值，而与它们的内容无关，与二者之间是否有关系无关。 Example： 命题1 ：雪是白的当且仅当北京是中国的首都。 真命题 命题2：如果2是偶数,则天上就可以掉馅饼。 假命题 2.1 连接词的优先级 所有五个连接词的优先顺序为： 否定 > 合取 > 析取 > 蕴含 > 等价 同级的连接词，按其出现的顺序（从左往右） 若运算要求与优先次序不一样，可以使用括号；同级连接词相邻时也可以使用括号 括号中的优先级为最高优先级 2.2 命题的符号化 3. 命题公式和真值表 3.1 命题变元 定义：一个特定的命题是一个常值命题 ，它不是具有值“T\"(\"1\") ，就是具有值“F\"(“0\")。 定义：一个任意的没有赋予具体内容的原子命题是一个变量命题，常称它为命题变量(或命题变元)(propositional variable)，该命题变量无具体的真值,它的变域是集合{T, F}(或{0, 1})。 复合命题是由原子命题与联结词构成的命题。所以，当其中的原子命题是命题变元时，此复合命题也即为命题变元的函数，且该函数的值仍为“真”或\"假”值，这样的函数可形象地称为“真值函数”或“命题公式”，此命题公式没有确切的真值。 G=P\\vee Q\\rightarrow \\neg P 3.2 命题公式 3.2.1 命题公式的概念 命题演算的合式公式又称为命题公式（简称公式），按如下规则生成： 命题变元本身是一个公式（如：$P，Q，R$） 如果G是公式，那么$\\neg G$也是公式 如果G, H是公式，那么$G\\vee H, G\\land H,G\\rightarrow H,G\\leftrightarrow H$也是公式 仅由有限步使用规则（1）（2）（3）得到的包含命题变元、连接词和括号的符号串才是命题公式。 note： 原子命题变元是最简单的合式公式，称为原子合式公式，简称原子公式 命题公式没有真值，只有对其命题变元进行真值指派后，方可确定命题公式的真值; 整个公式的最外层括号可以省略；公式中不影响运算次序的括号也可以省略。 在实际应用中，为了便于存储和运算，命题公式常用二元树的方式来表达。 3.2.2 公式的解释 定义：设$P_1、P_2、P_3、 ... P_n$是出现在公式G中的所有命题变元，指定$P_1、 P_2、P_3、 .... P_n$一组真值，则这组真值称为G的一个解释，常记为$I$。 如果公式在I下的解释是真的，则称I满足G，此时I是G的成真赋值；如果G在解释I下是假的，则称I弄假G，此时I是G的弄假赋值。 3.2.3 真值表 由公式G在其所有的解释下所取的真值构成的表，称为G的真值表。 3.3 命题公式分类和等价 3.3.1 命题公式的分类 定义： 如果一个公式G在所有解释下的真值都为“真”，公式G为永真公式（重言式） 如果一个公式G在所有解释下的真值都为“假”，公式G为永假公式（矛盾式），有时也称不可满足式 如果一个公式不是永假的，那么他是可满足式 三种公式直接的关系： G是永真的，当且仅当$\\urcorner G$是永假的 G是可满足的，当且仅当至少有一个解释$I$，使G在$I$下为真 若G是永真式，则G一定是可满足式，但反之可满足公式不一定是永真式 3.3.2 公式的等价 定义：设G, H是两个命题公式$P_1, P_2, P_3, ... , P_n$.是出现在G, H中所有的命题变元，如果对于$P_1,P_2,P_3,...,P_n$的$2^n$个解释，G与H的真值结果都相同，则称公式G与H是等价的，记作G = H。( 或G$\\Leftrightarrow$H) 定理：对于任意两个公式G和H，==G = H的充分必要条件是公式$G\\leftrightarrow H$是永真公式==。 3.3.3 命题公式的可判定性 可判定性：能否给出一个可行方法，完成对任意公式的判定类问题。（类型或等价判定） 命题公式是可判定的。——使用真值表/公式推理的方法判定公示 3.4 基本等价关系及其应用 3.4.1 基本等价关系 设 $G, H, S$ 为任意的命题公式。 (1) $E{1}: G \\vee G=G$; $E{2}: G \\wedge G=G$. 幂等律 (2) $E{3}: G \\vee H=H \\vee G$; $E{4}: G \\wedge H=H \\wedge G$. 交换律 (3) $E{5}: G \\vee(H \\vee S)=(G \\vee H) \\vee S$; $E{6}: G \\wedge(H \\wedge S)=(G \\wedge H) \\wedge S$. 结合律 (4) $E{7}: G \\vee 0=G$; $E{8}: G \\wedge 1=G$. 同一律 (5) $E{9}: G \\vee 1=1$; $E{10}: G \\wedge 0=0$. 零律 (0) $E{11}: G \\vee(H \\wedge S)=(G \\vee H) \\wedge(G \\vee S)$; $E{12}: G \\wedge(H \\vee S)=(G \\wedge H) \\vee(G \\wedge S)$. 分配律 (1) $E{13}: G \\vee(G \\wedge H)=G$ $E{14}: G \\wedge(G \\vee H)=G$. 吸收律 (8) $E{15}: \\neg G \\wedge G=0$. 矛盾律 (9) $E{16}: \\neg G \\vee G=1$. 排中律 (10) $E_{17}: \\neg(-G)=G$. 双重否定律 3.4.2 基本等价关系的应用 Example： 4. 范式 4.1 范式的概念 真值表能够方便地给出命题公式的真值情况，但是真值表的规模随着命题变元的数量呈指数型增长，因而我们考虑一种真值表的替代方法，这种方法是基于命题公式的一种标准形式。 4.1.1 简单析取式与简单合取式 定义： 命题变元或者是命题变元的否定称为文字 仅由有限个文字构成的析取式称为简单析取式（或子句） 仅由有限个文字构成的合取式称为简单合取式（或短语） note：有限个包括一个，文字既是子句也是短语 P与$\\urcorner P$是互补对 4.1.2 析取范式和合取范式 定义： 有限个简单合取式（短语）的析取式称为析取范式 如(P\\land Q)\\vee (\\urcorner P\\land Q)，又如P\\vee \\urcorner Q, P,\\urcorner Q 有限个简单析取式（子句）的合取式称为合取范式 如(P\\vee Q)\\land (\\urcorner P\\vee Q)，又如P\\land \\urcorner Q, P,\\urcorner Q 总结 范式关注的是命题公式的当前书写形式； 单个的文字是子句、短语、析取范式，合取范式； 析取范式、合取范式仅含联结词集{$\\urcorner \\land \\vee$} ,且否定联接词仅出现在命题变元之前。 范式存在定理： 对于任意命题公式，都存在与其等价的合取范式和析取范式。 Proof： 可以由逻辑等价公式求出等价它的析取范式和合取范式，具体步骤如下： 总结： 命题公式的析取范式可以指出公式何时为真，而合取范式可以指出公式何时为假，从而能够代替真值表。 命题公式的范式表达并不唯一，比如对公式$(P\\vee Q)\\land (P\\vee R)$而言，对应的析取范式有很多 最后： 一般求解范式的时候，最后要进行化简的过程。 4.2 主范式 引入主范式： 由于范式的不唯一性，我们考虑对构成范式的子句或短语进一步规范化 ,从而形成唯一的主析取范式和主合取范式。 4.2.1 极小项和极大项 4.2.1.1 定义 在含有n个命题变元$P_1,P_2,...,P_n$的短语或者子句中，若每个命题变元与其否定不同时存在，但二者之一恰好出现一次且仅一次，并且出现次序与$P_1,P_2,...,P_n$一致，则称此短语为关于$P_1,P_2,...,P_n$的一个极小项或者极大项。 一般来说，若有n个命题变元，则应有$2^n$个不同的极小项和$2^n$个不同的极大项 4.2.1.2 性质 $m_i\\land m_j=0;M_i\\vee M_j=1(i\\neq j)$ $m_i = \\urcorner M_i; M_i=\\urcorner m_i$ $\\vee{i=0}^{2^n-1}m_i=1;\\land{i=0}^{2^n-1}M_i=0$ 4.2.2 主析取范式和主合取范式 定义： 在给定的析取范式中，若每一个短语都是极小项，且按照编码从小到大的顺序排列，则称该范式为主析取范式(principal disjunctive normal form)。 在给定的合取范式中，若每一个子句都是极大项，且按照编码从小到大的顺序排列，则称该范式为主合取范式(principal conjunctive normal form)。 如果一个主析取范式不包含任何极小项,则称该主析取范式为“空”；如果一个主合取范式不包含任何极大项,则称主合取范式为“空\"。 公理： 任何一个公式都有与其等价的主析取范式和主合取范式。 Proof： 求出公式的析取范式和合取范式 消去重复出现的变元，矛盾式与重言式 若析取（合取）式的某一个短语（子句）$B_i$中缺少命题变元P，则可用下面的方法将命题变元P补进去 利用幂等律将重复的极小项和极大项合并，并利用交换律进行顺序调整，由此可转换成标准的主析取范式和主合取范式。 4.2.3 范式的求解 求解方法1：公式转换法 求解方法2：真值表法 利用真值表技术求主析取范式和主合取范式的简要方法: 列出真值表，选出公式的真值结果为真的所有的行，在这样的每一行中，找到其每一个解释所对应的极小项，将这些极小项进行析取即可得到相应的主析取范式。 列出真值表，选出公式的真值结果为假的所有的行，在这样的每一行中，找到其每一个解释所对应的极大项，将这些极大项进行合取即可得到相应的主合取范式。 从真值表按所给的算法求出主范式的方法,称为真值表技术(technique of truth table)。 由真值表技术可知，对于任一个命题公式而言，主析取范式所使用的极小项的编码和主合取范式所使用的极大项的编码是“互补”的关系。从而我们在求主析取范式和主合取范式时，可根据公式特点，先求出二者之一，然后可直接写出另一 个。 4.2.4 范式的应用 主范式可以用于了解公式的真值情况，进行公式类型的判定和等价关系的判定。 如果主析取范式中包含所有的极小项，那么该公式为永真公式 如果主合取范式中包含所有的极大项，那么该公式为用假公式 如果两个公式有相同的主析取范式或者主合取范式时，那么两个公式等价 5. 联结词的完备集 5.1 真值函数 定义：称$F:{0,1}^n\\rightarrow {0,1}$为n元真值函数 F的定义域：${0,1}^n={00...0,00...1,...,11...1}$，即由0，1组成的长为n的符号串的全体，值域为${0,1}$。n个命题变项可以构成$2^{2^n}$个不同的真值函数。 1的真值函数有4个 2的真值函数有16个 3的真值函数有$2^{2^3}=256$个 每个真值函数与唯一的主析取范式（主合取范式）等值。例如$F_0^{(2)}\\Leftrightarrow 0$(矛盾式)，$F_1^{(2)}\\Leftrightarrow (p \\land q) \\Leftrightarrow m_3……$，等。每个主析取范式对应无穷多个等值的命题公式，每一个命题公式又有唯一等值的主析取范式，所以每个真值函数对应无穷多个等值的命题公式，每个命题公式又对应唯一的等值的真值函数。 5.2 联结词的完备集 定义： 设S是一个联结词集合，如果任何$n(\\geq 1)$元真值函数都可以由仅含S中的联结词构成的公示表示，那么则称S是联结词的完备集。 定理：$S={\\urcorner, \\vee, \\land}$是连接词完备集 推论：以下的联结词都是联结词完备集 (1) $S{1}={\\neg, \\wedge, \\vee, \\rightarrow}$ (2) $S{2}={\\neg, \\wedge, \\vee, \\rightarrow, \\leftrightarrow}$ (3) $S{3}={\\neg, \\wedge}$ (4) $S{4}={\\neg, \\land}$ (5) $S_{5}={\\neg, \\rightarrow}$ 5.3 与非与或非 设p, q是两个命题，复合命题“p与q的否定”称为p, q的与非式，记做$p\\uparrow q$，即$p\\uparrow q \\Leftrightarrow \\neg(p \\land q)$，符号$\\uparrow $称为与非连接词。 设p, q是两个命题，复合命题“p或q的否定”称为p, q的或非式，记做$p\\downarrow q$，即$p\\downarrow q \\Leftrightarrow \\neg(p \\vee q)$，符号$\\uparrow $称为与非连接词。 定理：${\\uparrow }和{\\downarrow}$都是联结词完备集 var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"离散数学/命题逻辑的推理理论.html":{"url":"离散数学/命题逻辑的推理理论.html","title":"命题逻辑的推理理论","keywords":"","body":"命题逻辑的推理理论 1. 基本推理形式和蕴涵关系 1.1 基本推理形式 所谓推理，指的是从一组前提合乎逻辑地推理出结论的过程。在这里我们用命题公式来表达前提和结论。 定义： 设$G_1, G_2,...，G_n, H$是公式，称$H$是$G_1, G_2,... , G_n$的逻辑结果当且仅*当对任意解释$I$，如果$I$使得$G_1 \\land G_2\\land...\\land G_n$为真，则$I$也会使H为真。记为$G_1,G_2,... ,G_n\\Rightarrow H$。“$\\Rightarrow$”称为蕴涵关系。此时称$G_1, G_2,... , G_n\\Rightarrow H$为有效的，否则称为无效的。$G_1, G_2,... ,G_n$称为一组前提，有时用集合$\\Gamma$来表示，记为$\\Gamma= {G_1, G_2,... ,G_n} $，$H$称为结论。此时也称$H$是前提集合$\\Gamma$的逻辑结果。记为$\\Gamma→H$。 公理： 公式$H$是前提集合$\\Gamma = {G_1,G_2,...,G_n}$的逻辑结果当且仅当$(G_1\\land G_2\\land …\\land G_n)\\rightarrow H$为永真式。 判定方法： 真值表技术 公式转换关系 主析取范式法——永真式的主析取范式应该包含有所有的极小项 1.2 基本蕴涵关系 定理： 设 $G, H, I$ 为任意的命题公式。 (1) $I{1}: G \\wedge H \\Rightarrow G ; \\quad I{2}: G \\wedge H \\Rightarrow H$. (简化规则) (2) $I{3}: G \\Rightarrow G \\vee H ; \\quad I{4}: H \\Rightarrow G \\vee H$. (添加规则) (3) $I5: I, H \\Rightarrow G \\wedge H$; (合取引入规则) (4) $I{6}: G \\vee H, \\neg G \\Rightarrow H ; \\quad I{7}: G \\vee H, \\neg H \\Rightarrow G$. (选言三段论) (5) $I{8}: G \\rightarrow H, G \\Rightarrow H$; (假言推理规则) (6) $I{9}: G \\rightarrow H, \\neg H \\Rightarrow \\neg G$; (否定后件式) (7) $I{10}: G \\rightarrow H, H \\rightarrow I \\Rightarrow G \\rightarrow I$; (假言三段论) (8) $I_{11}: G \\vee H, G \\rightarrow I, H \\rightarrow I \\Rightarrow I$ (二难推论) Example： 2. 基本演绎法 2.1 推理规则 规则P（称为前提引用规则）：在推导的过程中，可以随时引入前提集合中的任意一个前提。 规则T（称为逻辑结果引用规则）：在推导的过程中，可以随时引入公式S，该公式S是由其前的一个或者多个公式推导出来的逻辑结果。 规则CP（称为附加前提规则）：如果能从给定的前提集合$\\Gamma$与公式P推导出来S，则能从前提集合$\\Gamma$推导出来S。 2.2 演绎法推论 2.2.1 自然演绎法 定义： 从前提集合$\\Gamma$推出结论$H$的一个演绎是构造命题公式的一个有限序列：$H1, H_2, H_3,... ,H{n-1},H_n$。其中，$H_i$或者是$\\Gamma$中的某个前提,或者是前面的某些$H_j(j 2.2.2 演绎 2.2.2.1 直接证明法 通常采用倒推的方式： 2.2.2.2 CP规则 2.2.2.3 间接证明法 反证法、归谬法 反证法可以认为是CP规则的一种变型。 2.3 推理的应用 var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"离散数学/谓词逻辑.html":{"url":"离散数学/谓词逻辑.html","title":"谓词逻辑","keywords":"","body":"谓词逻辑（一阶逻辑） 1. 谓词的引入 1.1 命题逻辑的局限性 1.2 个体词和谓词 1.2.1 个体词 个体词可以分为两种，个体常量和个体变量，均在个体域内取值。 表示具体或特定的个体词称为个体常量。一般用带或不带下标的小写英文字母$a,b,c,... ,a_1,b_1, c_1,...$等表示。 表示抽象的或泛指的个体词称为个体变量。一般用带或不带下标的小写英文字母$x,y,z,... ,x_1,y_1,z_1,...$ 等表示。 个体词的取值范围称为个体域，常用D来表示 宇宙间的所有个体域聚集在一起所构成的个体域称为全总个体域。 若无特别说明，均使用全总个体域。 1.2.2 谓词 设D为非空的个体域,定义在$D^n$(表示n个个体都在个体域D上取值)上取值于{0,1} 上的n元函数，称为n元命题函数或n元谓词，记为$P(x_1,x_2,... ,x_n)$。其中，个体变量$x_1,x_2,... ,x_n∈D$。 表示具体性质或关系的谓词称为谓词常量。 表示抽象的或泛指的性质或关系的谓词称为谓词变量。 谓词均使用大写英文字母$P, Q,R,..,F,G, H,...$来表示。 1.2.3 复合谓词的命题符号化情况 1.3 总结 2. 量词的引入 虽然有了个体词和谓词，但是对于有些命题而言，还是无法准确描述： 2.1 量词 全称量词：$\\forall$，所有的x，任意的x，一切的x，每一个x 存在量词：$\\exists$，有些，至少有一个x，某一些x，存在x 其中的x称为作用变量。一般将其量词加在其谓词之前,记为$(\\forall x)F(x) , (\\exist x)F(x)$。此时, F(x)称为全称量词和存在量词的辖域。 2.2 个体域符号化 使用全总个体域： 统一个体域为全总个体域,而对每一个句子中个体变量的变化范围用一 元特性谓词刻划之。这种特性谓词在加入到命题函数中时必定遵循如下原则: 对于全称量词$\\forall(x)$ ,刻划其对应个体域的特性谓词作为蕴涵式之前件加入。 对于存在量词$\\exists (x)$ ,刻划其对应个体域的特性谓词作为合取式之合取项加入。 2.3 量词的真值确定 量词的顺序不能随便变化： 个体与有限的情况下： 2.4 谓词符号化示例 2.4.1 示例1：一元谓词 2.4.2 示例2：二元谓词 量词对变元的约束往往与量词的次序有关。不同的量词次序,可以产生不同的真值。因此当多个量词同时出现时,不能随意颠倒它们的顺序,否则会改变原有的含义。 2.4.3 示例3：个体域默认选择 3. 谓词合式公式 3.1 四类公式 在基于谓词的形式化中,我们将使用如下四种符号: 常量符号：指所属个体域D中的某个元素，用带或不带下标的小写英文字母$a,b,c,.. ,a_1,b_1,c_1,... $来表示。 变量符号：指所属个体域D中的任意元素，用带或不带下标的小写英文字母$x,y,z,... ,x_1,y_1,z_1,...$来表示。 函数符号：n元函数符号$f(x_1, x_2,... ,x_n)$可以是所属个体域集合$D^n→D$的任意一个函数，用带或不带下标的小写英文字母$f,g,h,... ,f_1,g_1,h_1,...$来表示。==【函数符号的最终取值是个体域中的个体】== 谓词符号：n元谓词符号$P(x_1, x_2,... ,x_n)$可以是所属个体域集合$D^n→{0, 1}$的任意一个谓词，用带或不带下标的大写英文字母$P, Q,R,... ,P_1,Q_1, R_i，...$来表示。==【谓词符号的最终取值是0或者1】== 3.2 项 谓词逻辑中的项( Term),被递归地定义为: 任意的常量符号或任意的变量符号是项; 若$f(x_1,x_2,... ,x_n)$是n元函数符号，$t_1,t_2,... ,t_n$是项，则$f(t_1,t_2,... ,t_n)$是项 仅由有限次使用以上两个规则产生的符号串才是项。 3.3 谓词公式 Definition：若$P(x_1,x_2, ... ,x_n)$是n元谓词，$t_1,t_2,... ,t_n$ 是项,则称$P(t_1, t_2,... ,t_n)$为原子谓词公式，简称原子公式。 3.4 自由变元和约束变元 3.4.1 定义 给定一个合式公式G，若变元x出现在使用变元的量词的辖域之内，则称变元x的出现为约束出现，此时的变元x称为约束变元。若x的出现不是约束出现，则称它为自由出现，此时的变元x称为自由变元。 3.4.2 两个规则 规则1：约束规则的改名规则 将量词中的变元以及该量词辖域中此变量之所有约束出现都用新的个体变元替换; 新的变元-定要有别于改名辖域中的所有其它变量。 规则2：自由变元的代入规则 将公式中出现该自由变元的每一处都用新的个体变元替换 ; 新的变元不允许在原公式中以任何约束形式出现。也可用个体常量代入。 3.5 闭式 4. 公式的解释与分类 4.1 公式的解释 ​ 公式解释的概念： 4.2 公式的分类 如果公式G在它所有的解释下都取值为真，则称G为有效公式。 如果公式G在它所有的解释下都取值为假，则称G为矛盾公式。 如果至少有一个解释下取值为真，则称G为可满足公式。 5. 公式的等价关系 5.1 等价关系的定义 定义：如果$G\\leftrightarrow H$是有效公式，则公式G，H是等价的，记为$G=H$ 定义：设$G(P_1,P_2,...,P_n)$是命题演算中的命题公式，$P_1,P_2,...,P_n$是出现在命题G中的命题变元，当用任意的谓词公式$G_i(1\\leq i\\leq n)$分别代入$P_i$后，得到新的谓词公式$G(G_1,G_2,...,G_n)$称为原公式的代入实例。 永真公式的一个代入实例必然是有效公式 基本等价公式在谓词逻辑找那个仍然成立 5.2 基本等价关系 定理： 假设$G(x)，H(x)$是只含有自由变元$x$的公式，S是不含有$x$的公式，则在全总个体域中，有： $E_{25}: (\\exists x)G(x)=(\\exists y)G(y);$ $E_{26}:(\\forall x)G(x)=(\\forall y)G(y);$ 改名规则 $E_{27}:\\neg (\\exists x)G(x)=(\\forall x)\\neg G(x);$ $E_{28}:\\neg (\\forall x)G(x)=(\\exists x)\\neg G(x)$ 量词转换律/量词否定等价式 $E{29}:(\\forall x)(G(x) \\vee S)=(\\forall x) G(x) \\vee S$; $E{30}:(\\forall x)(G(x) \\wedge S)=(\\forall x) G(x) \\wedge S$. $E{31}:(\\exists x)(G(x) \\vee S)=(\\exists x) G(x) \\vee S$. $E{32}:(\\exists x)(G(x) \\wedge S)=(\\exists x) G(x) \\wedge S$. 量词辖域的收缩与扩张 $E{33}:(\\forall x)(G(x) \\wedge H(x))=(\\forall x) G(x) \\wedge(\\forall x) H(x)$; $E{34}:(\\exists x)(G(x) \\vee H(x))=(\\exists x) G(x) \\vee(\\exists x) H(x)$. 量词分配律 5.3 范式 在命题逻辑里，每一公式都有与之等值的范式，范式是一种统一的表达形式，当研究一个公式的特点(如永真、永假)时，范式起着重要作用。对谓词逻辑的公式来说，也有范式，其中前束范式与原公式是等值的，而其它范式与原公式只有较弱的关系。 5.3.1 定义 5.3.2 求解步骤 6. 谓词综合推理 6.1 推理形式和推理规则 6.1.1 推理形式 定义：设$G_1,G_2,... ,G_n, H$是公式，称$H$是$G_1, G_2,... , G_n$的逻辑结果（或称$G_1, G_2,..，G_n$共同蕴涵H）当且仅当对任意解释$I$，若$I$同时满足$G_1,G_2,... ,G_n$，则满足H，记为$G_1,G_2,... ,G_n→H$，此时称$G_1,G_2,... ,G_n\\Rightarrow H$是有效的，否则称为无效的。$G_1, G_2,... ,G_n$称为一组前提(premise) ，有时用集合F来表示，记$\\Gamma= {G1,G2,... ,Gn}$， $H$称为结论(conclusion) ，又称H是前提集合$\\Gamma$的逻辑结果,记为$\\Gamma→H$。 6.1.2 推理规律 6.1.3 推理规则 消去和引入量词的4种规则 6.1.3.1 全称特指规则US 6.1.3.2 存在特指规则ES 6.1.3.3 全称推广规则UG 6.1.3.4 存在推广规则EG 6.2 综合推理方法 6.2.1 基本方法 6.2.2 难点总结 在推导过程中，如既要使用规则US又要使用规则ES消去量词，而且选用的个体是同一个符号，则必须先使用规则ES，再使用规则US。然后再使用命题演算中的推理规则，最后使用规则UG或规则EG引入量词，得到所求结论。 如一个变量是用规则ES消去量词，对该变量在添加量词时，则只能使用规则EG ; 如使用规则US消去量词，对该变量在添加量词时，则可使用规则EG和规则UG。 在用规则US和规则ES消去量词时，此量词必须位于整个公式的最前端，且辖域为其后的整个公式。 在添加量词$\\forall x$和$\\exists x$时，所选用的$x$不能在公式$G(y)$或$G(c)$中出现。 $p \\lor q$，$p \\rightarrow r$，$q \\rightarrow s$ $\\neg r \\rightarrow s$ var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"离散数学/二元关系.html":{"url":"离散数学/二元关系.html","title":"二元关系","keywords":"","body":"二元关系 1. 序偶和笛卡尔乘积 1.1 序偶 定义：由两个元素按照一定的次序组成的二元组称为序偶，记做$$，其中$x$是第一元素，$y$是第二元素。【顺序很重要】 由定义可见，两个序偶$=$当且仅当$a=c,b=d$ 1.2 笛卡尔乘积 1.2.1 定义 定义：设A，B是两个集合，称集合$A\\times B={|(x\\in A) \\land (y\\in B)}$为集合A与B的笛卡尔乘积。 1.2.2 性质 笛卡尔积不满足交换律 $A\\times B=\\empty$当且仅当$A=\\empty$或者$B=\\empty$ 设A，B，C是任意三个集合，则不一定有$A\\times(B\\times C) = (A\\times B)\\times C$，即笛卡尔积不满足结合律 当A，B都是有限集合时，$|A\\times B| = |B\\times A| =|A|\\times B$ 笛卡尔积对并运算和交运算满足分配律 1.3 推广 定义： 由n个元素$a_1,a_2,...,a_n$按照一定的次序组成的n元组称为n重有序组，记做$$，其中$a_1$是第一个元素，$a_2$是第二个元素，……，$a_n$是第n个元素。 设$A_1,A_2,...,A_n$是n个集合，称集合 $A_1\\times A_2\\times ……\\times A_n={|a_i\\in A_i,i=1,2,3,...,n}$为集合$A_1, A_2,...,A_n$的笛卡尔积。当$A_1=A_2=...=A_n=A$时，可记$A_1\\times A_2\\times …… \\times A_n=A^n$ 2. 关系的定义 2.1 二元关系定义 设A, B为两个非空集合，称$A \\times B$的任意子集R为从A到B的一个二元关系，简称关系(relation)。其中，A称为关系R的前域，B称为关系R的后域。如果$A=B$，则称R为A上的一个二元关系。 几种重要的关系： 当$R=\\empty$时，称R为从A到B的空关系(empty relation) ; 当$R=A\\times B$时，称R为从A到B的全关系(total relation) ; A上的全关系通常记为$E_A$。 当$R=I_A={|x∈A}$时，称R为A上的恒等关系(identity relation)。 有限集合的二元关系的数量： 当集合A，B都是有限集时, $A\\times B$共有$|A|\\times |B|$ 个不同的元素，这些元素将会产生$2^{|A|\\times |B|}$ 个不同的子集。即，==从A到B的不同关系共有$2^{|A|\\times |B|}$个==。 2.2 定义域和值域 定义：设R是从A到B的二元关系，则A为关系R的前域，B为关系R的后域。 令：$C= {x|x∈A,\\exists y∈B,∈R}$ , $D={y|y∈B,\\exists x∈A, ∈R}$。 称C为R的定义域(domain)，记为$C= domR$；D为R的值域(range)，记为$D= ranR$； fldR = $domR∪ranR$为R的域( field)。 2.3 n元关系 3. 关系的表示 3.1 集合表示法 关系是一种特殊的集合，因此集合的两种基本表示法(枚举法和叙述法) ，可以用到关系的表示中。 枚举法 叙述法 图示法 3.2 关系图表示法 $A\\neq B$ $A=B$ 3.3 关系矩阵法 关系运算用上述的两种方式进行较为困难，使用关系矩阵比较简便。 定义：设$A= {a1,a_2, ... ,a_n}, B= {b_1,b_2,... ,b_m}$，R是从A到B的一个二元关系，称矩阵$M_R = (m{ij})_{n\\times m}$ 为关系R的关系矩阵(relation matrix) ,其中:$\\begin{cases}1\\ ∈R\\0\\ \\notin R\\end{cases}(1≤i≤m,1≤j≤n)$又称$M_R$为R的邻接矩阵(adjacency matrix)。 3.4 布尔矩阵的运算 3.4.1 布尔矩阵的交和并 3.4.2 布尔矩阵的积运算 4. 关系的运算 4.1 关系的并交差补运算 关系是一种特殊的集合，因此集合的所有基本运算(并、交、差、补)，都可以应用到关系中，并且同样满足集合的所有运算定律。 4.2 关系的复合运算 定义：设A，B，C是3三个集合，R是从A到B的关系，S是从B到C的关系（即$R：A→B,S：B→C$），则R与S的复合关系(合成关系）（composite relation）RoS是从A到C的关系，并且：$R o S={|(x∈A)\\land (z∈C)\\land (\\exists y)(y∈B\\land xRy\\land ySz)}$。运算\"o\"称为复合运算（composite operation）。 ​ ——R的后域是S的前域 4.3 逆运算 定义：设A，B是两个集合，R是A到B的关系，则从B到A的关系$R^{-1}={|∈R}$称为R的逆关系(inverse relation) ,运算“-1” 称为逆运算(inverse operation)。 $(R^{-1})^{-1}=R$ $\\O^{-1}=\\O$ $(A\\times B)^{-1}=B\\times A$ 求逆运算在三种表示法中的体现： 5. 关系的运算定律 5.1 复合运算性质 设A、B、C和D是任意四个集合，R、S和T分别是从A到B，B到C和C到D的二元关系，$I_A$和$I_B$分别是A和B上的恒等关系，则 证明方法： 证明两个关系相等，即证明两个集合相等；证明两个集合相等，也即证明两个集合相互包含。 以结合律为例，证明两个集合相等： 分配律 5.2 逆运算的运算定律 设A，B，C是三个集合，R, S分别是从A到B和从B到C的关系，则有： (R\\circ S)^{-1}=S^{-1}\\circ R^{-1} 6. 关系的幂运算 只要运算满足结合律，那么一定可以定义该运算的幂运算。 关系的复合运算满足结合律，因此可以定义关系的复合运算的幂运算。 6.1 幂运算的定义 设R是集合A上的关系，则R的n次幂，记为$R^n$，定义如下： $R^0=I_A$——【why？考虑同一律】 $R^1=R$ $R^{n+1}=R^n\\circ R=R\\circ R^n$ $R^n$仍是A上的关系，表示R多次自我复合的结果： $R^{m+n}=R^m\\circ R^n=R^n\\circ R^m=R^{m+n}$ $(R^m)^n=R^{mn},m,n\\in N$ 6.2 幂运算的性质 由前例可见，$R^n$的基数并非随着n的增加而增加，而是呈递减趋势 当$n\\geq |A|$时，则$R^n\\sube \\cup_{i=1}^{|A|}R^i$ 6.3 幂运算收敛定理 定理：设A是有限集合，且$|A|=n$，R是A上的关系，则： \\cup_{i=1}^\\infty R^i = \\cup_{i=1}^n R^i 7. 关系的性质 关系的性质可以对关系进行分类。 7.1 自反性与反自反性 定义： 设R是集合A上的关系， 如果对任意的$x\\in A$，都有$\\in R$，那么称R在A上是自反的，或者称R具有自反性。 如果对任意的$x\\in A$，都有$\\notin R$，那么称R在A上是反自反的，或者称R具有反自反性。 对于关系矩阵上的体现，会体现在对角线上： 总结 存在既不是自反的也不是反自反的关系; 关系R是自反的当且仅当R的关系图中每个结点都有自环，关系R是反自反的当且仅当R的关系图中每个结点都无自环; 关系R是自反的当且仅当R的关系矩阵的主对角线上全为1，关系R是反自反的当且仅当R的关系矩阵的主对角线上全为0. 7.2 对称性 设R是A上的关系： 如果对任意的$x,y\\in A$，如果$\\in R$，那么$\\in R$，那么称R是对称的，或称R具有对称性。 如果对任意的$x,y\\in A$，如果$\\in R且\\in R$，那么$x=y$，那么称R是反对称性的。 存在既是对称也是反对称的关系，也存在既不是对称也不是反对称的关系。 7.3 传递性 定义：设R是集合A上的关系，对任意的$x,y,z\\in A$，如果$\\in R $且$\\in R$，那么$\\in R$，则称R是传递的，或称R具有传递性。 对于关系图上的传递性的表现：有a->b, b->c一定有a->c 关系矩阵： 7.4 关系性质的判定定理 对具体集合上的具体关系，我们可根据关系图和关系矩阵等方法来判定关系的性质，但对于抽象集合上的抽象关系，则存在一定的局限性。为此，我们从集合运算的观点，给出相应的判定定理。 7.4.1 判定定理 设R是集合A上的关系，则： R是自反的，当且仅当$I_A\\sube R$——最小的是$I_A$ R是反自反的，当且仅当$R\\cap I_A=\\O$ R是对称的，当且仅当$R=R^{-1}$ R是反对称的，当且仅当$R\\cap R^{-1}\\sube I_A$——只可能是$I_A$中的元素 R是传递的，当且仅当$R\\circ R\\sube R$ 7.4.2 判定方法总结 7.4.3 关系性质判定例子 一个关系可能满足多种性质： 一个关系可能多种性质都不满足： 7.5 关系性质的保守性 关系既可做各种集合基本运算，又可做关系特有的复合运算和求逆运算。具有特殊性质的关系通过各类运算后产生的新关系是否仍然保持原有的特殊性质呢？这就是关系性质的保守性问题。 8. 关系的闭包 ​ 一个关系可能不具备某一个特殊性质。但是，如果希望它有我们希望它具备的某一个性质，应该如何操作呢？我们可以通过添加一些元素，使得关系具备我们想要的性质。例如，对给定集合A= {1, 2, 3}上的关系R= {, , }，它不具有自反性。根据自反性的定义，在关系R中添加, 这两个元素后，所得到的新关系$R^{'}$就具有自反性。另外还可以添加, , ，得到的新关系$R^{''}$仍然具有自反性。 ​ 如何在给定关系中添加最少的元素，使其具有需要的特殊性质，这就是关系的闭包问题。 ​ 自反性，对称性，传递性可以通过添加元素得到，但是对于反自反性，反对称性，无法通过添加元素得到，只能通过删除元素得到。这里不考虑删除元素得到关系性质的情况。 8.1 闭包的定义 设R是集合A上的关系，若存在A上的另一个关系$R'$，满足： $R'$是自反的（对称的，或传递的）——满足性质 对于任何自反的（对称的，传递的）关系$R^{''}$，如果$R\\sube R^{''}$，就有$R^{'}\\sube R^{''}$。则称$R'$为R的自反闭包（对称闭包或者传递闭包），分别记为$r(R)(s(R)或t(R))$ 8.2 闭包求解 利用关系图求闭包 检查R的关系图，在没有自环的结点处加上自环，可得r(R)的关系图; 检查R的关系图，将每条单向边全部改成双向边，可得s( R)的关系图; 检查R的关系图，从每个结点出发，找到其终点，如果该结点到其终点没有边相连，就加上此边，可得t(R)的关系图. 定理： 设 $R$ 是集合 $A$ 上的关系, 则 (1) $r(R)=R \\cup I{A}$; (2) $s(R)=R \\cup R^{-1}$; (3) $t(R)=\\bigcup{i=1}^{\\infty} R^{i}$, 若 $|A|=n$ ，则 $t(R)=\\bigcup_{i=1}^{n} R^{i}$. var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"离散数学/特殊关系.html":{"url":"离散数学/特殊关系.html","title":"特殊关系","keywords":"","body":"特殊关系 1.等价关系 1.1 等价关系定义 1.1.1 定义 设R是非空集合A上的关系，如果R是自反的，对称的，传递的，则称R为A上的等价关系。 1.1.2 同余关系 设n为正整数，定义整数集合Z上的以n为模的同余关系$R={|n|(x-y)}$，证明R是一个等价关系。 1.2 等价类 1.2.1 等价类的定义 定义：设R是非空集合A上的等价关系，对任意$x\\in A$，称集合$[x]_R={y|y\\in A,\\in R}$为$x$关于R的等价类，或者叫做由x生成的一个R等价类，其中$x$称为$[x]_R$的生成元（代表元或者典型元）。 1.2.2 等价类的性质 等价类是非空的 有些等价类是相同的，有些是不同的 所有等价类中的元素汇总为集合的所有元素 定理： 设R是非空集合A上的等价类，则： 对任意$x\\in A$，$[x]_R\\neq \\O$ 对任意$x,y\\in A$，如果$y\\in [x]_R$，则有$[x]_R=[y]_R$，否则$[x]_R\\cap [y]_R=\\O$ $\\cup_{x\\in A}[x]_R=A$ 1.3 商集 1.3.1 定义 定义：设R是非空集合A上的等价关系，由R确定的一切等价类的集合，称为集合A上的商集，记为A/R，即$A/R={[x]_R|x\\in A}$. 1.3.2 等价类的求法 2. 集合的划分 在等价关系中我们已经发现，同一个等价类中的元素具有相同的属性，因而可将集合中的元素分成不同的类别，对应于集合的划分。 2.1 集合的划分的定义 定理： 设R是非空集合A上的一个等价关系，则A对R的商集A/R是A的一个划分，称为由R导出的等价划分。 同一个集合有多种不同的划分，不同的等价关系导出不同的划分。 2.2 等价关系导出 给定集合A的一个划分$\\pi = {S_1,S_2,...,S_m}$，则由该划分确定的关系$R=(S_1\\times S_2)\\cup(S_2\\times S_2)\\cup……\\cup(S_m\\times S_m)$是A上的等价关系。我们称该等价关系为由划分$\\pi$所导出的等价关系。 3. 偏序关系 3.1 偏序关系的定义 定义：设R是非空集合A上的关系，如果R是自反的、反对称的、传递的，则称R为A上的偏序关系(partial order relation), 记为\"$\\leq$\"，读作“小于等于”，并将“$\\in \\leq$\"记为a≤b。序偶$$称为偏序集(partial order set)。 3.2 可比与覆盖 定义： 设R是非空集合$A$上的偏序关系，$\\forall x,y\\in A$， 如果$x\\leq y$或者$y\\leq x$，则称x与y可比 如果$x\\leq y$且不存在$z\\in A$使得$x\\leq z\\leq y$，则称$y$覆盖$x$ 3.3 字典排序 3.4 哈斯图 在偏序集的关系图中，许多有向边可以不用显示出来。例如，偏序关系满足自反性，所以每个结点都有环，因此可以不必显示这些环；又如，偏序关系满足传递性，我们不必显示由于传递性而必须出现的边；另外，由于其反对称的特性，我们可以规定边的方向，从而省去箭头。按照以上方法对关系图进行简化而得到的图形叫做哈斯图，哈斯图对于判断元素之间的先后顺序以及确定特殊元素非常方便。 3.4.1 定义 设R是非空集合A上的偏序关系，使用下面的方法对R的关系图进行简化： 取消每个结点的自环（因自反性） 取消由于传递性出现的边，即若$x\\rightarrow y,y\\rightarrow z$，则去掉$x\\rightarrow z$这条边（因传递性） 重新排列每条边，使得箭头的方向全部向上，然后去掉这些箭头（因反对称性） 以上的步骤可以得到一个包含足够偏序信息的图，这个图称为偏序关系R的哈斯图（Hasse diagram）。 3.4.2 特殊元素 3.4.2.1 最大元和最小元 定义： 设$$是偏序集，*B是A的任意一个子集*。若存在元素$b\\in B$，使得——==最大元和最小元是在集合B中寻找的== 对任意$x\\in B$，都有$x\\leq b$，则称b为B的最大元 对任意$x\\in B$，都有$b\\leq x$，则称b为B的最小元 3.4.2.2 极大元和极小元 定义： 设$$是偏序集，B是A的任意一个子集/u>。若存在元素$b\\in B$，使得——==极大元和极小元也是在集合B中寻找的== 对任意$x\\in B$，都有$b\\leq x\\Rightarrow x=b$，则称b为B的极大元 对任意$x\\in B$，都有$x\\leq b\\Rightarrow x=b$，则称b为B的极小元 4.3.2.3 上界和上确界 定义：设$$是偏序集，B是A的任意一个子集，若存在元素$a\\in A$，使得：——==上界和上确界都是在整个集合中寻找的== 对任意$x\\in B$，满足$x\\leq a$，则称a为B的上界 若元素$a'\\in A$是B的上界，元素$a\\in A$是B的任何一个上界，均有$a'\\leq a$，则称$a'$为B的最小上界或上确界 4.3.2.4 下界和下确界 定义：设$$是偏序集，B是A的任意一个子集，若存在元素$a\\in A$，使得：——==下界和下确界都是在整个集合中寻找的== 对任意$x\\in B$，满足$a\\leq x$，则称a为B的下界 若元素$a'\\in A$是B的上界，元素$a\\in A$是B的任何一个下界，均有$a\\leq a'$，则称$a'$为B的最小下界或下确界 4. 其他次序关系 4.1 拟序关系 设R是非空集合A上的关系，如果R是反自反的和传递的，则称R为A上的拟序关系(quasi-order relation)，记为“$∈$称为拟序集(quasi-order set)。 如果满足反自反和传递性，那么一定满足反对称性，证明如下： 拟序关系 VS 偏序关系： R是A上的偏序关系，则$R-I_A$是$A$上的拟序关系 S是A上的拟序关系，则$S\\cup I_A$是A上的偏序关系 4.2 全序关系 定义：设$$是一个偏序关系，若对任意的$x,y\\in A$，$x$与$y$都是可比的，则称关系$\\leq $为全序关系或者线序关系。称$$为全序集，或线序集，或链。 4.3 良序关系 定义：设$$是全序集，若$A$的任何一个非空子集都有最小元素，则称“$\\leq$”为良序关系，此时$$称为良序集。 4.4 总结 var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"离散数学/函数.html":{"url":"离散数学/函数.html","title":"函数","keywords":"","body":"函数 从二元关系的角度来研究函数 1. 函数的定义 1.1 定义 定义： 设$f$是集合A到B的关系，如果对每个$x\\in A$，都存在唯一的$y\\in B$，使得$\\in f$，则称关系$f$为A到B的函数或者映射，记为$f：A\\rightarrow B$。A为函数$f$的定义域，记为$dom$f=A；$f(A)$为函数的值域，记为ranf。 注意区分$f和f(x)$： $f$：函数，包含了多个序偶 $f(x)$：自变量为$x$时的函数值 如果关系$f$具备下列两种情况之一，那么$f$就不是函数: 存在元素a∈A，在B中没有像; 存在元素a∈A，有两个及两个以上的像。 1.2 举例 定义：把所有从A到B的一切函数构成的集合记为$B^A$： B^A=\\{f|f：A\\rightarrow B\\} 1.3 函数的数量 设函数$f:A\\rightarrow B,|A|=m,|B|=n$，对A中任意的元素而言，其序偶的第二元素都有n种可能的选择，因而总共有$n^m$种选法，也就是有$n^m$个不同的函数。 1.4 函数与一般关系的差别 当A和B都是有限集合时，函数和一般关系有下面的差别： 关系和函数的数量不同：从A到B的不同关系有$2^{|A|\\times|B|}$个，从A到B的不同的函数却仅有$|B|^{|A|}$个 关系和函数的基数不同：每一个关系的基数可以从$0\\sim |A|\\times|B|$，每一个函数的基数都为$|A|$个 关系和函数的第一元素存在差别：关系的第一个元素可以相同，函数的第一个元素一定是互不相同的。 2. 函数的类型 2.1 定义 设f为从集合A到集合B的函数： 对任意的$x_1,x_2\\in A$，如果$x_1\\neq x_2$，那么$f(x_1)\\neq f(x_2)$，则称$f$为从$A$到$B$的单射 如果ranf=B，则称$f$为从$A$到$B$的满射 如果$f$​既是单射又是满射，则称$f$为从$A$到$B$的双射 2.2 必要条件 若$f$是从有限集合A到有限集合B的函数，则有： $f$是单射的必要条件为$|A|\\leq |B|$ $f$是满射的必要条件为$|A|\\geq |B|$ $f$是双射的必要条件是$|A|=|B|$ 2.3 数学化描述 函数类型的数学化描述： $f：A\\rightarrow B$是单射当且仅当对$\\forall x_1,x_2\\in A$，若$x_1\\neq x_2$，那么$f(x_1)\\neq f(x_2)$ $f：A\\rightarrow B$是满射当且仅当对$\\forall y\\in B$，一定$\\exists x\\in A$，使得$f(x) = y$ $f：A\\rightarrow B$是双射，当且仅当满足以上两点条件 2.4 证明 3. 函数的运算 函数是特殊的关系，所以应用于关系的运算也可以应用于函数。但是函数经过某些关系运算之后不能保证仍是函数： 两个函数的交运算和并运算的结果不一定是函数。 3.1 函数的复合运算 定义：设$f:A\\rightarrow B,g: B\\rightarrow C$是两个函数，则$f$和$g$复合关系，$f\\circ g={x\\in A, z\\in C,\\exists y\\in B,使得y=f(x)且z=g(y)}$是从A到C的函数，称为函数$f$与$g$的复合函数，记为$f\\circ g:A\\rightarrow C$ 函数的复合不满足交换律： 函数的复合运算满足结合律： 3.2 函数运算的保守性 设f和g分别是从A到B和从B到C的函数，则： 若f和g是满射，那么$f\\circ g$也是从A到C的满射 若f和g是单射，那么$f\\circ g$也是从A到C的单射 若f和g是双射，那么$f\\circ g$也是从A到C的双射 3.3 函数的逆运算 var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"离散数学/图论基础.html":{"url":"离散数学/图论基础.html","title":"图论基础","keywords":"","body":"var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"操作系统复习笔记/about.html":{"url":"操作系统复习笔记/about.html","title":"操作系统复习","keywords":"","body":"var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"操作系统复习笔记/引论.html":{"url":"操作系统复习笔记/引论.html","title":"引论","keywords":"","body":"引论 1. 背景引入 冯诺依曼机（硬件）组成： Note：《计算机组成原理》这门课就是由冯诺依曼体系机的组成划分，依次介绍说明了计算机。 现代操作系统组成： 现代计算机系统的组成\\begin{cases}硬件设备\\begin{cases}处理器\\\\主存\\\\磁盘\\\\IO设备\\end{cases}\\\\软件\\begin{cases}系统软件\\begin{cases}操作系统\\\\语言处理程序\\\\通用程序\\\\服务支持软件\\end{cases}\\\\应用软件\\end{cases}\\end{cases} 1. 1 关于用户态和内核态的简单讨论 计算机有两种运行模式：内核态（管态、核心态）和用户态。 操作系统运行在内核态 具有对所有硬件的完全访问权，执行任何机器能够执行的任何指令 其他软件运行在用户态 用户态只使用了机器指令中的一个子集，特别的，影响机器控制或者IO的指令，在用户态中是禁止的 用户接口程序（shell或者GUI）处于用太太的最低层次，允许用户运行其他程序。 1.2 什么是操作系统 操作系统是运行在内核态的软件。有两部分的任务： 为应用程序员提供资源集的抽象 管理硬件资源 1.2.1 作为扩展机器的操作系统 操作系统的任务是创建好的抽象，并实现和管理它所创建的抽象对象 example：需要对IO操作深入了解 -> 驱动程序 -> 文件系统（不用在乎细节） 注意区别两个接口： 用户与软件的接口：GUI 软件（编写软件的程序员）与硬件机器：操作系统 1.2.2 作为资源管理者的操作系统 自顶向下的观点：操作系统是向用户程序提供基本抽象的概念 自底向下的观点：操作系统用来管理复杂系统的各个部分。——有序处理竞争的程序之间对处理器、存储器以及其他的IO接口设备的分配。 1.2.2.1 对资源的管理 多道程序之间存在共享： 共享硬件 共享信息（文件、数据等） 操作系统的主要任务是记录哪个程序在使用什么资源，对资源进行分配，评估使用代价，为不同的程序和用户调解相互冲突的资源请求。 1.2.2.2 对资源管理的方法 在时间上复用 不同的程序轮流使用它。 在空间上复用 每个客户都得到资源的一部分，example：若干程序之间分割内存 1.2 操作系统历史 操作系统的发展是重叠的。 1.2.1 第一代：真空管和穿孔卡片 没有程序设计语言，没有汇编语言，没有操作系统 1.2.2 第二代：晶体管和批处理系统 IBM 1401：将卡片读入磁带 IBM 7094：完成真正的计算 1.2.3 第三代：集成电路和多道程序设计 计算机发展的两种方向： 大型机 面向商务的计算机 1.2.3.1 多道程序设计 将内存分区，每一部分存放不同的作业。 当一个作业等待IO完成时，另一个作业可以使用CPU。当作业足够多时，CPU的使用率可以接近100%。 1.2.3.2 SPOOLing技术 SPOOLing技术是一种输入输出技术。 第三代计算机的另一个特点是，卡片被拿到机房后能够很快的将卡片读入磁盘。于是，任何一个时刻，当一个作业结束时，操作系统就能将一个新作业从磁盘读出，装入内存的区域运行。这种技术叫做同时的外部机器联机操作（Simultaneous Perpheral Operation On Line， SPOOLing），该技术也用于输出。 有了SPOOLing技术后，就不再需要IBM 1401机了。 1.2.3.3 进一步发展：分时系统 出现背景：第三代计算机是批处理系统的一个变体，适用于大型科学计算和繁忙的商务数据处理，本质仍是批处理系统。程序员怀念第一代处理的方式，因为可以独占计算机，不断debug。现在从一个作业提交到取回，往往花费较长时间，一个逗号的误用可能造成编译失败，浪费程序员较多时间。 多道程序的变体，每个用户都有一个联机终端。系统轮流为各个用户服务。用户的指令较为简短，不会很耗时。 1.2.3.4 MULTICS与云计算 着眼于制造满足波士顿地区所有用户计算需求的一台机器。 计算服务以“云计算”的形式回归。 1.2.3.5 小型机的崛起 IEEE定义了POSIX规范，大多数的UNIX版本支持它。POSIX定义了一个凡是UNIX必须支持的小型系统调用接口。 并且提出了MINIX 1.2.4 第四代：个人计算机 1.2.5 第五代：移动计算机 1.3 计算机硬件简介 1.3.1 处理器 1.3.1.1 处理器基本概念 CPU基本周期：取指->译码->执行 每个CPU有专属的指令集，故x86不能执行ARM程序；ARM不能执行x86程序。 寄存器的出现：访存时间较长，使用寄存器暂存数据 寄存器的分类\\begin{cases} 程序计数器：保存下一条指令地址\\\\ 堆栈指针：指向堆栈的顶端\\\\ 程序状态字：包含条件码位等\\\\ \\end{cases} OS必须知道所有的寄存器：保存现场 提高性能：流水线的出现 关于内核态和用户态： PSW中有一个二进制位控制这两个模式 当在内核态运行时，CPU可以执行指令集中的每一条指令，使用硬件的每一种功能 用户态时，仅允许执行整个指令集的一个子集和访问所有功能的一个子集 为了从操作系统中获取服务，用户程序必须使用系统调用以陷入内核并调用操作系统 TRAP指令把用户态切换成内核态，并启用操作系统。 1.3.1.2 多线程和多核芯片 多线程和超线程的概念。 多线程：允许CPU保持两个不同的线程状态，然后再纳秒级别的时间尺度内来回切换。 GPU：由成千上万的微核组成的处理器，擅长大量并行简单计算，比如在图像应用中渲染多边形 1.3.2 存储器 理想存储器： 迅速 充分大 非常便宜 现有技术无法满足。于是存储器系统采用分层结构： 每一层： 寄存器使用和CPU一样的材料制成，非常快，没有时延。 高速缓存被分割成高速缓存行，高速缓存甚至有两级或者三级，每一级比前一级容量大且慢。 L1缓存：CPU中，存储解码的指令 第二个L1缓存：频繁使用的数据字 L2缓存：若干兆字节内存字 RAM：随机访问存储器 ROM：只读存储器；用于启动计算机的引导模块放在ROM中 1.3.3 磁盘 成本低，随机访问数据时间慢了3个数量级。低速的原因是磁盘是一种机械装置： 磁道，柱面的概念 虚拟内存机制：使得运行大于物理内存的程序称为可能，其方法是将程序放在磁盘上，而将主存作为一种缓存，用来保存使用最为频繁的部分。这种机制需要快速映像内存地址，内存映像由存储器管理单元（MMU）完成。 一个程序切换到另一个程序，有时称为上下文切换，有必要对来自缓存的所有修改写回磁盘。 1.3.4 I/O设备 I/O设备包括两个部分： 设备控制器：为操作系统提供一个简单的接口 设备本身 1.4 操作系统大观园 1.4.1 大型机操作系统 1.4.2 服务器操作系统 通过网络同时为多个若干个用户服务，允许用户共享硬件和软件资源。 1.4.3 多处理器操作系统 1.5 操作系统概念 常见问题 Q：为什么要系统调用？ 当在内核态运行时，CPU可以执行指令集中的每一条指令，使用硬件的每一种功能 用户态时，仅允许执行整个指令集的一个子集和访问所有功能的一个子集 为了从操作系统中获取服务，用户程序必须使用系统调用以陷入内核并调用操作系统 TRAP指令把用户态切换成内核态，并启用操作系统。 Q：系统调用的过程？ 参数传递：由于用户空间和内核空间使用不同的栈空间，因此系统调用的参数需要使用寄存器进行传递。 执行陷入指令（read，fork等等），引发一个内中断，使 CPU 进入内核态 在内核态，执行相应的请求，内核程序处理系统调用 返回应用程序 var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"操作系统复习笔记/进程与线程.html":{"url":"操作系统复习笔记/进程与线程.html","title":"进程与线程","keywords":"","body":"进程与线程 进程：对正在运行的程序的一个抽象。 进程是操作系统最古老也是最重要的抽象之一，是对计算的抽象。即使可用的CPU只有一个，那么也有支持（伪）并发的能力。 2.1 进程 并发的必要性、并行的概念。 并发：伪并行。CPU由一个进程快速切换到另一个进程，造成并行的错觉。 多处理器系统可以做到真正的并行。但是很难对并行的活动进行跟踪，操作系统的设计者提出了顺序进程（进程）的概念模型。 2.1.1 进程模型 进程：一个正在执行的程序实例。包括程序计数器、寄存器和变量的当前值。 每个进程有自己的虚拟CPU，真正的CPU在各个进程之间来回切换。这种快速的切换称为多道程序设计。 2.1.1.1 关于逻辑程序计数器与物理程序计数器 ​ 4道程序被抽象为4个拥有自己控制流程（每个程序有自己的逻辑程序计数器）的进程，并且每个程序都独立的运行。实际上，只有一个物理的程序计数器，在每个程序运行时，他的逻辑程序计数器被装入实际的程序计数器中。当程序执行结束时，物理计数器的值被保存在进程的逻辑程序计数器中。在观察一段时间后，所有的进程都运行了，但是任何一个给定的瞬间仅有一个进程真正在执行。 2.1.1.2 关于实时要求 CPU在不同的进程之间来回切换，每个进程的执行速度是不一定的。在对进程进行编程时，绝对不能对时序做出任何想当然的假设。 Example：10000次空循环后读取磁盘的第一条记录，但是10000次空循环期间已经切换到别的进程。 2.1.1.3 进程和程序的关系 程序：用适当形式描述的算法 进程：正在执行的程序，一个程序运行两遍那么是两个进程 2.1.2 进程的创建 2.1.2.1 进程创建的情景 4种主要的事件会导致进程的创建： 系统初始化 系统初始化时会创建若干进程，包括前台和后台。 正在运行的进程执行创建进程的系统调用 一个正在运行的进程创建一个或者多个新进程协助其工作。 用户请求创建一个新的进程 Windows 一个批处理作业的初始化 用户在这种操作系统中，提交批处理作业。在操作系统认为有资源可以运行另一个作业时，它创建一个新的进程，并运行其输入队列中的下一个作业。 从技术上看，所有的上述情形，都是由一个已经存在的进程执行了一个创建进程的系统调用。 2.1.2.2 UNIX系统和Windows系统的进程创建命令 （1）UNIX fork：创建一个与调用进程相同的副本。在调用了fork后两个进程有相同的内存映像、同样的环境字符串和同样的打开文件 execve：修改内存映像 （2）Windows CreateProcess：既处理进程的创建，也负责把程序装入新的进程。 （3）二者共同点 进程创建之后，父进程和子进程有不同的地址空间，如果其中某个进程在其地址空间中修改了一个字，这个修改对其他进程而言是不可见的。 在UNIX中： 子进程的初始地址空间是父进程的一个副本，但是这里涉及两个不同的地址空间，不可写的内存区是共享的。某些UNIX的实现使得程序正文在两者间共享，因为它不能被修改。——完全分离可写和不可写的区域 或者，子进程共享父进程的所有内存，但是这种情况下通过写时复制共享，这意味着一旦两者之一想要修改部分内存，则这块内存首先被明确的复制，以确保修改发生在私有的内存区域。——写时复制 在Windows中： 从一开始，父进程的地址空间和子进程的地址空间就是不同的 2.1.3 进程的终止 2.1.3.1 进程终止的条件 进程终止的条件： 正常退出（自愿的） 出错退出（自愿的） 严重错误（非自愿） 被其他进程杀死（非自愿） 2.1.3.2 UNIX和Windows进程终止命令 （1）正常终止 多数进程是由于完成了他们的工作而终止： example：当编译器完成了给定程序的编译之后，编译器执行一个系统调用，通知操作系统他的工作已经完成。 在UNIX中，该系统调用是exit 在Windows中，相关的调用是ExitProcess。 （2）出错退出 如执行非法指令、引用不存在的内存或者除数是零等。 在UNIX中，进程可以通知操作系统，它希望自行处理某些类型的错误，在这类错误中，进程会受到信号（被中断），而不是在出现这类错误时终止。 （3）严重错误 编译器编译不存在的文件，直接终止。 （4）被其他进程杀死 UNIX中的系统调用是kill，Windows中的系统调用是TerminateProcess。 2.1.4 进程的层次结构 在某些系统中，当进程创建了另一个进程后，父进程和子进程就以某种形式继续保持联系。子进程本身可以创建更多的进程，组成一个进程的层次结构。 2.1.4.1 UNIX进程组 进程可以与他的子进程以及之后的后裔组成一个进程组。当用户从键盘发出一个信号时，该信号被送给与键盘相关的进程中的所有成员（他们通常是在当前窗口创建的所有活动进程）。每个进程可以分别捕获该信号，忽略该信号或者采取默认的动作，即该进程被杀死。 UNIX进程组参考init的例子。 2.1.4.2 Windows进程组 Windows没有进程层次的概念，所有的进程地位都是相同的。但是在创建进程的时候，父进程得到一个特别的令牌（称为句柄），该句柄可以用来控制子进程。 2.1.5 进程的状态 每个进程是一个独立的实体，有自己的程序计数器和内部状态，但是，进程之间经常需要相互作用。一个进程的输出结果可能作为另一个进程的输入。 运行态：该时刻进程实际占用CPU 就绪态：可运行，但因为其他进程正在运行而暂停停止 阻塞态：除非某种外部事件发生，否则不能进行 2.1.5.1 进程的调度 2、3的转换通过调度程序进行。调度程序的工作就是决定应当让哪个进程运行，何时运行，应该运行多长时间等。有较多的算法。 2.1.5.2 进程模型 操作系统的最底层是调度程序，因为它上面有所有的进程。 2.1.6 进程的实现 2.1.6.1 进程表 操作系统维护着一张表格，进程表。每个进程占用一个进程表项。（或者称为进程控制块） 表项包含了进程状态的重要信息：程序计数器、堆栈指针、内存分配情况、所打开文件的状态、账号和调度信息，以及其他在进程由运行态转换到就绪态或者阻塞态时必须保存的信息。 2.1.6.2 中断 与每一I/O类关联的是一个称为中断向量的位置。它包含中断服务程序的入口地址。假设一个磁盘中断发生时，进程3正在运行。则中断硬件将程序计数器、程序状态字、有时还有一个或者多个寄存器压入堆栈，计算机随即跳转到中断向量所指示的位置。这些都是硬件完成的所有操作，然后中断服务例程接管一系列剩余的工作。 所有的中断都从保存寄存器开始，对于当前进程而言，通常是保存在进程表项（PCB）中。随后，会从堆栈中删除由中断硬件机制存入堆栈的那些信息，并且将堆栈指针指向一个由进程处理程序所使用的临时堆栈。 该例程结束后，会调用一个C过程处理某个特定中断类型剩下的工作。在完成有关工作时，某些进程就绪，接着调用调度程序，决定随后该运行哪个进程。 一个进程在执行过程中可能被中断数千次，但每次中断后，都能回到与中断发生前完全相同的状态。 2.1.7 多道程序设计模型 多道程序设计可以提高CPU利用率。 假设： 进程等待I/O操作的时间与其停留在内存中的时间的比为p 内存中有n个进程 n个进程都在等待I/O操作的概率是$p^n$ 那么CPU的利用率由下面的公式给出： CPU利用率 = 1-p^n 2.2 线程 在传统操作系统中，每个进程有一个地址空间和一个控制线程。不过经常存在一个地址空间中准并行运行多个控制线程的情形，这些线程就像（差不多）分离的进程（共享地址空间除外）。 2.2.1 线程的使用 使用多线程的原因： 程序设计模型：在许多应用中同时发生着多种活动。其中某些活动会随着时间的推移被阻塞。通过将这些应用程序分解成可以准并行运行的多个顺序线程，程序设计模型会变得简单。 创建和撤销的开销：线程比进程更加轻量级，比进程更加容易创建，也更加容易撤销。在有大量线程需要动态和快速修改时，具有这一特性是非常重要的。 性能考虑：若多个线程都是CPU密集型的，那么并不能获得性能的增强，但是如果存在大量的计算和大量的I/O处理，拥有多个线程允许这些活动彼此重叠进行，会加速程序执行的速度 多线程使真正的并行成为可能[CH8] 多线程模型中：并行实体有共享同一个地址空间和所有可用数据的能力。 Example：文件编辑器的例子——三个线程能够代替三个进程 2.2.2 经典的线程模型 进程模型基于两种独立的概念：资源分组处理与执行。将这两种概念分开，就引入了“线程”的概念。 2.2.2.1 理解进程的角度：资源分组 理解进程的一个角度是：用某种方法将相关的资源集中在一起。 进程有存放程序正文和数据以及其他资源的地址空间，这些资源中包含打开的文件、子进程、即将发生的定时器、信号处理程序、账号信息等。把他们都放到进程中更容易管理。 2.2.2.2 理解进程的角度：线程 进程拥有一个执行的线程，通常简写为线程。线程中有： 一个程序计数器，用来记录接着要执行哪条指令 寄存器，用来保存线程当前的工作变量 堆栈，用来记录执行历史 进程用于将资源集中在一起，线程是在CPU上被调度的实体。 （1）多线程理解 同一个进程中并行运行多个线程，是对在同一台计算机中并行运行多个进程的模拟。 多个线程共享同一个地址空间和其他资源。 多个进程共享物理内存，磁盘，打印机和其他资源 在2-11a中，可以看到三个传统的进程。每个进程都有自己的地址空间和单个控制线程。每个线程在不同的地址空间中运行。 在2-11b中，可以看到一个进程带有三个控制线程。每个线程在相同的地址空间中运行。 进程中的线程，所有线程有相同的地址空间，共享同样的全局变量。一个线程可以读、写另一个线程的堆栈，甚至可以清除另一个线程的堆栈。线程之间是没有保护的。 （2）线程的状态 线程的状态和进程一样： 就绪 运行 阻塞 （3）线程堆栈 每个线程的堆栈有一帧，供各个被调用但是还没有从中返回的过程使用。在该栈帧中存放了相应过程的局部变量以及过程调用完成之后使用的返回地址。 通常每个线程会调用不同的过程，从而有一个各自不同的执行历史，故每个线程都要有自己的堆栈。 （4）线程的创建 多线程的情况下，进程通常会从当前的单个线程开始。线程调用库函数（如thread_create）创建。thread_create()参数指定了新线程要运行的过程名。 线程之间是平等的，不论有无层次关系，创建线程通常都会返回一个线程标识符，该标识符是新线程的名字。 （5）线程的退出 thread_exit 线程完成工作后，可以通过一个库过程（如thread_exit）退出，接着该线程消失，不再可调度。这种情况下，现成的创建和终止类似于进程的创建和终止。 thread_join 某些线程调用中，例如thread_join，可以线程可以等待一个（特定）线程退出。这个过程堵塞调用直到那个特殊的线程退出。 thread_yeild 允许线程自动放弃CPU从而让另一个线程运行。 因为线程不同于进程，所以无法利用时钟中断强制线程让出CPU。 2.2.3 POSIX线程 IEEE定义了线程的标准。定义的线程包叫做pthread。大部分UNIX支持该标准。 所有pthread线程都有某些特性。每一个都有一个标识符，一组寄存器和一组存储在结构中的属性。这些属性包括堆栈大小、调度参数以及其他线程需要的项目。 pthread_attr_init 建立一个线程的属性结构，并初始化成默认值。 pthread_attr_destory 删除一个线程的属性数据结构，释放它占用的内存。不会影响调用它的线程，这些线程会继续存在。 2.2.4 线程的实现 有两种主要的方式实现线程包：在用户空间和在内核中。这两种方法互有利弊，不过混合实现的方式也有可能。 2.2.4.1 在用户空间中实现线程 把整个线程包放在用户空间中，内核对线程包一无所知。从内核的角度考虑，就是按照正常的方式进行管理：单线程进程。线程在一个运行时系统的上层运行，该运行时系统是一个管理线程的过程的集合。如：pthread_create，pthread_exit，pthread_join和pthread_yeild等。 在用户空间管理线程时，每个进程需要有其专用的线程表，用来跟踪该进程中的线程。线程表与进程表相似，不过仅仅记录各个线程的属性，如每个线程的程序计数器、堆栈指针、寄存器和状态等。线程表由运行时系统管理。 在用户空间实现的优点： 用户线程包可以在不支持线程的操作系统上实现 允许每个进程有自己定制的调度算法 线程切换至少比陷入内核要快一个数量级：thread_yeild后调用线程调度程序来选择另一个要运行的程序，调度是本地过程。 在用户空间实现的缺点： 无法实现阻塞系统调用，因为会阻塞所有的线程 如果一个线程引起了缺页中断，那么整个进程都会被阻塞直到I/O完成，尽管有其他的线程可以执行 如果一个线程开始运行，那么在该进程中的其他线程就不能运行，除非第一个线程自动放弃CPU 2.2.4.2 在内核中实现线程 在内核中实现线程，不再需要运行时系统，进程中也没有线程表。 内核中有用来记录系统中所有线程的线程表。当某个线程希望创建一个新线程或者撤销一个已有的线程时，他进行一个系统调用，这个系统调用通过对线程表的更新完成线程的创建或者撤销。 线程表维护的信息： 寄存器 状态 其他信息 与在用户空间中一样。另外，内核维护了传统的进程表，以跟踪进程的状态。 优点： 所有能够阻塞线程的调用都以系统调用的形式实现。当一个线程阻塞时，可以运行进程中的另一个线程。 缺页中断类似 缺点： 但是内核中创建或者撤销线程的代价比较大 2.2.4.3 混合实现 引入内核级线程，然后将用户线程与全部内核线程多路复用起来。 编程人员可以决定多少个内核级线程和多少个用户级线程彼此多路复用。带来了最大的灵活度。 内核只识别内核级线程，并对其进行调用。一个内核线程会被多个用户级线程多路复用。每个内核级线程有一个可以轮流使用的用户线程集合。 2.2.5 弹出式线程 分布式系统中处理到来的消息：如服务请求。 传统：将进程与线程阻塞在receive系统调用上，等待消息到达。消息到达时，系统调用接收消息。 弹出式线程：一个消息的到达导致创建一个处理该消息的线程。好处是线程新，没有历史，可以快速创建。消息的到达和处理时间非常短。 2.3 进程间通信 进程经常需要与其他进程通信。进程间通信的问题： 进程如何把信息传递给另一个 确保两个或者更多的进程在关键活动中不会出现交叉 通信的正确顺序 第一个问题对于线程来说比较容易，因为它们共享一个地址空间。但是另外两个问题同样适用于线程。 2.3.1 竞争条件 Example：假脱机目录的例子 竞争条件：两个或者多个进程读写某些共享数据，而最后的结果取决于进程运行的精确时序，称为竞争条件。 2.3.2 临界区 凡涉及共享内存、共享文件以及共享任何资源的情况都会引起与前面类似的错误。 解决关键：需要互斥（mutual exclusion），即以某种手段确保当一个进程在使用一个共享变量或者文件时，其他进程不能进行相似的操作。 临界区：对共享内存进行访问的片段称为临界区（critical region）。 目标：适当安排，使得两个进程不同时处于临界区中。 对于一个好的解决方案，需要满足下面4个条件： 任何两个进程不能同时处于其临界区中 不应对CPU的速度和数量做任何的假设 临界区外运行的进程不得阻塞其他进程 不得使进程无期限的等待进入临界区 2.3.3 忙等待的互斥 实现互斥的方案 2.3.3.1 屏蔽中断 进程进入临界区后屏蔽所有中断，离开之前再打开中断。 屏蔽中断后时钟中断也被屏蔽，只有发生时钟中断时才会进行进程切换，因此屏蔽之后CPU不会再切换到别的进程。 缺点：屏蔽中断的权利交给用户进程是不明智的。 2.3.3.2 锁变量 设想有一个共享（锁）变量，其初始值为0。当一个进程想进入临界区时，他首先测试这把锁。 锁的值为0，那么进程将其设置为1，并进入临界区 锁的值为1，那么进程等待直到其值变为0 缺点：与脱机目录一样的疏漏。 2.3.3.3 严格轮换法 用于忙等待的锁称为自旋锁（spin lock） 该方案要求两个进程严格轮流进入临界区。 2.3.3.4 Peterson解法 使用共享变量。 #define FALSE 0 #define TRUE 1 #define N 2 /* number of processes */ int turn; /* whose turn is it? */ int interested[N]; /* all values initially 0 (FALSE) */ void enter region(int process) /* process is 0 or 1 */ { int other; /* number of the other process */ other = 1 − process; /* the opposite of process */ interested[process] = TRUE; /* show that you are interested */ tur n = process; /* set flag */ while (turn == process && interested[other] == TRUE); /* null statement */ ; } void leave region(int process) /* process: who is leaving */ { interested[process] = FALSE; /* indicate departure from critical region */ } 2.3.3.5 TSL指令 硬件支持的方案，有下面的指令： TSL RX, LOCK 称为测试并加锁，将一个内存字lock读到寄存器RX中，然后在该内存地址上存一个非零值。读字和写字的操作保证是不可分割的，即该指令结束之前其他处理器不允许访问该内存字。执行TSL指令的CPU将锁住内存总线，以进制其他CPU在本指令结束之前访问该内存字。 一个可以替代TSL的指令是XCHG，它原子性的交换了两个位置的内容。 2.3.4 睡眠与唤醒 Peterson解法和TSL或者XCHG解法都是正确的，但是都有忙等待的缺点。忙等待解法本质上是：当一个进程想进入临界区时，先检查是否允许进入，若不允许，则该进程将原地等待，直到允许为止。 忙等待可能造成优先级反转问题：两个进程H和L，H优先级高于L，H在就绪态时H可以随时运行。某一时刻，L处于临界区中，此时H变到就绪态，准备运行（例如，一条I/O操作结束）。现在H开始忙等待，但由于当H就绪时L不会被调度，也就无法离开临界区，所以H将永远一直等下去。被称为优先级反转问题。 进程间通信原语：无法进入临界区时将阻塞，而不是忙等待。最简单的是sleep和wake up。 sleep：引起调用进程阻塞的系统调用，即被挂起，直到有另一个进程将其唤醒。 wake up：有一个参数，即要被唤醒的进行。 2.3.4.1 生产者-消费者问题 生产者：把信息放入缓冲区；缓冲区已满时休眠 消费者：从缓冲区中取出信息；缓冲区已空时休眠 上述的程序存在竞争条件：当count=0时，消费者读取count，判断得count=0，此时时间片轮转到生产者，生产者读取为0，进行生产；产出1后wake up消费者。但是此时消费者并为逻辑上进入睡眠，所以wake up信号量丢失，然后当消费者下次运行时，他读到的count是0，所以睡眠。而生产者迟早会填满整个缓冲区，然后睡眠。这样一来，两个进程都将永远睡眠下去。 2.3.5 信号量 down操作： 检查信号量的值是否大于零 若大于0，则将其值减1（即用掉一个保存的唤醒信号）并继续； 若该值为0，则进程睡眠 检查数值、修改变量值以及可能发生的睡眠均为一个单一的，不可分割的原子操作。 up操作： 检查信号量的值增加1，唤醒一个进程。 对一个有进程在其上睡眠的信号量执行一次up操作后，该信号量的值仍是0，但在其上睡眠的进程却少了一个。 信号量的增加和进程的唤醒同样也是不可分割的。不会有进程因为执行up而阻塞。 down和up操作也可以称为P操作和V操作。 2.3.5.1 用信号量解决生产者-消费者问题 通过up和down作为系统调用实现，而且操作系统只需在执行以下操作时屏蔽所有中断：测试信号量、更新信号量以及在需要的时候使某个进程睡眠。 该方法使用了三个信号量： full：记录充满的缓冲槽的数目；初值为0 empty：记录空缓冲槽的数目；初值为缓冲区中槽的数目 mutex：确保生产者和消费者不会同时访问缓冲区 信号量的另一种用途是用来实现同步。信号量full和empty用来保证某种事件顺序发生或者不发生。 2.3.6 互斥量 互斥量是信号量的简化版本、互斥量仅仅适用于管理共享资源或指责一小段代码。 互斥量是一个可以处于两态之一的变量：解锁和加锁。实际上常常食用一个整型量，0表示解锁，其他的所有值表示加锁。 互斥量有两个过程，当一个线程（或进程）访问临界区时，他调用mutex_lock。 如果该互斥量当前是解锁的（即临界区可用），此调用成功，调用线程可以自由进入该临界区 如果互斥量已经加锁，那么调用线程被阻塞，直到在临界区的线程完成并调用mutex_unlock 如果多个线程被阻塞在该互斥量上，将随机选择一个线程并允许它获得锁 mutex_lock和mutex_unlock的实现代码如下： 2.3.6.1 快速用户区互斥futex futex：Linux的一个特性，实现了基本的锁（很像互斥锁），但避免了陷入内核。 因为来回切换到内核花销很大，所以这样做可观地改善了性能。 futex包含两个部分\\begin{cases}一个内核服务\\\\一个用户库\\end{cases} 内核服务 提供一个等待队列，允许多个进程在一个锁上等待。 用户库 2.3.6.2 pthread中的互斥量 pthread提供了一系列的用来同步线程的函数。 基本机制是使用一个可以被锁定和解锁的互斥量保护每个临界区 互斥量在允许或阻塞对临界区的访问上很有用 提供了另一种同步机制条件变量 条件变量则允许线程由于一些未达到的条件而阻塞 pthread_cond_wait：阻塞调用线程直到另一个线程向它发起信号 pthread_cond_signal：发起唤醒 条件变量与互斥量经常一起使用。这种模式用于让一个线程锁住一个互斥量，然后当它不能获得他所期待的结果时等待一个条件变量。 2.3.7 管程 Monitor 管程：高级同步原语，是一个由过程、变量及数据结构组成的集合。 任何一个时刻，管程中只能有一个活跃进程，可以有效完成互斥。 互斥：使用互斥量和信号量；编译器安排互斥，操作概率小很多 无法运行时阻塞：条件变量以及相关的两个操作wait和signal 2.3.8 消息传递 消息传递是机器间的信息交换方法。这种进程间通信方法使用两条原语：send和receive。 send(destination,&message)：向一个给定的目标发送消息 和 receive(source,&message)：从一个源接收一个消息。 如果没有消息可用，则接收者可能被阻塞，直到一条消息到达，或者带着一个错误码返回。 2.3.8.1 消息传递系统的设计要点 区分新老消息：序号 消息丢失：发送确认 2.3.10 避免锁：读-复制-更新 有些情况下可以允许写操作来更新数据结构，即便有其他的进程正在使用它。关键在于确保每个读操作要么读取旧的版本要么读取新的版本，但绝不能是新旧数据的一些奇怪组合。 2.4 调度 存在多个进程竞争CPU的情况，必须要选择下一个要运行的进程。在操作系统中，完成选择工作的这一部分称为调度程序，该程序使用的算法称为调度算法。 线程的处理与进程相似，先讨论进程，然后讨论线程调度的独特文体。 2.4.1 调度简介 批处理阶段：依次运行磁带上的每一个作业 多道程序设计：批处理和分时服务相结合 个人计算机：两个方向：唯一进程（不用调度选择）；或者多个调度程序但是先后顺序或者时间要求可能没那么严格。 网络服务器：多个进程经常竞争CPU 2.4.1.1 进程行为 几乎所有的进程I/O请求好计算都是交替突发的。如下图，某些进程花费了大多数时间在计算上（图a），而其他进程（如图b）则在等待I/O上花费了绝大多数的时间。根据进程在等待I/O上花费的时间，前者称为计算密集型（compute-bound），后者称为I/O密集型（I/O-bound）。 随着CPU变得越来越快，更多的进程倾向于I/O密集型。这种现象之所以发生是因为CPU改进得比磁盘快，其结果是，未来对I/O密集型进程的调度处理更为重要。 基本思想：如果要运行I/O密集型进程，那么应该让它尽快得到机会，以便发出磁盘请求并保持磁盘始终忙碌。 2.4.1.2 何时调度 创建一个新进程后：运行父进程or子进程 在一个进程退出后 当一个进程阻塞在I/O和信号量上，或者因为其他原因阻塞时 当一个I/O中断发生时 两种调度算法： 非抢占式调度：挑选一个进程运行，直到该进程被阻塞或者自动放弃CPU 抢占式调度：挑选一个进程，并且让进程运行至某个固定时间段的最大值。如果该时间段结束时，进程仍在运行，他就被挂起，调度程序选择另一个进程运行。 2.4.1.3 调度算法分类 不同的环境需要不同的调度算法，列举三种环境： 不同的环境\\begin{cases}批处理：非抢占式也是可以接受的\\\\交互式：抢占是必须的\\\\实时：抢占有时是不必要的\\end{cases} 2.4.1.4 调度算法的目标 吞吐量：每小时完成的作业数量 周转时间：从一个批处理作业提价到完成时刻为止的统计平均时间。该数据度量了用户得到输出所需的平均等待时间 响应时间：发出命令到得到响应的时间 2.4.2 批处理系统中的调度 2.4.2.1 先来先服务 进程按照它们请求CPU的顺序使用CPU，有一个就绪进程的单一队列。作业不会因为运行时间太长而被中断。当其他作业进入时，它们排列到队列队尾。 优点：易于理解，便于应用 缺点： 不利于短作业及I/O密集型进程 2.4.2.2 最短作业优先 非抢占式批处理算法，平均周转时间最短。 只有在所有作业都可以同时运行时，最短作业优先算法才是最优化的。 2.4.2.3 最短剩余时间优先 最短作业优先的抢占式版本。 选择剩余运行时间最短的进程运行。 2.4.3 交互式系统中的调度 2.4.3.1 轮转调度 每个进程被分配一个时间片，允许该进程在该时间片中运行。 如果时间片结束时该进程还在运行，将剥夺CPU并分配给另一个进程。 如果该进程在时间片结束前阻塞或者结束，即CPU立即进行切换。 时间片轮转中唯一有趣的是时间片的长度从一个进程切换到另一个进程是需要一定时间的——保存装入寄存器值集内存映像、更新各种表格和列表、清除和重新调入内存高速缓存等。需要考虑真正工作时间与切换开销（上下文切换）耗费的时间的比值。 2.4.3.2 优先级调度 轮转调度做了一个隐含的假设：所有的进程同等重要。 优先级调度基本思想：每个进程被赋予一个优先级，允许优先级最高的进程可以最先运行。 为防止高优先级的进程无休止的运行下去： 调度程序可能在每个时钟中断时降低当前进程的优先级，如果这一行为导致该进程的优先级低于次高优先级的进程，则进行进程切换。 另一种方法是：给每个进程赋予一个允许运行的最大时间片，当用完这个时间片时，次高优先级的进程便获得运行机会。 优先级调度的一种实现：一组进程分成若干类，并且在各类之间采用优先级调度，而在各个进程内部采用轮转调度： 2.4.3.3 多级队列 设立优先级类，属于最高优先级的进程类运行1个时间片，属于次高优先级类的进程运行2个时间片，再次一级运行4个时间片，以此类推，当一个进程用完分配的时间片后，他被移到下一类。 2.4.3.4 最短进程优先 对于批处理系统：最短作业意味着最短响应时间。 交互式进程通常遵循下列模式：等待命令、执行命令、等待命令、执行命令，不断重复。如果将每个命令看做一个独立的“作业”，可以通过最短作业优先来使响应时间最短。唯一的问题是如何从当前进程中找到那个最短的进程。 找到最短进程的方法： 老化技术 运行估计运行时间最短的那个。假设每条命令的预估运行时间为$T_0$。假设下一次运行时间为$T_1$，用这两个值加权来进行最短时间估计时间：$aT_0+(1-a)T_1$。通过选择a的值来决定是尽快忘掉老的运行时间还是在较长一段时间内记住他们。当$a=\\frac{1}{2}$时，可以得到下面的序列： T_0,\\quad T_1/2+T_0/2,\\quad T_2/2+T_1/4+T_0/4,\\quad T_3/2+T_2/4+T_1/8+T_0/8 可以看到，在三轮过后，$T_0$在新的估计值中占的比例是$1/8$ 有时把这种通过当前测量值和先前估计值加权得到下一个新的估计值的技术称为老化（aging）。 2.4.4 实时系统中的调度 实时系统是一种时间起着主导作用的系统。 实时系统通常可以分为硬实时和软实时： 硬实时：必须满足绝对的截止时间 软实时：虽然不希望偶尔错失截止时间，但可以容忍 可调度的实时系统： 实时系统可以按照响应方式进一步分类成周期性事件和非周期性事件。一个系统可能响应多个周期性的事件流。根据每个事件要处理的时间长短，系统甚至可能无法处理完所有的事件。例如：有m个周期事件，事件$i$以周期$P_i$发生，并需要$C_i$秒CPU处理一个事件，那么可以处理事件的条件是： \\sum\\limits_{i=1}^m\\frac{C_i}{P_i}\\leq 1 满足这个条件的系统称为可调度的。 2.4.5 策略和机制 调度机制与调度策略分离：调度算法以某种形式参数化，参数由用户进程填写。 2.4.6 线程调度 用户级线程： 由运行时系统将上述进程的调度算法应用在线程上。 2.5 经典的IPC问题 2.5.1 哲学家就餐问题 问题背景： 哲学家的生活中有两种交替活动时段：吃饭和思考。饿了时，试图分两次去拿左边和右边的叉子，每次拿一把，不分次序。如果成功得到两把叉子，就开始吃饭，吃完后放下叉子继续思考。 饥饿（starvation）：所有程序都在不停地运行，但都无法取得进展，称为饥饿。 #define N 5 /* number of philosophers */ #define LEFT (i+N−1)%N /* number of i’s left neighbor */ #define RIGHT (i+1)%N /* number of i’s right neighbor */ #define THINKING 0 /* philosopher is thinking */ #define HUNGRY 1 /* philosopher is trying to get for ks */ #define EATING 2 /* philosopher is eating */ typedef int semaphore; /* semaphores are a special kind of int */ int state[N]; /* array to keep track of everyone’s state */ semaphore mutex = 1; /* mutual exclusion for critical regions */ semaphore s[N]; /* one semaphore per philosopher */ void philosopher(int i) /* i: philosopher number, from 0 to N−1 */ { while (TRUE) { /* repeat forever */ think(); /* philosopher is thinking */ take_forks(i); /* acquire two for ks or block */ eat(); /* yum-yum, spaghetti */ put_forks(i); /* put both for ks back on table */ } } void take forks(int i) /* i: philosopher number, from 0 to N−1 */ { down(&mutex); /* enter critical region */ state[i] = HUNGRY; /* record fact that philosopher i is hungry */ test(i); /* try to acquire 2 for ks */ up(&mutex); /* exit critical region */ down(&s[i]); /* block if for ks were not acquired */ } void put forks(i) /* i: philosopher number, from 0 to N−1 */ { down(&mutex); /* enter critical region */ state[i] = THINKING; /* philosopher has finished eating */ test(LEFT); /* see if left neighbor can now eat */ test(RIGHT); /* see if right neighbor can now eat */ up(&mutex); /* exit critical region */ } void test(i) /* i: philosopher number, from 0 to N−1 */ { if (state[i] == HUNGRY && state[LEFT] != EATING && state[RIGHT] != EATING) { state[i] = EATING; up(&s[i]); } } 2.5.2 读者-写者问题 读者写者问题，为数据库访问建立了一个模型。 第一个读者对信号量db执行down操作，随后的读者只是递增一个计数器rc。当读者离开时，他们递减这个计数器，而最后一个读者则对信号量执行up操作，这样允许一个被阻塞的写者（如果存在的话）可以访问数据库。 2.6 面试常见问题 var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"经验贴-面试/保研英语面试常见问题总结.html":{"url":"经验贴-面试/保研英语面试常见问题总结.html","title":"保研英语面试常见问题总结","keywords":"","body":"英语面试常见问题总结 PART1 Introduction 1.1 自我介绍-3min以内版本 老师好，我是孙蕴琦，是来自西安电子科技大学软件工程专业的一名学生。我的专业排名为第2名，四六级成绩较好，分别为600和539分。 在本科期间我有过服务计算方面的科研经历，具体参与的科研为一个关于EUA问题（边缘用户分配问题）的研究。在科研过程中，我负责的是前期算法选择和后期的对比算法测试两个部分的工作。前期我使用了一个开源的规划引擎叫做OptaPlanner，测试其中集成的如遗传算法等启发式算法在其中的应用效果，以验证该引擎是否存在应用在论文算法中的可能。在论文编写的后期，我负责实现对比算法的性能测试，计算对比算法的QoS，QoE等指标。 另外也有过一个工程项目的经历，项目的具体背景因为涉及一些机密信息，所以不方便详细说明。项目的核心是OptaPlanner规划引擎的改造，就是上述在EUA问题中提到的Opta。这个项目我主要负责的是研究Opta的源码，给出一个算法的替换文档。 在竞赛方面，我主要参加的竞赛是数学建模竞赛，负责了队伍三年内的所有竞赛的编程工作，队伍也斩获了省级一等奖、国际二等奖的成绩。 以上就是我在科研、竞赛、项目方面的主要经历，另外还有一些关于Hadoop文件系统源码分析、函数绘图语言解释器的编写相关的原创性工作，如果老师感兴趣，我愿意后续介绍。 I am Sun Yunqi, a student from Xidian University majoring in software Engineering. I ranked second in my major. And the scores of my CET-4 and CET-6 are 600 and 539 respectively. During my undergraduate study, I had scientific research experience in service computing, specifically participating in a research on EUA problem (edge user allocation problem). I was responsible for algorithm selection in the early stage and test the comparison algorithm in the late stage. In addition, I also have an engineering project experience, the specific background of the project involves some confidential information, so it is not convenient to elaborate. The core of the project is to replace the algorithm in Opta. In this project, I was mainly responsible for studying the source code of Opta and providing a replacement document of the algorithm. In terms of competition, I mainly took part in mathematical modeling competition, and was responsible for the programming of all competitions within three years. Our team also won the provincial first prize and the international second prize. The above are my main experiences in scientific research, competitions and projects. In addition, I have also done some original work related to Hadoop file system and function language interpreter. If you are interested, I would like to introduce them to you. 1.2 项目介绍 1.2.1 边缘计算项目 我的设计是一种规则引擎结合批处理式的启发式算法，我们将EUA问题建模成一个规划问题，问题的目标是 最大化用户的覆盖率 最小化重新分配的次数 问题的约束条件为 用户在MEC的服务范围内 已分配的用户数量小于当前用户的总数量 这里将相应的约束通过编写的规则映射成得分的计算：破坏约束会以负分数的形式反馈，满足软约束会以正分数的形式反馈，最后选取得分最高的方案。为了提高得分计算的效率，基于规则系统计算得分的时候我们采取增量的计算的方式，计算本次分配相对于上次分配的一个$\\Delta$，而不是全部整体再进行一次得分计算。 My design is a rule engine combined with a batch-style heuristic algorithm. We model the EUA problem as a planning problem. The goals of the problem are Maximize user coverage Minimize the number of reallocations The constraints of the problem are Users should be within the service scope of MEC The number of allocated users is smaller than the total number of current users Here, the corresponding constraints are mapped into the score calculation through the written rules: the broken constraints will be given feedback in the form of negative score, and the soft constraints will be given feedback in the form of positive score. Finally, the scheme with the highest score is selected. In order to improve the efficiency of score calculation, when calculating the score based on the rule system, we adopt the incremental calculation method to calculate the $\\Delta$of the current distribution compared with the last distribution, instead of the whole score calculation again. 1.2.2 Opta项目 1.2.3 Hadoop 文件系统 PART2 常见问答 var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"经验贴-面试/英文个人陈述.html":{"url":"经验贴-面试/英文个人陈述.html","title":"英文个人陈述","keywords":"","body":"Personal Statement ​ I am SunYunqi, an undergraduate student majoring in software engineering from Xidian University. I have always been fascinated by the strong scientific research atmosphere of Shanghai Jiao Tong University, hoping to be admitted by UM-SJTU Joint Institute. In the following, I will introduce myself from three aspects: my academic background, scientific research experience and research plan for the future postgraduate stage. 1. Academic Background ​ My performance in the first five semesters was excellent, ranking 2/119 (top 2%). My GPA was 3.9/4.0, and I was awarded first-class scholarship, Excellent Student and Excellent Member of the Communist Youth League. In addition, I got good scores in CET 4 and CET 6, which were 600 and 539 respectively. My experience in scientific research and participating in international competitions has also cultivated my ability to read English literature proficiently. 2. Undergraduate Research and Original Work ​ In terms of scientific research, I have always had a strong interest in cloud computing and big data. ​ In my sophomore year, I joined the Data Intelligence Laboratory of the school for related learning. In the one year since I joined the laboratory, I have been actively responsible for the work, and followed up the engineering project of \"Core transformation and Application of OptaPlanner Planning Engine\" and the related scientific research work of \"Edge User Allocation (EUA) problem\". In the Opta project, I was mainly responsible for source code analysis and providing process documents for the replacement of the algorithm core, which I accomplished excellently. In the scientific research activity of EUA problem, I participated in the modeling of the problem and the analysis of the core algorithm, and mainly undertook the setting of the algorithm comparative experiment and wrote the analysis document of the comparative experiment results. At present, there is an ICSOC conference paper in the research project. ​ I also have rich experience in other original practical projects during my college years: my team analyzed the support mechanism and design concept of Hadoop's underlying file system, considered how to add support for Windows file system into it, and implemented a simple XdFileSystem by myself. In the second year of college, I used Python to implement a drawing language interpreter, integrated dynamic drawing, graphics preference setting, exception description and other functions. 3. Research Plan ​ If I have the honor to study for a master's degree in Shanghai Jiao Tong University, I will make the following efforts from the three aspects. Professional courses ​ In the postgraduate period, I will continue to maintain a practical and active learning attitude, hoping to further systematically and scientifically learn the theoretical knowledge, so as to lay a solid foundation for academic research and practical activities. Academic research ​ I hope I can focus on scientific research and devote myself to academic study during my postgraduate study. ​ In depth, I hope to study big data or network computing related fields based on the edge computing knowledge I learned when I participated in scientific research projects during my undergraduate years. I hope to further study cloud-edge collaborative computing and other knowledge, and try to alleviate the existing computing pressure in the field of big data. On the other hand, from the perspective of breadth, I have a certain understanding of Hadoop distributed architecture during my undergraduate study, and I am eager to have the opportunity to participate in distributed research and further explore issues such as big data storage. ​ In the process of scientific research and learning, I will try to cultivate the habit of reading literature every day, draw experience from the achievements of others and summarize my own shortcomings, and simultaneously improve my cognitive breadth and logical thinking ability. I will actively communicate with my supervisor and other members of the team, constantly improve my theory, correct mistakes and shortcomings, and enhance my scientific research ability and teamwork ability. ​ My goal is to publish at least one CCF class A paper or other top-journal paper during my postgraduate study, to truly make contributions and achievements in my field, and do my best to live up to my own guidance and expectations as well as those of teachers. Practical projects ​ In addition to scientific research, I am also willing to participate in some engineering projects. In my opinion, learning to apply cutting-edge theoretical knowledge into practice is also one of the important values of scientific research. In the process of participating in the project, I will guide the practice with theory, draw experience from the practice, and constantly innovate to improve my practical level. var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"经验贴-面试/预推免各院校经验贴总结.html":{"url":"经验贴-面试/预推免各院校经验贴总结.html","title":"预推免各院校经验贴总结","keywords":"","body":"预推免各院校经验贴总结 [tips 关于华五清北] 复旦和浙大入营后还会填一轮志愿，故可以填专硕保证入营。 上交预推免只有直博了 科大无预推免 复旦结果可能出的很晚 pre：英文面试问题汇总 哈深、复旦、南大等都有英语面试，需要提前背过常见问题 2021计算机保研夏令营、预推免英语问答echoliuy的博客-CSDN博客计算机夏令营面试问题 如何搞定保研中的英语面试？保研面试中常见的英语问题有哪些？ - 知乎 (zhihu.com) 1. 哈深 经验贴： 保研之路——哈深计算机预推免乱八七糟的小白的博客-CSDN博客哈深计算机预推免【注意离散数学复习！！！】 2021年计算机专业保研经历分享（复旦、浙大、上科大） - 知乎 (zhihu.com) 2021年哈尔滨工业大学(深圳)计算机学院预推免面试经历w_uxidixi的博客-CSDN博客哈工深预推免 2020年哈工大深圳CS预推免经历No.17.Devil的博客-CSDN博客哈深预推免 211无科研无rank菜鸡的2021计算机保研记录（川大、南软、华师se、信工所、计算所、软件所）reedcome的博客-CSDN博客南大软院预推免 2020年哈尔滨工业大学(深圳)计算机学院预推免面试_ModestYjx的博客-CSDN博客 保研经验分享--清深、交软、计算所、哈深、成电_weixin_48628281的博客-CSDN博客 21推免经验整理 - 知乎 (zhihu.com) 1.1 笔试 考察范围：数据结构，离散数学，操作系统，计组，计网，数据库。【408重点】 离散题目大多是牛客上的，但是牛客上貌似也没有总结，很零散 考核题目和考研哈深的. 1.2 面试 PPT自我介绍，PPT上项目要注意，谨慎纯开发项目，考察算法（抽算法题，问思路） 英文介绍项目 2. 南大 2.1 面试 只有面试，无机考 1min英文自我介绍 提英文问题，如英文解释快排 计网的知识，ipv6出现的动力是什么，以及报文头哪些字段发生了变化；还问了很多其他对于机器学习的一些理解，感觉这些是没法准备，只能看现场发挥了 3. 浙大 只有面试，无机考 3-5min的自我介绍 算法问题 4. 复旦 经验帖： 2021年计算机专业保研经历分享（复旦、浙大、上科大） - 知乎 (zhihu.com) 2021复旦计算机保研夏令营经验LinX\\I/的博客-CSDN博客复旦保研机试 2020复旦大学计算机夏令营机试题 (wwwofai.com) BlankSpacePlus/fdu-cs-summer-camp: 复旦大学2021年CS夏令营机试题解 (github.com) 保研之路——复旦计算机学院预推免乱八七糟的小白的博客-CSDN博客预推免有机试吗 【保研夏令营经验贴】2021复旦大学计算机科学技术学院小天才才的博客-CSDN博客复旦网安预推免 2021年计算机专业保研经历分享（复旦、浙大、上科大） - 知乎 (zhihu.com) 1.4.1 机考 DP题，发给联络员解题思路和测试样例的pdf以及源代码即可。 面试时会提问机考相关的问题。 1.4.2 英文面试 经验贴中有提到的英文面问题： 自我介绍 为什么选择复旦 介绍项目，根据项目进行提问 介绍本科校园生活 介绍你所在的城市 科研阶段中的最大挑战 研究生的研究方向 如果录取打算研究什么 1.4.3 专业课面试 中文自我介绍，科研经历，如果没有可能到专业课上（经验贴概率论、机器学习、python），机考思路 5. 北航软院 var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"},"GLOSSARY.html":{"url":"GLOSSARY.html","keywords":"","body":"markdown 简洁优雅的排版语言,简化版的 HTML,加强版的 TXT,详情请参考 https://xinwuyun.github.io/markdown/ git 分布式版本控制系统,详情请参考 https://xinwuyun.github.io/git/ var targetUl = document.getElementsByClassName('page-inner')[0].getElementsByTagName('ul')[0];if(targetUl.getElementsByTagName('a').length>0){targetUl.className='toc';}"}}